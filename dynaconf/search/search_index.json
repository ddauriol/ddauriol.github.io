{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"DYNACONF a layered configuration system for Python applications -with strong support for 12-factor applications and extensions for Flask and Django . Release v|version|. ( Installation ) Dynaconf - Easy and Powerful Settings Configuration for Python Strict separation of settings from code (following 12-factor applications Guide). Define comprehensive default values. Store parameters in multiple file formats ( .toml , .json, .yaml, .ini and .py). Sensitive secrets like tokens and passwords can be stored in safe places like .secrets file or vault server. Parameters can optionally be stored in external services like Redis server. Simple feature flag system. Layered [environment] system. Environment variables can be used to override parameters. Support for .env files to automate the export of environment variables. Correct data types (even for environment variables). Have only one canonical settings module to rule all your instances. Drop in extension for Flask app.config object. Drop in extension for Django conf.settings object. Powerful \\$ dynaconf CLI to help you manage your settings via console. Customizable Validation System to ensure correct config parameters. Allow the change of dynamic parameters on the fly without the need to redeploy your application. Who is using Dynaconf? Pulp Project - Django - (RedHat) Ansible Galaxy - Django - (RedHat) Insights QE (RedHat) CloudForms QE (RedHat) Seek AI & Catho Job boards - Flask - (on AI APIs) Quokka CMS - Flask iNNOVO Cloud GmbH Teraki ARA Records Ansible - Django Are you using Dynaconf? Please give feedback Indices and tables genindex modindex search","title":"Home"},{"location":"#dynaconf-easy-and-powerful-settings-configuration-for-python","text":"Strict separation of settings from code (following 12-factor applications Guide). Define comprehensive default values. Store parameters in multiple file formats ( .toml , .json, .yaml, .ini and .py). Sensitive secrets like tokens and passwords can be stored in safe places like .secrets file or vault server. Parameters can optionally be stored in external services like Redis server. Simple feature flag system. Layered [environment] system. Environment variables can be used to override parameters. Support for .env files to automate the export of environment variables. Correct data types (even for environment variables). Have only one canonical settings module to rule all your instances. Drop in extension for Flask app.config object. Drop in extension for Django conf.settings object. Powerful \\$ dynaconf CLI to help you manage your settings via console. Customizable Validation System to ensure correct config parameters. Allow the change of dynamic parameters on the fly without the need to redeploy your application.","title":"Dynaconf - Easy and Powerful Settings Configuration for Python"},{"location":"#who-is-using-dynaconf","text":"Pulp Project - Django - (RedHat) Ansible Galaxy - Django - (RedHat) Insights QE (RedHat) CloudForms QE (RedHat) Seek AI & Catho Job boards - Flask - (on AI APIs) Quokka CMS - Flask iNNOVO Cloud GmbH Teraki ARA Records Ansible - Django Are you using Dynaconf? Please give feedback","title":"Who is using Dynaconf?"},{"location":"#indices-and-tables","text":"genindex modindex search","title":"Indices and tables"},{"location":"license/","text":"The MIT License (MIT) Copyright (c) 2015 Bruno Rocha Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#the-mit-license-mit","text":"","title":"The MIT License (MIT)"},{"location":"license/#copyright-c-2015-bruno-rocha","text":"Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"Copyright (c) 2015 Bruno Rocha"},{"location":"guides/accessing_values/","text":"Accessing parameters Dynaconf offers different ways to access settings parameters Assuming the following settings.toml file [default] host = \"server\" port = 5555 auth = {user=\"admin\", passwd=\"1234\"} As attributes (dot notation) Using dot notation settings.HOST Raises: AttributeError if not defined As dictionary [item] Using item access settings['PORT'] Raises: KeyError if not defined Default values (get) Using dict style get settings.get('TIMEOUT', 300) Returns the default (300) if not defined Using dotted-path lookup settings.get('AUTH.USER', 'anonymous') Returns the default ('anonymous') if not defined Explicitly disabling dotted-path lookup settings.get('AUTH.USER', dotted_lookup=False) Forcing type casting settings.as_int('PORT') Available casts: as_int as_float as_bool as_json Boxed values In Dynaconf values are Boxed, it means the dot notation can also be used to access dictionary members, example: settings.toml [default] mysql = {host=\"server.com\", port=3600, auth={user=\"admin\", passwd=1234}} You can now access from dynaconf import settings connect( host=settings.MYSQL.host, port=settings.MYSQL.port, username=settings.MYSQL.auth.user, passwd=settings.MYSQL.auth.get('passwd'), ) Export settings as a Python dictionary After exporting the settings to a python dictionary it is easy to use it to serialize as a JSON, YAML or any other format you may need. Programmatically from dynaconf import settings settings.as_dict() # a dict with only user defined values in current env settings.as_dict(env='production') # a dict with only user defined values in production env settings.as_dict(internal=True) # a dict with all values, user defined and dynaconf internal CLI (export to json) from your project root folder (generally the same place where you have .env or from where you call your scripts. dynaconf list -o path/to/file.json dynaconf list -e production -o path/to/file.json","title":"Accessing parameters"},{"location":"guides/accessing_values/#accessing-parameters","text":"Dynaconf offers different ways to access settings parameters Assuming the following settings.toml file [default] host = \"server\" port = 5555 auth = {user=\"admin\", passwd=\"1234\"}","title":"Accessing parameters"},{"location":"guides/accessing_values/#as-attributes-dot-notation","text":"Using dot notation settings.HOST Raises: AttributeError if not defined","title":"As attributes (dot notation)"},{"location":"guides/accessing_values/#as-dictionary-item","text":"Using item access settings['PORT'] Raises: KeyError if not defined","title":"As dictionary [item]"},{"location":"guides/accessing_values/#default-values-get","text":"Using dict style get settings.get('TIMEOUT', 300) Returns the default (300) if not defined Using dotted-path lookup settings.get('AUTH.USER', 'anonymous') Returns the default ('anonymous') if not defined Explicitly disabling dotted-path lookup settings.get('AUTH.USER', dotted_lookup=False)","title":"Default values (get)"},{"location":"guides/accessing_values/#forcing-type-casting","text":"settings.as_int('PORT') Available casts: as_int as_float as_bool as_json","title":"Forcing type casting"},{"location":"guides/accessing_values/#boxed-values","text":"In Dynaconf values are Boxed, it means the dot notation can also be used to access dictionary members, example: settings.toml [default] mysql = {host=\"server.com\", port=3600, auth={user=\"admin\", passwd=1234}} You can now access from dynaconf import settings connect( host=settings.MYSQL.host, port=settings.MYSQL.port, username=settings.MYSQL.auth.user, passwd=settings.MYSQL.auth.get('passwd'), )","title":"Boxed values"},{"location":"guides/accessing_values/#export-settings-as-a-python-dictionary","text":"After exporting the settings to a python dictionary it is easy to use it to serialize as a JSON, YAML or any other format you may need.","title":"Export settings as a Python dictionary"},{"location":"guides/accessing_values/#programmatically","text":"from dynaconf import settings settings.as_dict() # a dict with only user defined values in current env settings.as_dict(env='production') # a dict with only user defined values in production env settings.as_dict(internal=True) # a dict with all values, user defined and dynaconf internal","title":"Programmatically"},{"location":"guides/accessing_values/#cli-export-to-json","text":"from your project root folder (generally the same place where you have .env or from where you call your scripts. dynaconf list -o path/to/file.json dynaconf list -e production -o path/to/file.json","title":"CLI (export to json)"},{"location":"guides/advanced_usage/","text":"Advanced Usage Yeah Dynamic is part of the name of this library so you can do lots of things :) Customizing the settings object Sometimes you want to override settings for your existing Package or Framework lets say you have a conf module exposing a config object and used to do: from myprogram.conf import config Now you want to use Dynaconf, open that conf.py or conf/__init__.py and do: # coding: utf-8 from dynaconf import LazySettings config = LazySettings(ENVVAR_PREFIX_FOR_DYNACONF=\"MYPROGRAM\") Now you can use export MYPROGRAM_FOO=bar instead of DYNACONF_FOO=bar Module impersonation In some cases you may need to impersonate your legacy settings module for example you already have a program that does. from myprogram import settings and now you want to use dynaconf without the need to change your whole codebase. Go to your myprogram/settings.py and apply the module impersonation. import sys from dynaconf import LazySettings sys.modules[__name__] = LazySettings() the last line of above code will make the module to replace itself with a dynaconf instance in the first time it is imported. Switching working environments You can switch between existing environments using: from_env : ( recommended ) Will create a new settings instance pointing to defined env. setenv : Will set the existing instance to defined env. using_env : Context manager that will have defined env only inside its scope. from_env New in 2.1.0 Return a new isolated settings object pointing to specified env. Example of settings.toml:: [development] message = 'This is in dev' foo = 1 [other] message = 'this is in other env' bar = 2 Program:: >>> from dynaconf import settings >>> print(settings.MESSAGE) 'This is in dev' >>> print(settings.FOO) 1 >>> print(settings.BAR) AttributeError: settings object has no attribute 'BAR' Then you can use from_env : >>> print(settings.from_env('other').MESSAGE) 'This is in other env' >>> print(settings.from_env('other').BAR) 2 >>> print(settings.from_env('other').FOO) AttributeError: settings object has no attribute 'FOO' The existing settings object remains the same. >>> print(settings.MESSAGE) 'This is in dev' You can assign new settings objects to different envs like: development_settings = settings.from_env('development') other_settings = settings.from_env('other') And you can choose if the variables from different envs will be chained and overridden in a sequence: all_settings = settings.from_env('development', keep=True).from_env('other', keep=True) >>> print(all_settings.MESSAGE) 'This is in other env' >>> print(all_settings.FOO) 1 >>> print(all_settings.BAR) 2 The variables from [development] are loaded keeping pre-loaded values, then the variables from [other] are loaded keeping pre-loaded from [development] and overriding it. It is also possible to pass additional configuration variables to from_env method. new_settings = settings.from_env('production', keep=True, SETTINGS_FILE_FOR_DYNACONF='another_file_path.yaml') Then the new_settings will inherit all the variables from existing env and also load the another_file_path.yaml production env. setenv Will change in_place the env for the existing object. from dynaconf import settings settings.setenv('other') # now values comes from [other] section of config assert settings.MESSAGE == 'This is in other env' settings.setenv() # now working env are back to previous using_env Using context manager from dynaconf import settings with settings.using_env('other'): # now values comes from [other] section of config assert settings.MESSAGE == 'This is in other env' # existing settings back to normal after the context manager scope assert settings.MESSAGE == 'This is in dev' Populating objects New in 2.0.0 You can use dynaconf values to populate Python objects (intances). example: class Obj: ... then you can do: from dynaconf import settings # assume it has DEBUG=True and VALUE=42.1 obj = Obj() settings.populate_obj(obj) assert obj.DEBUG is True assert obj.VALUE == 42.1 Also you can specify only some keys: from dynaconf import settings # assume it has DEBUG=True and VALUE=42.1 obj = Obj() settings.populate_obj(obj, keys=['DEBUG']) assert obj.DEBUG is True # ok assert obj.VALUE == 42.1 # AttributeError Customizations It is possible to customize how your project will load settings, example: You want your users to customize a settings file defined in export PROJECTNAME_SETTINGS=/path/to/settings.toml and you want environment variables to be loaded from PROJECTNAME_VARNAME ENVVAR_PREFIX_FOR_DYNACONF = \"PROJECTNAME\" \"\"\"This defines which environment variable global prefix dynaconf will load That means that `export PROJECTNAME_FOO=1` will be loaded to `duanconf.settings.FOO On command line it is possible to check it with `dynaconf list -k foo`\"\"\" ENV_SWITCHER_FOR_DYNACONF='PROJECTNAME_ENV' \"\"\"By default it is DYNACONF_ENV, this is the envvar used to switch from development to production but with this settings your users can do `export PROJECT_ENV=production` (new in 2.0.0)\"\"\" ENVVAR_FOR_DYNACONF = \"PROJECTNAME_SETTINGS\" \"\"\"This defines which path dynaconf will look to load config files example: export PROJECTNAME_SETTINGS=/path/to/settings.toml and the format can be .ini, .json, .yaml or .toml e.g:: export PROJECTNAME_SETTINGS=settings.toml [default] FOO = 1 [development] FOO = 2 [production] FOO = 3 OR:: export PROJECTNAME_SETTINGS=settings.yaml default: foo: 1 development: foo: 2 production: foo: 3 It is also possible to pass a list of files:: export PROJECTNAME_SETTINGS=settings.toml,other_settings.yaml,another.json The variables will be cascaded in the defined order (last wins the precedence) The environment variables wins precedence over all! \"\"\" # load dynaconf settings = LazySettings( ENVVAR_PREFIX_FOR_DYNACONF=ENVVAR_PREFIX_FOR_DYNACONF, ENVVAR_FOR_DYNACONF=ENVVAR_FOR_DYNACONF. ENV_SWITCHER_FOR_DYNACONF=ENV_SWITCHER_FOR_DYNACONF ) Then the working environment can now be switched using export PROJECTNAME_ENV=production Exporting You can generate a file with current configs by calling dynaconf list -o /path/to/file.ext see more in cli You can also do that programmatically with: from dynaconf import loaders from dynaconf import settings from dynaconf.utils.boxing import DynaBox # generates a dict with all the keys for `development` env data = settings.as_dict(env='development') # writes to a file, the format is inferred by extension # can be .yaml, .toml, .ini, .json, .py loaders.write('/path/to/file.yaml', DynaBox(data).to_dict(), merge=False, env='development') Preloading files New in 2.2.0 Useful for plugin based apps. from dynaconf import LazySettings settings = LazySettings( PRELOAD_FOR_DYNACONF=[\"/path/*\", \"other/settings.toml\"], # <-- Loaded first SETTINGS_FILE_FOR_DYNACONF=\"/etc/foo/settings.py\", # <-- Loaded second (the main file) INCLUDES_FOR_DYNACONF=[\"other.module.settings\", \"other/settings.yaml\"] # <-- Loaded at the end )","title":"Advanced Usage"},{"location":"guides/advanced_usage/#advanced-usage","text":"Yeah Dynamic is part of the name of this library so you can do lots of things :)","title":"Advanced Usage"},{"location":"guides/advanced_usage/#customizing-the-settings-object","text":"Sometimes you want to override settings for your existing Package or Framework lets say you have a conf module exposing a config object and used to do: from myprogram.conf import config Now you want to use Dynaconf, open that conf.py or conf/__init__.py and do: # coding: utf-8 from dynaconf import LazySettings config = LazySettings(ENVVAR_PREFIX_FOR_DYNACONF=\"MYPROGRAM\") Now you can use export MYPROGRAM_FOO=bar instead of DYNACONF_FOO=bar","title":"Customizing the settings object"},{"location":"guides/advanced_usage/#module-impersonation","text":"In some cases you may need to impersonate your legacy settings module for example you already have a program that does. from myprogram import settings and now you want to use dynaconf without the need to change your whole codebase. Go to your myprogram/settings.py and apply the module impersonation. import sys from dynaconf import LazySettings sys.modules[__name__] = LazySettings() the last line of above code will make the module to replace itself with a dynaconf instance in the first time it is imported.","title":"Module impersonation"},{"location":"guides/advanced_usage/#switching-working-environments","text":"You can switch between existing environments using: from_env : ( recommended ) Will create a new settings instance pointing to defined env. setenv : Will set the existing instance to defined env. using_env : Context manager that will have defined env only inside its scope.","title":"Switching working environments"},{"location":"guides/advanced_usage/#from_env","text":"New in 2.1.0 Return a new isolated settings object pointing to specified env. Example of settings.toml:: [development] message = 'This is in dev' foo = 1 [other] message = 'this is in other env' bar = 2 Program:: >>> from dynaconf import settings >>> print(settings.MESSAGE) 'This is in dev' >>> print(settings.FOO) 1 >>> print(settings.BAR) AttributeError: settings object has no attribute 'BAR' Then you can use from_env : >>> print(settings.from_env('other').MESSAGE) 'This is in other env' >>> print(settings.from_env('other').BAR) 2 >>> print(settings.from_env('other').FOO) AttributeError: settings object has no attribute 'FOO' The existing settings object remains the same. >>> print(settings.MESSAGE) 'This is in dev' You can assign new settings objects to different envs like: development_settings = settings.from_env('development') other_settings = settings.from_env('other') And you can choose if the variables from different envs will be chained and overridden in a sequence: all_settings = settings.from_env('development', keep=True).from_env('other', keep=True) >>> print(all_settings.MESSAGE) 'This is in other env' >>> print(all_settings.FOO) 1 >>> print(all_settings.BAR) 2 The variables from [development] are loaded keeping pre-loaded values, then the variables from [other] are loaded keeping pre-loaded from [development] and overriding it. It is also possible to pass additional configuration variables to from_env method. new_settings = settings.from_env('production', keep=True, SETTINGS_FILE_FOR_DYNACONF='another_file_path.yaml') Then the new_settings will inherit all the variables from existing env and also load the another_file_path.yaml production env.","title":"from_env"},{"location":"guides/advanced_usage/#setenv","text":"Will change in_place the env for the existing object. from dynaconf import settings settings.setenv('other') # now values comes from [other] section of config assert settings.MESSAGE == 'This is in other env' settings.setenv() # now working env are back to previous","title":"setenv"},{"location":"guides/advanced_usage/#using_env","text":"Using context manager from dynaconf import settings with settings.using_env('other'): # now values comes from [other] section of config assert settings.MESSAGE == 'This is in other env' # existing settings back to normal after the context manager scope assert settings.MESSAGE == 'This is in dev'","title":"using_env"},{"location":"guides/advanced_usage/#populating-objects","text":"New in 2.0.0 You can use dynaconf values to populate Python objects (intances). example: class Obj: ... then you can do: from dynaconf import settings # assume it has DEBUG=True and VALUE=42.1 obj = Obj() settings.populate_obj(obj) assert obj.DEBUG is True assert obj.VALUE == 42.1 Also you can specify only some keys: from dynaconf import settings # assume it has DEBUG=True and VALUE=42.1 obj = Obj() settings.populate_obj(obj, keys=['DEBUG']) assert obj.DEBUG is True # ok assert obj.VALUE == 42.1 # AttributeError","title":"Populating objects"},{"location":"guides/advanced_usage/#customizations","text":"It is possible to customize how your project will load settings, example: You want your users to customize a settings file defined in export PROJECTNAME_SETTINGS=/path/to/settings.toml and you want environment variables to be loaded from PROJECTNAME_VARNAME ENVVAR_PREFIX_FOR_DYNACONF = \"PROJECTNAME\" \"\"\"This defines which environment variable global prefix dynaconf will load That means that `export PROJECTNAME_FOO=1` will be loaded to `duanconf.settings.FOO On command line it is possible to check it with `dynaconf list -k foo`\"\"\" ENV_SWITCHER_FOR_DYNACONF='PROJECTNAME_ENV' \"\"\"By default it is DYNACONF_ENV, this is the envvar used to switch from development to production but with this settings your users can do `export PROJECT_ENV=production` (new in 2.0.0)\"\"\" ENVVAR_FOR_DYNACONF = \"PROJECTNAME_SETTINGS\" \"\"\"This defines which path dynaconf will look to load config files example: export PROJECTNAME_SETTINGS=/path/to/settings.toml and the format can be .ini, .json, .yaml or .toml e.g:: export PROJECTNAME_SETTINGS=settings.toml [default] FOO = 1 [development] FOO = 2 [production] FOO = 3 OR:: export PROJECTNAME_SETTINGS=settings.yaml default: foo: 1 development: foo: 2 production: foo: 3 It is also possible to pass a list of files:: export PROJECTNAME_SETTINGS=settings.toml,other_settings.yaml,another.json The variables will be cascaded in the defined order (last wins the precedence) The environment variables wins precedence over all! \"\"\" # load dynaconf settings = LazySettings( ENVVAR_PREFIX_FOR_DYNACONF=ENVVAR_PREFIX_FOR_DYNACONF, ENVVAR_FOR_DYNACONF=ENVVAR_FOR_DYNACONF. ENV_SWITCHER_FOR_DYNACONF=ENV_SWITCHER_FOR_DYNACONF ) Then the working environment can now be switched using export PROJECTNAME_ENV=production","title":"Customizations"},{"location":"guides/advanced_usage/#exporting","text":"You can generate a file with current configs by calling dynaconf list -o /path/to/file.ext see more in cli You can also do that programmatically with: from dynaconf import loaders from dynaconf import settings from dynaconf.utils.boxing import DynaBox # generates a dict with all the keys for `development` env data = settings.as_dict(env='development') # writes to a file, the format is inferred by extension # can be .yaml, .toml, .ini, .json, .py loaders.write('/path/to/file.yaml', DynaBox(data).to_dict(), merge=False, env='development')","title":"Exporting"},{"location":"guides/advanced_usage/#preloading-files","text":"New in 2.2.0 Useful for plugin based apps. from dynaconf import LazySettings settings = LazySettings( PRELOAD_FOR_DYNACONF=[\"/path/*\", \"other/settings.toml\"], # <-- Loaded first SETTINGS_FILE_FOR_DYNACONF=\"/etc/foo/settings.py\", # <-- Loaded second (the main file) INCLUDES_FOR_DYNACONF=[\"other.module.settings\", \"other/settings.yaml\"] # <-- Loaded at the end )","title":"Preloading files"},{"location":"guides/alternatives/","text":"Alternatives Dynaconf tries to define standard and good practices for config and aims to have flexibility and 100% of test coverage for Python 3.x. Dynaconf implements the best parts of the alternatives below, to implement Dynaconf lots of configuration libraries have been tested and studied. But if you are still looking for something different take a look at the following excellent alternatives. Python Decouple PrettyConf Profig Everett Configman PyMLconf AnyConfig Config Conman","title":"Alternatives"},{"location":"guides/alternatives/#alternatives","text":"Dynaconf tries to define standard and good practices for config and aims to have flexibility and 100% of test coverage for Python 3.x. Dynaconf implements the best parts of the alternatives below, to implement Dynaconf lots of configuration libraries have been tested and studied. But if you are still looking for something different take a look at the following excellent alternatives. Python Decouple PrettyConf Profig Everett Configman PyMLconf AnyConfig Config Conman","title":"Alternatives"},{"location":"guides/cli/","text":"The dynaconf CLI The $ dynaconf cli provides some useful commands IMPORTANT if you are using Flask Extension the env var FLASK_APP must be defined to use the CLI, and if using Django Extension the DJANGO_SETTINGS_MODULE must be defined. dynaconf --help Usage: dynaconf [OPTIONS] COMMAND [ARGS]... Dynaconf - Command Line Interface Options: --version Show dynaconf version --docs Open documentation in browser --banner Show awesome banner -i, --instance TEXT Custom instance of LazySettings --help Show this message and exit. Commands: init Inits a dynaconf project By default it... list Lists all defined config values write Writes data to specific source validate Validates based on dynaconf_validators.toml file dynaconf init Use init to easily configure your application configuration, once dynaconf is installed go to the root directory of your application and run: creates settings files in current directory $ dynaconf init -v key=value -v foo=bar -s token=1234 -e production The above command will create in the current directory settings.toml [default] KEY = \"default\" FOO = \"default\" [production] KEY = \"value\" FOO = \"bar\" also .secrets.toml [default] TOKEN = \"default\" [production] TOKEN = \"1234\" The command will also create a .env setting the working environment to [production] ENV_FOR_DYNACONF=\"PRODUCTION\" And will include the .secrets.toml in the .gitignore # Ignore dynaconf secret files .secrets.* For sensitive data in production is recommended using Vault Server Usage: dynaconf init [OPTIONS] Inits a dynaconf project By default it creates a settings.toml and a .secrets.toml for [default|development|staging|testing|production|global] envs. The format of the files can be changed passing --format=yaml|json|ini|py. This command must run on the project's root folder or you must pass --path=/myproject/root/folder. If you want to have a .env created with the ENV defined there e.g: `ENV_FOR_DYNACONF=production` just pass --env=production and then .env will also be created and the env defined to production. Options: -f, --format [ini|toml|yaml|json|py|env] -p, --path TEXT defaults to current directory -e, --env TEXT Sets the working env in `.env` file -v, --vars TEXT extra values to write to settings file file e.g: `dynaconf init -v NAME=foo -v X=2 -s, --secrets TEXT secret key values to be written in .secrets e.g: `dynaconf init -s TOKEN=kdslmflds --wg / --no-wg -y --django TEXT --help Show this message and exit. dynaconf list List all defined parameters and optionally export to a json file. Usage: dynaconf list [OPTIONS] Lists all user defined config values and if `--all` is passed it also shows dynaconf internal variables. Options: -e, --env TEXT Filters the env to get the values -k, --key TEXT Filters a single key -m, --more Pagination more|less style -l, --loader TEXT a loader identifier to filter e.g: toml|yaml -a, --all show dynaconf internal settings? -o, --output FILE Filepath to write the listed values as json --output-flat Output file is flat (do not include [env] name) --help Show this message and exit. Exporting current environment as a file dynaconf list -o path/to/file.yaml The above command will export all the items showed by dynaconf list to the desired format which is inferred by the -o file extension, supported formats yaml, toml, ini, json, py When using py you may want a flat output (without being nested inside the env key) dynaconf list -o path/to/file.py --output-flat dynaconf write Usage: dynaconf write [OPTIONS] TO Writes data to specific source Options: -v, --vars TEXT key values to be written e.g: `dynaconf write toml -e NAME=foo -e X=2 -s, --secrets TEXT secret key values to be written in .secrets e.g: `dynaconf write toml -s TOKEN=kdslmflds -s X=2 -p, --path TEXT defaults to current directory/settings.{ext} -e, --env TEXT env to write to defaults to DEVELOPMENT for files for external sources like Redis and Vault it will be DYNACONF or the value set in $ENVVAR_PREFIX_FOR_DYNACONF -y --help Show this message and exit. dynaconf validate NEW in 1.0.1 Starting on version 1.0.1 it is possible to define validators in TOML file called dynaconf_validators.toml placed in the same fodler as your settings files. dynaconf_validators.toml equivalent to program above [default] version = {must_exist=true} name = {must_exist=true} password = {must_exist=false} [default.age] must_exist = true lte = 30 gte = 10 [production] project = {eq=\"hello_world\"} Then to fire the validation use: $ dynaconf validate If validates it returns status 0 (success) and this command can be called in your CI/CD/Deploy jobs. dynaconf --version returns dynaconf version $ dynaconf --version 1.0.0 dynaconf --docs Opens Dynaconf documentation in browser dynaconf --banner Prints this awesome ascii made banner in the console :) $ dynaconf --banner \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u255a\u2588\u2588\u2557 \u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2551 \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551 \u255a\u2588\u2588\u2554\u255d \u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2551 \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551\u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d Learn more at: http://github.com/rochacbruno/dynaconf","title":"The dynaconf CLI"},{"location":"guides/cli/#the-dynaconf-cli","text":"The $ dynaconf cli provides some useful commands IMPORTANT if you are using Flask Extension the env var FLASK_APP must be defined to use the CLI, and if using Django Extension the DJANGO_SETTINGS_MODULE must be defined.","title":"The dynaconf CLI"},{"location":"guides/cli/#dynaconf-help","text":"Usage: dynaconf [OPTIONS] COMMAND [ARGS]... Dynaconf - Command Line Interface Options: --version Show dynaconf version --docs Open documentation in browser --banner Show awesome banner -i, --instance TEXT Custom instance of LazySettings --help Show this message and exit. Commands: init Inits a dynaconf project By default it... list Lists all defined config values write Writes data to specific source validate Validates based on dynaconf_validators.toml file","title":"dynaconf --help"},{"location":"guides/cli/#dynaconf-init","text":"Use init to easily configure your application configuration, once dynaconf is installed go to the root directory of your application and run: creates settings files in current directory $ dynaconf init -v key=value -v foo=bar -s token=1234 -e production The above command will create in the current directory settings.toml [default] KEY = \"default\" FOO = \"default\" [production] KEY = \"value\" FOO = \"bar\" also .secrets.toml [default] TOKEN = \"default\" [production] TOKEN = \"1234\" The command will also create a .env setting the working environment to [production] ENV_FOR_DYNACONF=\"PRODUCTION\" And will include the .secrets.toml in the .gitignore # Ignore dynaconf secret files .secrets.* For sensitive data in production is recommended using Vault Server Usage: dynaconf init [OPTIONS] Inits a dynaconf project By default it creates a settings.toml and a .secrets.toml for [default|development|staging|testing|production|global] envs. The format of the files can be changed passing --format=yaml|json|ini|py. This command must run on the project's root folder or you must pass --path=/myproject/root/folder. If you want to have a .env created with the ENV defined there e.g: `ENV_FOR_DYNACONF=production` just pass --env=production and then .env will also be created and the env defined to production. Options: -f, --format [ini|toml|yaml|json|py|env] -p, --path TEXT defaults to current directory -e, --env TEXT Sets the working env in `.env` file -v, --vars TEXT extra values to write to settings file file e.g: `dynaconf init -v NAME=foo -v X=2 -s, --secrets TEXT secret key values to be written in .secrets e.g: `dynaconf init -s TOKEN=kdslmflds --wg / --no-wg -y --django TEXT --help Show this message and exit.","title":"dynaconf init"},{"location":"guides/cli/#dynaconf-list","text":"List all defined parameters and optionally export to a json file. Usage: dynaconf list [OPTIONS] Lists all user defined config values and if `--all` is passed it also shows dynaconf internal variables. Options: -e, --env TEXT Filters the env to get the values -k, --key TEXT Filters a single key -m, --more Pagination more|less style -l, --loader TEXT a loader identifier to filter e.g: toml|yaml -a, --all show dynaconf internal settings? -o, --output FILE Filepath to write the listed values as json --output-flat Output file is flat (do not include [env] name) --help Show this message and exit.","title":"dynaconf list"},{"location":"guides/cli/#exporting-current-environment-as-a-file","text":"dynaconf list -o path/to/file.yaml The above command will export all the items showed by dynaconf list to the desired format which is inferred by the -o file extension, supported formats yaml, toml, ini, json, py When using py you may want a flat output (without being nested inside the env key) dynaconf list -o path/to/file.py --output-flat","title":"Exporting current environment as a file"},{"location":"guides/cli/#dynaconf-write","text":"Usage: dynaconf write [OPTIONS] TO Writes data to specific source Options: -v, --vars TEXT key values to be written e.g: `dynaconf write toml -e NAME=foo -e X=2 -s, --secrets TEXT secret key values to be written in .secrets e.g: `dynaconf write toml -s TOKEN=kdslmflds -s X=2 -p, --path TEXT defaults to current directory/settings.{ext} -e, --env TEXT env to write to defaults to DEVELOPMENT for files for external sources like Redis and Vault it will be DYNACONF or the value set in $ENVVAR_PREFIX_FOR_DYNACONF -y --help Show this message and exit.","title":"dynaconf write"},{"location":"guides/cli/#dynaconf-validate","text":"NEW in 1.0.1 Starting on version 1.0.1 it is possible to define validators in TOML file called dynaconf_validators.toml placed in the same fodler as your settings files. dynaconf_validators.toml equivalent to program above [default] version = {must_exist=true} name = {must_exist=true} password = {must_exist=false} [default.age] must_exist = true lte = 30 gte = 10 [production] project = {eq=\"hello_world\"} Then to fire the validation use: $ dynaconf validate If validates it returns status 0 (success) and this command can be called in your CI/CD/Deploy jobs.","title":"dynaconf validate"},{"location":"guides/cli/#dynaconf-version","text":"returns dynaconf version $ dynaconf --version 1.0.0","title":"dynaconf --version"},{"location":"guides/cli/#dynaconf-docs","text":"Opens Dynaconf documentation in browser","title":"dynaconf --docs"},{"location":"guides/cli/#dynaconf-banner","text":"Prints this awesome ascii made banner in the console :) $ dynaconf --banner \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u255a\u2588\u2588\u2557 \u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2551 \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551 \u255a\u2588\u2588\u2554\u255d \u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2551 \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551\u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d Learn more at: http://github.com/rochacbruno/dynaconf","title":"dynaconf --banner"},{"location":"guides/configuration/","text":"Configuring Dynaconf Dynaconf can be configured through variables suffixed with _FOR_DYNACONF those settings can be used to change various dynaconf defaults and behaviors. Each config variable here can be exported to environment variables or wrote to .env file, example: export DEBUG_LEVEL_FOR_DYNACONF=DEBUG export ENV_FOR_DYNACONF=production Or when using your own Dynaconf instance you can pass as parameters directly: from dynaconf import LazySettings settings = LazySettings( DEBUG_LEVEL_FOR_DYNACONF='DEBUG', ENVVAR_PREFIX_FOR_DYNACONF='MYPROGRAM', ENVVAR_FOR_DYNACONF='MYPROGRAM_SETTINGS', ) It can also be passed as parameters to extensions like FlaskDynaconf or set in the DjangoDynaconf on settings.py file. Configuration options NOTE: Append _FOR_DYNACONF when exporting these variables. .. csv-table:: :header: \"Variable\", \"Type\", \"Usage\", \"default\", \"example\" :widths: 15, 15, 50, 30, 50 :delim: | AUTO_CAST | bool | *@casting* like *@int* is parsed. | true | AUTO_CAST_FOR_DYNACONF=false COMMENTJSON_ENABLED | bool | Enable comments in json files. | false (req:*pip install commentjson*) | COMMENTJSON_ENABLED_FOR_DYNACONF=true CORE_LOADERS | list | A list of enabled core loaders. | [\u2018YAML\u2019, \u2018TOML\u2019, \u2018INI\u2019, \u2018JSON\u2019, \u2018PY\u2019] | CORE_LOADERS_FOR_DYNACONF=\u2019[\u201cYAML\u201d, \u201cJSON\u201d]\u2019 or \u2018[]\u2019 DEBUG_LEVEL | str | Upper case logging level. | NOTSET | DEBUG_LEVEL_FOR_DYNACONF=DEBUG DOTENV_OVERRIDE | bool | *.env* should override the exported envvars. | false | DOTENV_OVERRIDE_FOR_DYNACONF=true DOTENV_PATH | str | Defines where to look for *.env* file. | PROJECT_ROOT | DOTENV_PATH_FOR_DYNACONF=\u201d/tmp/.env\u201d ENCODING | str | Encoding to read settings files. | utf-8 | ENCODING_FOR_DYNACONF=\u201dcp1252\u201d ENV | str | Working environment. | \u201cdevelopment\u201d | ENV_FOR_DYNACONF=production *FORCE_ENV | str | Force the working environment | None | FORCE_ENV_FOR_DYNACONF=other ENV_SWITCHER | str | Variable used to change working env. | ENV_FOR_DYNACONF | ENV_SWITCHER_FOR_DYNACONF=MYPROGRAM_ENV ENVVAR | str | The envvar which holds the list of settings files. | \u2018SETTINGS_FILE_FOR_DYNACONF\u2019 | ENVVAR_FOR_DYNACONF=MYPROGRAM_SETTINGS ENVVAR_PREFIX | str | Prefix for exporting parameters as env vars. Example: If your program is called *MYPROGRAM* you may want users to use *MYPROGRAM_FOO=bar* instead of *DYNACONF_FOO=bar* on envvars. | \u201cDYNACONF\u201d | ENVVAR_PREFIX_FOR_DYNACONF=MYPROGRAM (loads MYPROGRAM_VAR) ENVVAR_PREFIX_FOR_DYNACONF=\u2019\u2019 (loads _VAR) ENVVAR_PREFIX_FOR_DYNACONF=false (loads VAR) FRESH_VARS | list | A list of vars to be re-loaded on every access. | [] | FRESH_VARS_FOR_DYNACONF=[\u201cHOST\u201d, \u201cPORT\u201d] INCLUDES | list | A list of paths or a glob to load can be a toml-like list, or sep by , or ; | [] | INCLUDES_FOR_DYNACONF=\u201d[\u2018path1.ext\u2019, \u2018folder/*\u2019]\u201d INCLUDES_FOR_DYNACONF=\u201dpath1.toml;path2.toml\u201d INCLUDES_FOR_DYNACONF=\u201dpath1.toml,path2.toml\u201d INCLUDES_FOR_DYNACONF=\u201dsingle_path.toml\u201d INCLUDES_FOR_DYNACONF=\u201dsingle_path/glob/.toml\u201d INSTANCE **used only by** *$dynaconf** *cli*. | str | Custom instance of LazySettings Must be an importable Python module. | None | INSTANCE_FOR_DYNACONF=myapp.settings LOADERS | list | A list of enabled external loaders. | [\u2018dynaconf.loaders.env_loader\u2019] | LOADERS_FOR_DYNACONF=\u2019[\u2018module.mycustomloader\u2019, \u2026]\u2019 MERGE_ENABLED | bool | A bool to activate the global merge feature | False | MERGE_ENABLED_FOR_DYNACONF=1 NESTED_SEPARATOR | str | Separator for nested assignment like `export DYNACONF_DATABASES__NAME='foo'` | `__` double underline | NESTED_SEPARATOR_FOR_DYNACONF='___' PRELOAD | list | A list of paths or glob to be pre-loaded before main settings file. | [] | PRELOAD_FOR_DYNACONF=\"['path1.ext', 'folder/*']\" REDIS_DB | int | Redis DB. | 0 | REDIS_DB_FOR_DYNACONF=1 REDIS_ENABLED | bool | Redis loader is enabled. | false | REDIS_ENABLED_FOR_DYNACONF=true REDIS_HOST | str | Redis server address. | localhost | REDIS_HOST_FOR_DYNACONF=\u201dlocalhost\u201d REDIS_PORT | int | Redis port. | 6379 | REDIS_PORT_FOR_DYNACONF=8899 ROOT_PATH | str | Directory to look for settings files. This path is the base to search for files defined in *SETTINGS_FILE*. Dynaconf will also search for files in a relative *config/* subfolder if exists. | *None*. If set Dynaconf will look this path first before it starts to search for file in the other locations. see: `<usage.md#the-settings-files>`_ | ROOT_PATH_FOR_DYNACONF=\u201d/my/custom/absolute/path/\u201d SECRETS | str | Path to aditional secrets file to be loaded. | None | SECRETS_FOR_DYNACONF=/var/jenkins/settings_ci.toml SETTINGS_FILE | list, str | List of files to load. | List of all supportes files: *settings.{py,toml,yaml,ini,conf,json} .secrets.{py,toml,yaml,ini,conf,json}*. This var name can be replaced by: *ENVVAR_FOR_DYNACONF=MYPROGRAM_SETTINGS* | SETTINGS_FILE_FOR_DYNACONF=\u201dmyconfig.toml\u201d SETTINGS_FILE_FOR_DYNACONF=\u201d[\u2018conf.toml\u2019,\u2019settings.yaml\u2019]\u201d SETTINGS_FILE_FOR_DYNACONF=\u201dconf.toml,settings.yaml\u201d SETTINGS_FILE_FOR_DYNACONF=\u201dconf.toml;settings.yaml\u201d MYPROGRAM_SETTINGS=\u201dconf.toml,settings.yaml\u201d SILENT_ERRORS | bool | Loading errors should be silenced. | true | SILENT_ERRORS_FOR_DYNACONF=false SKIP_FILES | list | Files to skip/ignore if found on search tree. | [] | SKIP_FILES_FOR_DYNACONF=\u201d[\u2018/absolute/path/to/file.ext\u2019]\u201d VAULT_ALLOW_REDIRECTS | bool | Vault allow redirects. | None | VAULT_ALLOW_REDIRECTS_FOR_DYNACONF=false VAULT_CERT | str | Vault cert/pem file path. | None | VAULT_CERT_FOR_DYNACONF=\u201d~/.ssh/key.pem\u201d VAULT_ENABLED | bool | Vault server is enabled. | false | VAULT_ENABLED_FOR_DYNACONF=true VAULT_HOST | str | Vault host. | localhost | VAULT_HOST_FOR_DYNACONF=\u201dserver\u201d VAULT_PATH | str | Vault path to the configuration. | None | VAULT_PATH_FOR_DYNACONF=\u201dsecret_data\u201d VAULT_PORT | str | Vault port. | 8200 | VAULT_PORT_FOR_DYNACONF=\u201d2800\u201d VAULT_PROXIES | dict | Vault proxies. | None | VAULT_PROXIES_FOR_DYNACONF={http=\u201dhttp:/localhost:3128/\u201d} VAULT_ROLE_ID | str | Vault Role ID. | None | VAULT_ROLE_ID_FOR_DYNACONF=\u201dsome-role-id\u201d VAULT_SCHEME | str | Vault scheme. | http | VAULT_SCHEME_FOR_DYNACONF=\u201dhttps\u201d VAULT_SECRET_ID | str | Vault Secret ID. | None | VAULT_SECRET_ID_FOR_DYNACONF=\u201dsome-secret-id\u201d VAULT_TIMEOUT | int | Vault timeout in seconds. | None | VAULT_TIMEOUT_FOR_DYNACONF=60 VAULT_TOKEN | str | Vault token. | None | VAULT_TOKEN_FOR_DYNACONF=\u201dmyroot\u201d VAULT_URL | str | Vault URL. | http:// localhost :8200 | VAULT_URL_FOR_DYNACONF=\u201dhttp://server/8200\u201d VAULT_VERIFY | bool | Vault should verify. | None | VAULT_VERIFY_FOR_DYNACONF=true YAML_LOADER | str | yaml method name {safe,full,unsafe}_load. | safe_load | YAML_LOADER_FOR_DYNACONF=unsafe_load Internal use variables FORCE_ENV_FOR_DYNACONF: This variable exists to support the from_env method, the crontib extensions and to use for testing. Deprecated options Some configuration options has been deprecated and replaced with a new name, we try to make it without breaking backwards compatibility with old version, but you may receive a warning if use: PROJECT_ROOT replaced by ROOT_PATH_FOR_DYNACONF PROJECT_ROOT_FOR_DYNACONF replaced by ROOT_PATH_FOR_DYNACONF DYNACONF_NAMESPACE replaced by ENV_FOR_DYNACONF NAMESPACE_FOR_DYNACONF replaced by ENV_FOR_DYNACONF BASE_NAMESPACE_FOR_DYNACONF replaced by DEFAULT_ENV_FOR_DYNACONF DYNACONF_SETTINGS_MODULE replaced by SETTINGS_FILE_FOR_DYNACONF DYNACONF_SETTINGS replaced by SETTINGS_FILE_FOR_DYNACONF SETTINGS_MODULE replaced by SETTINGS_FILE_FOR_DYNACONF DYNACONF_SILENT_ERRORS replaced by SILENT_ERRORS_FOR_DYNACONF DYNACONF_ALWAYS_FRESH_VARS replaced by FRESH_VARS_FOR_DYNACONF GLOBAL_ENV_FOR_DYNACONF replaced by ENVVAR_PREFIX_FOR_DYNACONF SETTINGS_MODULE_FOR_DYNACONF replaced by SETTINGS_FILE_FOR_DYNACONF .. autoclass:: dynaconf.default_settings :show-inheritance:","title":"Configuring Dynacon"},{"location":"guides/configuration/#configuring-dynaconf","text":"Dynaconf can be configured through variables suffixed with _FOR_DYNACONF those settings can be used to change various dynaconf defaults and behaviors. Each config variable here can be exported to environment variables or wrote to .env file, example: export DEBUG_LEVEL_FOR_DYNACONF=DEBUG export ENV_FOR_DYNACONF=production Or when using your own Dynaconf instance you can pass as parameters directly: from dynaconf import LazySettings settings = LazySettings( DEBUG_LEVEL_FOR_DYNACONF='DEBUG', ENVVAR_PREFIX_FOR_DYNACONF='MYPROGRAM', ENVVAR_FOR_DYNACONF='MYPROGRAM_SETTINGS', ) It can also be passed as parameters to extensions like FlaskDynaconf or set in the DjangoDynaconf on settings.py file.","title":"Configuring Dynaconf"},{"location":"guides/configuration/#configuration-options","text":"NOTE: Append _FOR_DYNACONF when exporting these variables. .. csv-table:: :header: \"Variable\", \"Type\", \"Usage\", \"default\", \"example\" :widths: 15, 15, 50, 30, 50 :delim: | AUTO_CAST | bool | *@casting* like *@int* is parsed. | true | AUTO_CAST_FOR_DYNACONF=false COMMENTJSON_ENABLED | bool | Enable comments in json files. | false (req:*pip install commentjson*) | COMMENTJSON_ENABLED_FOR_DYNACONF=true CORE_LOADERS | list | A list of enabled core loaders. | [\u2018YAML\u2019, \u2018TOML\u2019, \u2018INI\u2019, \u2018JSON\u2019, \u2018PY\u2019] | CORE_LOADERS_FOR_DYNACONF=\u2019[\u201cYAML\u201d, \u201cJSON\u201d]\u2019 or \u2018[]\u2019 DEBUG_LEVEL | str | Upper case logging level. | NOTSET | DEBUG_LEVEL_FOR_DYNACONF=DEBUG DOTENV_OVERRIDE | bool | *.env* should override the exported envvars. | false | DOTENV_OVERRIDE_FOR_DYNACONF=true DOTENV_PATH | str | Defines where to look for *.env* file. | PROJECT_ROOT | DOTENV_PATH_FOR_DYNACONF=\u201d/tmp/.env\u201d ENCODING | str | Encoding to read settings files. | utf-8 | ENCODING_FOR_DYNACONF=\u201dcp1252\u201d ENV | str | Working environment. | \u201cdevelopment\u201d | ENV_FOR_DYNACONF=production *FORCE_ENV | str | Force the working environment | None | FORCE_ENV_FOR_DYNACONF=other ENV_SWITCHER | str | Variable used to change working env. | ENV_FOR_DYNACONF | ENV_SWITCHER_FOR_DYNACONF=MYPROGRAM_ENV ENVVAR | str | The envvar which holds the list of settings files. | \u2018SETTINGS_FILE_FOR_DYNACONF\u2019 | ENVVAR_FOR_DYNACONF=MYPROGRAM_SETTINGS ENVVAR_PREFIX | str | Prefix for exporting parameters as env vars. Example: If your program is called *MYPROGRAM* you may want users to use *MYPROGRAM_FOO=bar* instead of *DYNACONF_FOO=bar* on envvars. | \u201cDYNACONF\u201d | ENVVAR_PREFIX_FOR_DYNACONF=MYPROGRAM (loads MYPROGRAM_VAR) ENVVAR_PREFIX_FOR_DYNACONF=\u2019\u2019 (loads _VAR) ENVVAR_PREFIX_FOR_DYNACONF=false (loads VAR) FRESH_VARS | list | A list of vars to be re-loaded on every access. | [] | FRESH_VARS_FOR_DYNACONF=[\u201cHOST\u201d, \u201cPORT\u201d] INCLUDES | list | A list of paths or a glob to load can be a toml-like list, or sep by , or ; | [] | INCLUDES_FOR_DYNACONF=\u201d[\u2018path1.ext\u2019, \u2018folder/*\u2019]\u201d INCLUDES_FOR_DYNACONF=\u201dpath1.toml;path2.toml\u201d INCLUDES_FOR_DYNACONF=\u201dpath1.toml,path2.toml\u201d INCLUDES_FOR_DYNACONF=\u201dsingle_path.toml\u201d INCLUDES_FOR_DYNACONF=\u201dsingle_path/glob/.toml\u201d INSTANCE **used only by** *$dynaconf** *cli*. | str | Custom instance of LazySettings Must be an importable Python module. | None | INSTANCE_FOR_DYNACONF=myapp.settings LOADERS | list | A list of enabled external loaders. | [\u2018dynaconf.loaders.env_loader\u2019] | LOADERS_FOR_DYNACONF=\u2019[\u2018module.mycustomloader\u2019, \u2026]\u2019 MERGE_ENABLED | bool | A bool to activate the global merge feature | False | MERGE_ENABLED_FOR_DYNACONF=1 NESTED_SEPARATOR | str | Separator for nested assignment like `export DYNACONF_DATABASES__NAME='foo'` | `__` double underline | NESTED_SEPARATOR_FOR_DYNACONF='___' PRELOAD | list | A list of paths or glob to be pre-loaded before main settings file. | [] | PRELOAD_FOR_DYNACONF=\"['path1.ext', 'folder/*']\" REDIS_DB | int | Redis DB. | 0 | REDIS_DB_FOR_DYNACONF=1 REDIS_ENABLED | bool | Redis loader is enabled. | false | REDIS_ENABLED_FOR_DYNACONF=true REDIS_HOST | str | Redis server address. | localhost | REDIS_HOST_FOR_DYNACONF=\u201dlocalhost\u201d REDIS_PORT | int | Redis port. | 6379 | REDIS_PORT_FOR_DYNACONF=8899 ROOT_PATH | str | Directory to look for settings files. This path is the base to search for files defined in *SETTINGS_FILE*. Dynaconf will also search for files in a relative *config/* subfolder if exists. | *None*. If set Dynaconf will look this path first before it starts to search for file in the other locations. see: `<usage.md#the-settings-files>`_ | ROOT_PATH_FOR_DYNACONF=\u201d/my/custom/absolute/path/\u201d SECRETS | str | Path to aditional secrets file to be loaded. | None | SECRETS_FOR_DYNACONF=/var/jenkins/settings_ci.toml SETTINGS_FILE | list, str | List of files to load. | List of all supportes files: *settings.{py,toml,yaml,ini,conf,json} .secrets.{py,toml,yaml,ini,conf,json}*. This var name can be replaced by: *ENVVAR_FOR_DYNACONF=MYPROGRAM_SETTINGS* | SETTINGS_FILE_FOR_DYNACONF=\u201dmyconfig.toml\u201d SETTINGS_FILE_FOR_DYNACONF=\u201d[\u2018conf.toml\u2019,\u2019settings.yaml\u2019]\u201d SETTINGS_FILE_FOR_DYNACONF=\u201dconf.toml,settings.yaml\u201d SETTINGS_FILE_FOR_DYNACONF=\u201dconf.toml;settings.yaml\u201d MYPROGRAM_SETTINGS=\u201dconf.toml,settings.yaml\u201d SILENT_ERRORS | bool | Loading errors should be silenced. | true | SILENT_ERRORS_FOR_DYNACONF=false SKIP_FILES | list | Files to skip/ignore if found on search tree. | [] | SKIP_FILES_FOR_DYNACONF=\u201d[\u2018/absolute/path/to/file.ext\u2019]\u201d VAULT_ALLOW_REDIRECTS | bool | Vault allow redirects. | None | VAULT_ALLOW_REDIRECTS_FOR_DYNACONF=false VAULT_CERT | str | Vault cert/pem file path. | None | VAULT_CERT_FOR_DYNACONF=\u201d~/.ssh/key.pem\u201d VAULT_ENABLED | bool | Vault server is enabled. | false | VAULT_ENABLED_FOR_DYNACONF=true VAULT_HOST | str | Vault host. | localhost | VAULT_HOST_FOR_DYNACONF=\u201dserver\u201d VAULT_PATH | str | Vault path to the configuration. | None | VAULT_PATH_FOR_DYNACONF=\u201dsecret_data\u201d VAULT_PORT | str | Vault port. | 8200 | VAULT_PORT_FOR_DYNACONF=\u201d2800\u201d VAULT_PROXIES | dict | Vault proxies. | None | VAULT_PROXIES_FOR_DYNACONF={http=\u201dhttp:/localhost:3128/\u201d} VAULT_ROLE_ID | str | Vault Role ID. | None | VAULT_ROLE_ID_FOR_DYNACONF=\u201dsome-role-id\u201d VAULT_SCHEME | str | Vault scheme. | http | VAULT_SCHEME_FOR_DYNACONF=\u201dhttps\u201d VAULT_SECRET_ID | str | Vault Secret ID. | None | VAULT_SECRET_ID_FOR_DYNACONF=\u201dsome-secret-id\u201d VAULT_TIMEOUT | int | Vault timeout in seconds. | None | VAULT_TIMEOUT_FOR_DYNACONF=60 VAULT_TOKEN | str | Vault token. | None | VAULT_TOKEN_FOR_DYNACONF=\u201dmyroot\u201d VAULT_URL | str | Vault URL. | http:// localhost :8200 | VAULT_URL_FOR_DYNACONF=\u201dhttp://server/8200\u201d VAULT_VERIFY | bool | Vault should verify. | None | VAULT_VERIFY_FOR_DYNACONF=true YAML_LOADER | str | yaml method name {safe,full,unsafe}_load. | safe_load | YAML_LOADER_FOR_DYNACONF=unsafe_load","title":"Configuration options"},{"location":"guides/configuration/#internal-use-variables","text":"FORCE_ENV_FOR_DYNACONF: This variable exists to support the from_env method, the crontib extensions and to use for testing.","title":"Internal use variables"},{"location":"guides/configuration/#deprecated-options","text":"Some configuration options has been deprecated and replaced with a new name, we try to make it without breaking backwards compatibility with old version, but you may receive a warning if use: PROJECT_ROOT replaced by ROOT_PATH_FOR_DYNACONF PROJECT_ROOT_FOR_DYNACONF replaced by ROOT_PATH_FOR_DYNACONF DYNACONF_NAMESPACE replaced by ENV_FOR_DYNACONF NAMESPACE_FOR_DYNACONF replaced by ENV_FOR_DYNACONF BASE_NAMESPACE_FOR_DYNACONF replaced by DEFAULT_ENV_FOR_DYNACONF DYNACONF_SETTINGS_MODULE replaced by SETTINGS_FILE_FOR_DYNACONF DYNACONF_SETTINGS replaced by SETTINGS_FILE_FOR_DYNACONF SETTINGS_MODULE replaced by SETTINGS_FILE_FOR_DYNACONF DYNACONF_SILENT_ERRORS replaced by SILENT_ERRORS_FOR_DYNACONF DYNACONF_ALWAYS_FRESH_VARS replaced by FRESH_VARS_FOR_DYNACONF GLOBAL_ENV_FOR_DYNACONF replaced by ENVVAR_PREFIX_FOR_DYNACONF SETTINGS_MODULE_FOR_DYNACONF replaced by SETTINGS_FILE_FOR_DYNACONF .. autoclass:: dynaconf.default_settings :show-inheritance:","title":"Deprecated options"},{"location":"guides/contribute/","text":"How to contribute In github repository issues and Pull Request are welcomed! New implementations Bug Fixes Bug reports More examples of use in /example folder Documentation Feedback as issues and comments or joining #dynaconf on freenode Donation to rochacbruno [at] gmail.com in PayPal New implementations - Steps Create and use a new virtualenv and install the requirements of the file requirements_dev.txt. Install the pre-commit pre-commit install --install-hooks During and after development run tests ! py.test -v --cov-config .coveragerc --cov=dynaconf -l tests/ --junitxml=junit/test-results.xml","title":"How to contribute"},{"location":"guides/contribute/#how-to-contribute","text":"In github repository issues and Pull Request are welcomed! New implementations Bug Fixes Bug reports More examples of use in /example folder Documentation Feedback as issues and comments or joining #dynaconf on freenode Donation to rochacbruno [at] gmail.com in PayPal","title":"How to contribute"},{"location":"guides/contribute/#new-implementations-steps","text":"Create and use a new virtualenv and install the requirements of the file requirements_dev.txt. Install the pre-commit pre-commit install --install-hooks During and after development run tests ! py.test -v --cov-config .coveragerc --cov=dynaconf -l tests/ --junitxml=junit/test-results.xml","title":"New implementations - Steps"},{"location":"guides/credits/","text":"Credits Dynaconf is inspired by flask.config and django.conf.settings Some ideas also taken from Rust config crate Environments definitions ideas taken from Rust rocket framework","title":"Credits"},{"location":"guides/credits/#credits","text":"Dynaconf is inspired by flask.config and django.conf.settings Some ideas also taken from Rust config crate Environments definitions ideas taken from Rust rocket framework","title":"Credits"},{"location":"guides/django/","text":"Django Extension New in 2.0.0 Dynaconf extensions for Django works by patching the settings.py file with dynaconf loading hooks, the change is done on a single file and then in your whole project every time you call django.conf.settings you will have access to dynaconf attributes and methods. Ensure dynaconf is installed on your env pip install dynaconf[yaml] Initialize the extension You can manually append at the bottom of your django project's settings.py the following code: # HERE STARTS DYNACONF EXTENSION LOAD (Keep at the very bottom of settings.py) # Read more at https://dynaconf.readthedocs.io/en/latest/guides/django.md import dynaconf # noqa settings = dynaconf.DjangoDynaconf(__name__) # noqa # HERE ENDS DYNACONF EXTENSION LOAD (No more code below this line) Or optionally you can, on the same directory where your manage.py is located run: export DJANGO_SETTINGS_MODULE=yourapp.settings $ dynaconf init # or passing the location of the settings file $ dynaconf init --django yourapp/settings.py Dynaconf will append its extension loading code to the bottom of your yourapp/settings.py file and will create settings.toml and .secrets.toml in the current folder (the same where manage.py is located). TIP Take a look at example/django_example Using DJANGO_ environment variables Then django.conf.settings will work as a dynaconf.settings instance and DJANGO_ will be the global prefix to export environment variables. Example: export DJANGO_DEBUG=true # django.conf.settings.DEBUG export DJANGO_INTVALUE=1 # django.conf.settings['INTVALUE'] export DJANGO_HELLO=\"Hello\" # django.conf.settings.get('HELLO') TIP : If you dont want to use DJANGO_ as prefix for envvars you can customize by passing a new name e.g: dynaconf.DjangoDynaconf(__name__, ENVVAR_PREFIX_FOR_DYNACONF=\"FOO\") then export FOO_DEBUG=true You can also set nested dictionary values, for example lets say you have a configuration like this: settings.py ... DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'module.foo.engine', 'ARGS': {'timeout': 30} } } ... And now you want to change the values of ENGINE to other.module , via environment variables you can use the format ${ENVVAR_PREFIX}_${VARIABLE}__${NESTED_ITEM}__${NESTED_ITEM} Each __ (dunder, a.k.a double underline ) denotes access to nested elements in a dictionary. So: export DYNACONF_DATABASES__default__ENGINE=other.module will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'timeout': 30} } } Read more on environment variables Settings files You can also have settings files for your Django app, in the root directory (the same where manage.py is located) put your settings.{yaml, toml, ini, json, py} and .secrets.{yaml, toml, ini, json, py} files and then define your environments [default] , [development] and [production] . NOTE: .yaml is the recommended format for Django applications because it allows complex data structures in easy way, but feel free to choose any format you are familiar with. To switch the working environment the DJANGO_ENV variable can be used, so DJANGO_ENV=development to work in development mode or DJANGO_ENV=production to switch to production. IMPORTANT : To use $ dynaconf CLI the DJANGO_SETTINGS_MODULE environment variable must be defined. IF you don't want to manually create your config files take a look at the CLI Customizations It is possible to customize how your django project will load settings, example: You want your users to customize a settings file defined in export PROJECTNAME_SETTINGS=/path/to/settings.toml and you want environment variables to be loaded from PROJECTNAME_VARNAME Edit django settings.py and modify the dynaconf extension part: from: # HERE STARTS DYNACONF EXTENSION LOAD ... settings = dynaconf.DjangoDynaconf(__name__) # HERE ENDS DYNACONF EXTENSION LOAD to: # HERE STARTS DYNACONF EXTENSION LOAD ... settings = dynaconf.DjangoDynaconf( __name__, ENVVAR_PREFIX_FOR_DYNACONF='PROJECTNAME', ENV_SWITCHER_FOR_DYNACONF='PROJECTNAME_ENV', SETTINGS_FILE_FOR_DYNACONF='/etc/projectname/settings.toml', ENVVAR_FOR_DYNACONF='PROJECTNAME_SETTINGS', INCLUDES_FOR_DYNACONF=['/etc/projectname/plugins/*'], ) # HERE ENDS DYNACONF EXTENSION LOAD Variables on environment can be set/override using PROJECTNAME_ prefix e.g: export PROJECTNAME_DEBUG=true . Working environment can now be switched using export PROJECTNAME_ENV=production it defaults to development . Your settings are now read from /etc/projectname/settings.toml (dynaconf will not perform search for all the settings formats). This settings location can be changed via envvar using export PROJECTNAME_SETTINGS=/other/path/to/settings.py{yaml,toml,json,ini} You can have additional settings read from /etc/projectname/plugins/* any supoprted file from this folder will be loaded. You can set more options, take a look on configuration Reading Settings on Standalone Scripts NOTE : The recommended way to create standalone scripts is by creating management commands inside your Django applications or pugins. IMPORTANT If you need that script to be out of your Django Application Scope, it is also possible and if needed you can use settings.DYNACONF.configure() instead of the common settings.configure() provided by Django. Examples: Examples below assumes you have DJANGO_SETTINGS_MODULE environment variable set, either by exporting it to your env or by explicitly adding it to os.environ dictionary. IMPORTANT : If you call settings.configure() directly dynaconf will be disabled. As you have DJANGO_SETTINGS_MODULE exported you don't need to call it, but if you need please use: settings.DYNACONF.configure() . Common case /etc/my_script.py from django.conf import settings print(settings.DATABASES) Explicitly adding the setting module /etc/my_script.py import os os.environ['DJANGO_SETTINGS_MODULE'] = 'foo.settings' from django.conf import settings print(settings.DATABASES) When you need the configure Calling DYNACONF.configure() is needed when you want to access dynaconf special methods like using_env , get , get_fresh etc... /etc/my_script.py from django.conf import settings settings.DYNACONF.configure() print(settings.get('DATABASES')) Importing settings directly (recommended for the above case) /etc/my_script.py from foo.settings import settings print(settings.get('DATABASES')) Importing settings via importlib /etc/my_script.py import os import importlib settings = importlib.import_module(os.environ['DJANGO_SETTINGS_MODULE']) print(settings.get('DATABASES')) Testing on Django Django testing must work out of the box! But in some cases when you mock stuff and need to add environment variables to os.environ on demand for test cases it may be needed to reload the dynaconf . To do that write up on your test case setup part: import os import importlib from myapp import settings # NOTE: this uses your app module not django.conf class TestCase(...): def setUp(self): os.environ['DJANGO_FOO'] = 'BAR' # dynaconf should read it and set `settings.FOO` importlib.reload(settings) def test_foo(self): self.assertEqual(settings.FOO, 'BAR') Explicit mode Some users have the preference to explicitly load each setting variable inside the settings.py and then let django manage it in the common way, it is possible. NOTE Doing this way misses the ability to use dynaconf methods like using_env , get etc on your django applications code, you can use it only inside settings.py Dynaconf will be available only on settings.py scope, on the rest of your application settings is managed by Django normally. settings.py import sys from dynaconf import LazySettings settings = LazySettings(**YOUR_OPTIONS_HERE) DEBUG = settings.get('DEBUG', False) DATABASES = settings.get('DATABASES', { 'default': { 'ENGINE': '...', 'NAME': '... } }) ... # At the end of your settings.py settings.populate_obj(sys.modules[__name__], ignore=locals()) NOTE : Starting in 2.1.1 the ignore argument will tell Dynaconf to not override variables that already exists in the current settings file, remove it if you want all the existing local variables to be overwritten by dynaconf. You can still change env with export DJANGO_ENV=production and also can export variables lile export DJANGO_DEBUG=true Knowm Caveats If settings.configure() is called directly it disables Dynaconf, use settings.DYNACONF.configure() Deprecation note On old dynaconf releases the solution was to add dynaconf.contrib.django_dynaconf to INSTALLED_APPS as the first item, this still works but has some limitations so it is not recommended anymore.","title":"Django"},{"location":"guides/django/#django-extension","text":"New in 2.0.0 Dynaconf extensions for Django works by patching the settings.py file with dynaconf loading hooks, the change is done on a single file and then in your whole project every time you call django.conf.settings you will have access to dynaconf attributes and methods. Ensure dynaconf is installed on your env pip install dynaconf[yaml]","title":"Django Extension"},{"location":"guides/django/#initialize-the-extension","text":"You can manually append at the bottom of your django project's settings.py the following code: # HERE STARTS DYNACONF EXTENSION LOAD (Keep at the very bottom of settings.py) # Read more at https://dynaconf.readthedocs.io/en/latest/guides/django.md import dynaconf # noqa settings = dynaconf.DjangoDynaconf(__name__) # noqa # HERE ENDS DYNACONF EXTENSION LOAD (No more code below this line) Or optionally you can, on the same directory where your manage.py is located run: export DJANGO_SETTINGS_MODULE=yourapp.settings $ dynaconf init # or passing the location of the settings file $ dynaconf init --django yourapp/settings.py Dynaconf will append its extension loading code to the bottom of your yourapp/settings.py file and will create settings.toml and .secrets.toml in the current folder (the same where manage.py is located). TIP Take a look at example/django_example","title":"Initialize the extension"},{"location":"guides/django/#using-django_-environment-variables","text":"Then django.conf.settings will work as a dynaconf.settings instance and DJANGO_ will be the global prefix to export environment variables. Example: export DJANGO_DEBUG=true # django.conf.settings.DEBUG export DJANGO_INTVALUE=1 # django.conf.settings['INTVALUE'] export DJANGO_HELLO=\"Hello\" # django.conf.settings.get('HELLO') TIP : If you dont want to use DJANGO_ as prefix for envvars you can customize by passing a new name e.g: dynaconf.DjangoDynaconf(__name__, ENVVAR_PREFIX_FOR_DYNACONF=\"FOO\") then export FOO_DEBUG=true You can also set nested dictionary values, for example lets say you have a configuration like this: settings.py ... DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'module.foo.engine', 'ARGS': {'timeout': 30} } } ... And now you want to change the values of ENGINE to other.module , via environment variables you can use the format ${ENVVAR_PREFIX}_${VARIABLE}__${NESTED_ITEM}__${NESTED_ITEM} Each __ (dunder, a.k.a double underline ) denotes access to nested elements in a dictionary. So: export DYNACONF_DATABASES__default__ENGINE=other.module will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'timeout': 30} } } Read more on environment variables","title":"Using DJANGO_ environment variables"},{"location":"guides/django/#settings-files","text":"You can also have settings files for your Django app, in the root directory (the same where manage.py is located) put your settings.{yaml, toml, ini, json, py} and .secrets.{yaml, toml, ini, json, py} files and then define your environments [default] , [development] and [production] . NOTE: .yaml is the recommended format for Django applications because it allows complex data structures in easy way, but feel free to choose any format you are familiar with. To switch the working environment the DJANGO_ENV variable can be used, so DJANGO_ENV=development to work in development mode or DJANGO_ENV=production to switch to production. IMPORTANT : To use $ dynaconf CLI the DJANGO_SETTINGS_MODULE environment variable must be defined. IF you don't want to manually create your config files take a look at the CLI","title":"Settings files"},{"location":"guides/django/#customizations","text":"It is possible to customize how your django project will load settings, example: You want your users to customize a settings file defined in export PROJECTNAME_SETTINGS=/path/to/settings.toml and you want environment variables to be loaded from PROJECTNAME_VARNAME Edit django settings.py and modify the dynaconf extension part: from: # HERE STARTS DYNACONF EXTENSION LOAD ... settings = dynaconf.DjangoDynaconf(__name__) # HERE ENDS DYNACONF EXTENSION LOAD to: # HERE STARTS DYNACONF EXTENSION LOAD ... settings = dynaconf.DjangoDynaconf( __name__, ENVVAR_PREFIX_FOR_DYNACONF='PROJECTNAME', ENV_SWITCHER_FOR_DYNACONF='PROJECTNAME_ENV', SETTINGS_FILE_FOR_DYNACONF='/etc/projectname/settings.toml', ENVVAR_FOR_DYNACONF='PROJECTNAME_SETTINGS', INCLUDES_FOR_DYNACONF=['/etc/projectname/plugins/*'], ) # HERE ENDS DYNACONF EXTENSION LOAD Variables on environment can be set/override using PROJECTNAME_ prefix e.g: export PROJECTNAME_DEBUG=true . Working environment can now be switched using export PROJECTNAME_ENV=production it defaults to development . Your settings are now read from /etc/projectname/settings.toml (dynaconf will not perform search for all the settings formats). This settings location can be changed via envvar using export PROJECTNAME_SETTINGS=/other/path/to/settings.py{yaml,toml,json,ini} You can have additional settings read from /etc/projectname/plugins/* any supoprted file from this folder will be loaded. You can set more options, take a look on configuration","title":"Customizations"},{"location":"guides/django/#reading-settings-on-standalone-scripts","text":"NOTE : The recommended way to create standalone scripts is by creating management commands inside your Django applications or pugins. IMPORTANT If you need that script to be out of your Django Application Scope, it is also possible and if needed you can use settings.DYNACONF.configure() instead of the common settings.configure() provided by Django.","title":"Reading Settings on Standalone Scripts"},{"location":"guides/django/#examples","text":"Examples below assumes you have DJANGO_SETTINGS_MODULE environment variable set, either by exporting it to your env or by explicitly adding it to os.environ dictionary. IMPORTANT : If you call settings.configure() directly dynaconf will be disabled. As you have DJANGO_SETTINGS_MODULE exported you don't need to call it, but if you need please use: settings.DYNACONF.configure() .","title":"Examples:"},{"location":"guides/django/#common-case","text":"/etc/my_script.py from django.conf import settings print(settings.DATABASES)","title":"Common case"},{"location":"guides/django/#explicitly-adding-the-setting-module","text":"/etc/my_script.py import os os.environ['DJANGO_SETTINGS_MODULE'] = 'foo.settings' from django.conf import settings print(settings.DATABASES)","title":"Explicitly adding the setting module"},{"location":"guides/django/#when-you-need-the-configure","text":"Calling DYNACONF.configure() is needed when you want to access dynaconf special methods like using_env , get , get_fresh etc... /etc/my_script.py from django.conf import settings settings.DYNACONF.configure() print(settings.get('DATABASES'))","title":"When you need the configure"},{"location":"guides/django/#importing-settings-directly-recommended-for-the-above-case","text":"/etc/my_script.py from foo.settings import settings print(settings.get('DATABASES'))","title":"Importing settings directly (recommended for the above case)"},{"location":"guides/django/#importing-settings-via-importlib","text":"/etc/my_script.py import os import importlib settings = importlib.import_module(os.environ['DJANGO_SETTINGS_MODULE']) print(settings.get('DATABASES'))","title":"Importing settings via importlib"},{"location":"guides/django/#testing-on-django","text":"Django testing must work out of the box! But in some cases when you mock stuff and need to add environment variables to os.environ on demand for test cases it may be needed to reload the dynaconf . To do that write up on your test case setup part: import os import importlib from myapp import settings # NOTE: this uses your app module not django.conf class TestCase(...): def setUp(self): os.environ['DJANGO_FOO'] = 'BAR' # dynaconf should read it and set `settings.FOO` importlib.reload(settings) def test_foo(self): self.assertEqual(settings.FOO, 'BAR')","title":"Testing on Django"},{"location":"guides/django/#explicit-mode","text":"Some users have the preference to explicitly load each setting variable inside the settings.py and then let django manage it in the common way, it is possible. NOTE Doing this way misses the ability to use dynaconf methods like using_env , get etc on your django applications code, you can use it only inside settings.py Dynaconf will be available only on settings.py scope, on the rest of your application settings is managed by Django normally. settings.py import sys from dynaconf import LazySettings settings = LazySettings(**YOUR_OPTIONS_HERE) DEBUG = settings.get('DEBUG', False) DATABASES = settings.get('DATABASES', { 'default': { 'ENGINE': '...', 'NAME': '... } }) ... # At the end of your settings.py settings.populate_obj(sys.modules[__name__], ignore=locals()) NOTE : Starting in 2.1.1 the ignore argument will tell Dynaconf to not override variables that already exists in the current settings file, remove it if you want all the existing local variables to be overwritten by dynaconf. You can still change env with export DJANGO_ENV=production and also can export variables lile export DJANGO_DEBUG=true","title":"Explicit mode"},{"location":"guides/django/#knowm-caveats","text":"If settings.configure() is called directly it disables Dynaconf, use settings.DYNACONF.configure()","title":"Knowm Caveats"},{"location":"guides/django/#deprecation-note","text":"On old dynaconf releases the solution was to add dynaconf.contrib.django_dynaconf to INSTALLED_APPS as the first item, this still works but has some limitations so it is not recommended anymore.","title":"Deprecation note"},{"location":"guides/environment_variables/","text":"Environment variables overloading parameters via env vars All configuration parameters, including custom environments and dynaconf configuration , can be overridden through environment variables. To override the configuration parameter {param} , use an environment variable named DYNACONF_{PARAM} . For instance, to override the \"HOST\" configuration parameter, you can run your application with: DYNACONF_HOST='otherhost.com' python yourapp.py '.env' files If you don't want to declare the variables on every program call you can run export DYNACONF_{PARAM} in your shell or put the values in a .env file located in the same directory as your settings files (the root directory of your application or the same folder where your program script is located), variables in .env does not overrride existing environment variables. IMPORTANT : Dynaconf will search for a .env on the order explained here . So to avoid conflicts with existing .env in parent directories it is recommended to have a .env inside your project even if it is empty. Precedence and type casting Environment variables take precedence over all other configuration sources: if the variable is set, it will be used as the value for the parameter even if parameter exists in settings files or in .env . Variable values are parsed as if they were TOML syntax. As illustration, consider the following examples: # Numbers DYNACONF_INTEGER=42 DYNACONF_FLOAT=3.14 # Text DYNACONF_STRING=Hello DYNACONF_STRING=\"Hello\" # Booleans DYNACONF_BOOL=true DYNACONF_BOOL=false # Use extra quotes to force a string from other type DYNACONF_STRING=\"'42'\" DYNACONF_STRING=\"'true'\" # Arrays must be homogenous in toml syntax DYNACONF_ARRAY=[1, 2, 3] DYNACONF_ARRAY=[1.1, 2.2, 3.3] DYNACONF_ARRAY=['a', 'b', 'c'] # Dictionaries DYNACONF_DICT={key=\"abc\",val=123} # toml syntax does not allow `None/null` values so use @none DYNACONF_NONE='@none None' # toml syntax does not allow mixed type arrays so use @json DYNACONF_ARRAY='@json [42, 3.14, \"hello\", true, [\"otherarray\"], {\"foo\": \"bar\"}]' # Lazily formatted string can access env vars and settings variables. # using str.format DYNACONF_DATABASE_PATH=\"@format '{env[HOME]}/.config/databases/{this.DB_NAME}\" # using jinja2 DYNACONF_DATABASE_PATH=\"@jinja {{env.HOME}}/.config/databases/{{this.DB_NAME}}\" NOTE : Older versions of Dynaconf used the @casting prefixes for env vars like export DYNACONF_INTEGER='@int 123' still works but this casting is deprecated in favor of using TOML syntax described above. To disable the @casting do export AUTO_CAST_FOR_DYNACONF=false Merging new data to existing variables Nested keys in dictionaries via environment variables. New in 2.1.0 This is useful for Django settings. Lets say you have a configuration like this: settings.py DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'module.foo.engine', 'ARGS': {'timeout': 30} } } And now you want to change the values of ENGINE to other.module , via environment variables you can use the format ${ENVVAR_PREFIX}_${VARIABLE}__${NESTED_ITEM}__${NESTED_ITEM} Each __ (dunder, a.k.a double underline ) denotes access to nested elements in a dictionary. So DATABASES['default']['ENGINE'] = 'other.module' Can be expressed as environment variables as: export DYNACONF_DATABASES__default__ENGINE=other.module NOTE : if you are using Django extension then the prefix will be DJANGO_ instead of DYNACONF_ and the same if you are using FLASK_ or a custom prefix if you have customized the ENVVAR_PREFIX . This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'timeout': 30} } } IMPORTANT lower case keys are respected only on *nix systems, unfortunately Windows environment variables are case insensitive and Python reads it as all upper cases, that means that if you are running on Windows the dictionary can have only upper case keys. Now if you want to add a new item to ARGS key: export DYNACONF_DATABASES__default__ARGS__retries=10 This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'timeout': 30, 'retries': 10} } } and you can also pass a toml like dictionary to be merged with existing ARGS key using @merge token. new in 3.0.0 # as a toml (recommended) export DYNACONF_DATABASES__default__ARGS='@merge {timeout=50, size=1}' # OR as a json export DYNACONF_DATABASES__default__ARGS='@merge {\"timeout\": 50, \"size\": 1}' # OR as plain key pair export DYNACONF_DATABASES__default__ARGS='@merge timeout=50,size=1' will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'retries': 10, 'timeout': 50, 'size': 1} } } Now if you want to clean an existing nested attribute you can just assign the new value. # As a TOML empty dictionary `\"{}\"` export DYNACONF_DATABASES__default__ARGS='{}' This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {} } } # As a TOML dictionary (recommended) export DYNACONF_DATABASES__default__ARGS='{timeout=90}' This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'timeout': 90} } } And if in any case you need to completely remove that key from the dictionary: export DYNACONF_DATABASES__default__ARGS='@del' This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module' } } Using the dynaconf_merge mark on configuration files. New in 2.0.0 To merge exported variables there is the dynaconf_merge tokens, example: Your main settings file (e.g settings.toml ) has an existing DATABASE dict setting on [default] env. Now you want to contribute to the same DATABASE key by adding new keys, so you can use dynaconf_merge at the end of your dict: In specific [envs] [default] database = {host=\"server.com\", user=\"default\"} [development] database = {user=\"dev_user\", dynaconf_merge=true} or New in 2.2.0 [default] database = {host=\"server.com\", user=\"default\"} [development.database] dynaconf_merge = {user=\"dev_user\"} In an environment variable use @merge token: New in 2.2.0 # Toml formatted envvar export DYNACONF_DATABASE='@merge {password=1234}' or dunder (recommended) # Toml formatted envvar export DYNACONF_DATABASE__PASSWORD=1234 The end result will be on [development] env: settings.DATABASE == {'host': 'server.com', 'user': 'dev_user', 'password': 1234} Read more in Getting Started Guide The global prefix The DYNACONF_{param} prefix is set by ENVVAR_PREFIX_FOR_DYNACONF and serves only to be used in environment variables to override config values. This prefix itself can be changed to something more significant for your application, however we recommend keeping DYNACONF_{param} as your global env prefix. Setting ENVVAR_PREFIX_FOR_DYNACONF to false will disable the prefix entirely and cause Dynaconf to load all environment variables. When providing ENVVAR_PREFIX_FOR_DYNACONF as parameter to LazySettings or settings.configure , make sure to give it a Python-native False : from dynaconf import LazySettings settings = LazySettings(ENVVAR_PREFIX_FOR_DYNACONF=False) NOTE : See the Configuring dynaconf section in documentation to learn more on how to use .env variables to configure dynaconf behavior.","title":"Environment variables"},{"location":"guides/environment_variables/#environment-variables","text":"","title":"Environment variables"},{"location":"guides/environment_variables/#overloading-parameters-via-env-vars","text":"All configuration parameters, including custom environments and dynaconf configuration , can be overridden through environment variables. To override the configuration parameter {param} , use an environment variable named DYNACONF_{PARAM} . For instance, to override the \"HOST\" configuration parameter, you can run your application with: DYNACONF_HOST='otherhost.com' python yourapp.py","title":"overloading parameters via env vars"},{"location":"guides/environment_variables/#env-files","text":"If you don't want to declare the variables on every program call you can run export DYNACONF_{PARAM} in your shell or put the values in a .env file located in the same directory as your settings files (the root directory of your application or the same folder where your program script is located), variables in .env does not overrride existing environment variables. IMPORTANT : Dynaconf will search for a .env on the order explained here . So to avoid conflicts with existing .env in parent directories it is recommended to have a .env inside your project even if it is empty.","title":"'.env' files"},{"location":"guides/environment_variables/#precedence-and-type-casting","text":"Environment variables take precedence over all other configuration sources: if the variable is set, it will be used as the value for the parameter even if parameter exists in settings files or in .env . Variable values are parsed as if they were TOML syntax. As illustration, consider the following examples: # Numbers DYNACONF_INTEGER=42 DYNACONF_FLOAT=3.14 # Text DYNACONF_STRING=Hello DYNACONF_STRING=\"Hello\" # Booleans DYNACONF_BOOL=true DYNACONF_BOOL=false # Use extra quotes to force a string from other type DYNACONF_STRING=\"'42'\" DYNACONF_STRING=\"'true'\" # Arrays must be homogenous in toml syntax DYNACONF_ARRAY=[1, 2, 3] DYNACONF_ARRAY=[1.1, 2.2, 3.3] DYNACONF_ARRAY=['a', 'b', 'c'] # Dictionaries DYNACONF_DICT={key=\"abc\",val=123} # toml syntax does not allow `None/null` values so use @none DYNACONF_NONE='@none None' # toml syntax does not allow mixed type arrays so use @json DYNACONF_ARRAY='@json [42, 3.14, \"hello\", true, [\"otherarray\"], {\"foo\": \"bar\"}]' # Lazily formatted string can access env vars and settings variables. # using str.format DYNACONF_DATABASE_PATH=\"@format '{env[HOME]}/.config/databases/{this.DB_NAME}\" # using jinja2 DYNACONF_DATABASE_PATH=\"@jinja {{env.HOME}}/.config/databases/{{this.DB_NAME}}\" NOTE : Older versions of Dynaconf used the @casting prefixes for env vars like export DYNACONF_INTEGER='@int 123' still works but this casting is deprecated in favor of using TOML syntax described above. To disable the @casting do export AUTO_CAST_FOR_DYNACONF=false","title":"Precedence and type casting"},{"location":"guides/environment_variables/#merging-new-data-to-existing-variables","text":"","title":"Merging new data to existing variables"},{"location":"guides/environment_variables/#nested-keys-in-dictionaries-via-environment-variables","text":"New in 2.1.0 This is useful for Django settings. Lets say you have a configuration like this: settings.py DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'module.foo.engine', 'ARGS': {'timeout': 30} } } And now you want to change the values of ENGINE to other.module , via environment variables you can use the format ${ENVVAR_PREFIX}_${VARIABLE}__${NESTED_ITEM}__${NESTED_ITEM} Each __ (dunder, a.k.a double underline ) denotes access to nested elements in a dictionary. So DATABASES['default']['ENGINE'] = 'other.module' Can be expressed as environment variables as: export DYNACONF_DATABASES__default__ENGINE=other.module NOTE : if you are using Django extension then the prefix will be DJANGO_ instead of DYNACONF_ and the same if you are using FLASK_ or a custom prefix if you have customized the ENVVAR_PREFIX . This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'timeout': 30} } } IMPORTANT lower case keys are respected only on *nix systems, unfortunately Windows environment variables are case insensitive and Python reads it as all upper cases, that means that if you are running on Windows the dictionary can have only upper case keys. Now if you want to add a new item to ARGS key: export DYNACONF_DATABASES__default__ARGS__retries=10 This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'timeout': 30, 'retries': 10} } } and you can also pass a toml like dictionary to be merged with existing ARGS key using @merge token. new in 3.0.0 # as a toml (recommended) export DYNACONF_DATABASES__default__ARGS='@merge {timeout=50, size=1}' # OR as a json export DYNACONF_DATABASES__default__ARGS='@merge {\"timeout\": 50, \"size\": 1}' # OR as plain key pair export DYNACONF_DATABASES__default__ARGS='@merge timeout=50,size=1' will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'retries': 10, 'timeout': 50, 'size': 1} } } Now if you want to clean an existing nested attribute you can just assign the new value. # As a TOML empty dictionary `\"{}\"` export DYNACONF_DATABASES__default__ARGS='{}' This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {} } } # As a TOML dictionary (recommended) export DYNACONF_DATABASES__default__ARGS='{timeout=90}' This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'timeout': 90} } } And if in any case you need to completely remove that key from the dictionary: export DYNACONF_DATABASES__default__ARGS='@del' This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module' } }","title":"Nested keys in dictionaries via environment variables."},{"location":"guides/environment_variables/#using-the-dynaconf_merge-mark-on-configuration-files","text":"New in 2.0.0 To merge exported variables there is the dynaconf_merge tokens, example: Your main settings file (e.g settings.toml ) has an existing DATABASE dict setting on [default] env. Now you want to contribute to the same DATABASE key by adding new keys, so you can use dynaconf_merge at the end of your dict: In specific [envs] [default] database = {host=\"server.com\", user=\"default\"} [development] database = {user=\"dev_user\", dynaconf_merge=true} or New in 2.2.0 [default] database = {host=\"server.com\", user=\"default\"} [development.database] dynaconf_merge = {user=\"dev_user\"} In an environment variable use @merge token: New in 2.2.0 # Toml formatted envvar export DYNACONF_DATABASE='@merge {password=1234}' or dunder (recommended) # Toml formatted envvar export DYNACONF_DATABASE__PASSWORD=1234 The end result will be on [development] env: settings.DATABASE == {'host': 'server.com', 'user': 'dev_user', 'password': 1234} Read more in Getting Started Guide","title":"Using the dynaconf_merge mark on configuration files."},{"location":"guides/environment_variables/#the-global-prefix","text":"The DYNACONF_{param} prefix is set by ENVVAR_PREFIX_FOR_DYNACONF and serves only to be used in environment variables to override config values. This prefix itself can be changed to something more significant for your application, however we recommend keeping DYNACONF_{param} as your global env prefix. Setting ENVVAR_PREFIX_FOR_DYNACONF to false will disable the prefix entirely and cause Dynaconf to load all environment variables. When providing ENVVAR_PREFIX_FOR_DYNACONF as parameter to LazySettings or settings.configure , make sure to give it a Python-native False : from dynaconf import LazySettings settings = LazySettings(ENVVAR_PREFIX_FOR_DYNACONF=False) NOTE : See the Configuring dynaconf section in documentation to learn more on how to use .env variables to configure dynaconf behavior.","title":"The global prefix"},{"location":"guides/examples/","text":"Examples Supported file formats TOML [default] DEBUG = true SERVER = \"flaskdynaconf.com\" PORT = 6666 MESSAGE = \"Dynaconf works like a charm with Flask and TOML\" TEST_RULE = '/flask_with_toml' [development] DEBUG = true SERVER = \"dev.flaskdynaconf.com\" [production] DEBUG = false SERVER = \"prod.flaskdynaconf.com\" YAML default: DEBUG: true SERVER: flaskdynaconf.com PORT: 6666 MESSAGE: Dynaconf works like a charm with Flask and YAML TEST_RULE: /flask_with_yaml development: DEBUG: true SERVER: dev.flaskdynaconf.com production: DEBUG: false SERVER: prod.flaskdynaconf.com INI [default] DEBUG = true SERVER = \"flaskdynaconf.com\" PORT = 6666 MESSAGE = \"Dynaconf works like a charm with Flask and INI\" TEST_RULE = '/flask_with_ini' [development] DEBUG = true SERVER = \"dev.flaskdynaconf.com\" [production] DEBUG = false SERVER = \"prod.flaskdynaconf.com\" JSON { \"default\": { \"DEBUG\": true, \"SERVER\": \"flaskdynaconf.com\", \"PORT\": 6666, \"MESSAGE\": \"Dynaconf works like a charm with Flask and JSON\", \"TEST_RULE\": \"/flask_with_json\" }, \"development\": { \"DEBUG\": true, \"SERVER\": \"dev.flaskdynaconf.com\" }, \"production\": { \"DEBUG\": false, \"SERVER\": \"prod.flaskdynaconf.com\" } } PY In python fils the environment is set by prefixing the file names settings.py DEBUG = True SERVER = \"flaskdynaconf.com\" PORT = 6666 MESSAGE = \"Dynaconf works like a charm with Flask and .py\" TEST_RULE = '/flask_with_ini' development_settings.py DEBUG = True SERVER = \"dev.flaskdynaconf.com\" production_settings.py DEBUG = False SERVER = \"prod.flaskdynaconf.com\" .env .env allows only the global environment (overrides everything) DEBUG=true SERVER=\"flaskdynaconf.com\" PORT=6666 MESSAGE=\"Dynaconf works like a charm with Flask and .env\" TEST_RULE='/flask_with_ini' Using a default main config file plus variable settings file On the .env export SETTINGS_FILE_FOR_DYNACONF=\"default.toml\" The default file [default] variable1 = 'value1' Now having specific settings per environment Use cases: plugin based apps user specific settings dev specific settings On the user1 environment export INCLUDES_FOR_DYNACONF='/path/to/user1_specific_settings.toml' On the user2 environment export INCLUDES_FOR_DYNACONF='/path/to/user2_specific_settings.toml' It can be a glob export INCLUDES_FOR_DYNACONF='/path/to/config/*.toml' And also supports having a ; or , separated list of paths or globs. More examples Take a look at example/ for more examples.","title":"Examples"},{"location":"guides/examples/#examples","text":"","title":"Examples"},{"location":"guides/examples/#supported-file-formats","text":"","title":"Supported file formats"},{"location":"guides/examples/#toml","text":"[default] DEBUG = true SERVER = \"flaskdynaconf.com\" PORT = 6666 MESSAGE = \"Dynaconf works like a charm with Flask and TOML\" TEST_RULE = '/flask_with_toml' [development] DEBUG = true SERVER = \"dev.flaskdynaconf.com\" [production] DEBUG = false SERVER = \"prod.flaskdynaconf.com\"","title":"TOML"},{"location":"guides/examples/#yaml","text":"default: DEBUG: true SERVER: flaskdynaconf.com PORT: 6666 MESSAGE: Dynaconf works like a charm with Flask and YAML TEST_RULE: /flask_with_yaml development: DEBUG: true SERVER: dev.flaskdynaconf.com production: DEBUG: false SERVER: prod.flaskdynaconf.com","title":"YAML"},{"location":"guides/examples/#ini","text":"[default] DEBUG = true SERVER = \"flaskdynaconf.com\" PORT = 6666 MESSAGE = \"Dynaconf works like a charm with Flask and INI\" TEST_RULE = '/flask_with_ini' [development] DEBUG = true SERVER = \"dev.flaskdynaconf.com\" [production] DEBUG = false SERVER = \"prod.flaskdynaconf.com\"","title":"INI"},{"location":"guides/examples/#json","text":"{ \"default\": { \"DEBUG\": true, \"SERVER\": \"flaskdynaconf.com\", \"PORT\": 6666, \"MESSAGE\": \"Dynaconf works like a charm with Flask and JSON\", \"TEST_RULE\": \"/flask_with_json\" }, \"development\": { \"DEBUG\": true, \"SERVER\": \"dev.flaskdynaconf.com\" }, \"production\": { \"DEBUG\": false, \"SERVER\": \"prod.flaskdynaconf.com\" } }","title":"JSON"},{"location":"guides/examples/#py","text":"In python fils the environment is set by prefixing the file names settings.py DEBUG = True SERVER = \"flaskdynaconf.com\" PORT = 6666 MESSAGE = \"Dynaconf works like a charm with Flask and .py\" TEST_RULE = '/flask_with_ini' development_settings.py DEBUG = True SERVER = \"dev.flaskdynaconf.com\" production_settings.py DEBUG = False SERVER = \"prod.flaskdynaconf.com\"","title":"PY"},{"location":"guides/examples/#env","text":".env allows only the global environment (overrides everything) DEBUG=true SERVER=\"flaskdynaconf.com\" PORT=6666 MESSAGE=\"Dynaconf works like a charm with Flask and .env\" TEST_RULE='/flask_with_ini'","title":".env"},{"location":"guides/examples/#using-a-default-main-config-file-plus-variable-settings-file","text":"On the .env export SETTINGS_FILE_FOR_DYNACONF=\"default.toml\" The default file [default] variable1 = 'value1' Now having specific settings per environment Use cases: plugin based apps user specific settings dev specific settings On the user1 environment export INCLUDES_FOR_DYNACONF='/path/to/user1_specific_settings.toml' On the user2 environment export INCLUDES_FOR_DYNACONF='/path/to/user2_specific_settings.toml' It can be a glob export INCLUDES_FOR_DYNACONF='/path/to/config/*.toml' And also supports having a ; or , separated list of paths or globs.","title":"Using a default main config file plus variable settings file"},{"location":"guides/examples/#more-examples","text":"Take a look at example/ for more examples.","title":"More examples"},{"location":"guides/extend/","text":"Extending Creating new loaders In your project i.e called myprogram create your custom loader. myprogram/my_custom_loader.py def load(obj, env=None, silent=True, key=None, filename=None): \"\"\" Reads and loads in to \"obj\" a single key or all keys from source :param obj: the settings instance :param env: settings current env (upper case) default='DEVELOPMENT' :param silent: if errors should raise :param key: if defined load a single key, else load all from `env` :param filename: Custom filename to load (useful for tests) :return: None \"\"\" # Load data from your custom data source (file, database, memory etc) # use `obj.set(key, value)` or `obj.update(dict)` to load data # use `obj.logger.debug` to log your loader activities # use `obj.find_file('filename.ext')` to find the file in search tree # Return nothing In the .env file or exporting the envvar define: LOADERS_FOR_DYNACONF=['myprogram.my_custom_loader', 'dynaconf.loaders.env_loader'] Dynaconf will import your myprogram.my_custom_loader.load and call it. IMPORTANT : the 'dynaconf.loaders.env_loader' must be the last in the loaders list if you want to keep the behavior of having envvars to override parameters. In case you need to disable all external loaders and rely only the settings.* file loaders define: LOADERS_FOR_DYNACONF=false In case you need to disable all core loaders and rely only on external loaders: CORE_LOADERS_FOR_DYNACONF='[]' # a toml empty list See example/custom_loader","title":"Extending"},{"location":"guides/extend/#extending","text":"","title":"Extending"},{"location":"guides/extend/#creating-new-loaders","text":"In your project i.e called myprogram create your custom loader. myprogram/my_custom_loader.py def load(obj, env=None, silent=True, key=None, filename=None): \"\"\" Reads and loads in to \"obj\" a single key or all keys from source :param obj: the settings instance :param env: settings current env (upper case) default='DEVELOPMENT' :param silent: if errors should raise :param key: if defined load a single key, else load all from `env` :param filename: Custom filename to load (useful for tests) :return: None \"\"\" # Load data from your custom data source (file, database, memory etc) # use `obj.set(key, value)` or `obj.update(dict)` to load data # use `obj.logger.debug` to log your loader activities # use `obj.find_file('filename.ext')` to find the file in search tree # Return nothing In the .env file or exporting the envvar define: LOADERS_FOR_DYNACONF=['myprogram.my_custom_loader', 'dynaconf.loaders.env_loader'] Dynaconf will import your myprogram.my_custom_loader.load and call it. IMPORTANT : the 'dynaconf.loaders.env_loader' must be the last in the loaders list if you want to keep the behavior of having envvars to override parameters. In case you need to disable all external loaders and rely only the settings.* file loaders define: LOADERS_FOR_DYNACONF=false In case you need to disable all core loaders and rely only on external loaders: CORE_LOADERS_FOR_DYNACONF='[]' # a toml empty list See example/custom_loader","title":"Creating new loaders"},{"location":"guides/external_storages/","text":"External storages An external storage is needed in some programs for scenarios like: 1) Having a single storage for settings and distribute across multiple instances 2) The need to change settings on the fly without redeploying or restarting the app (see Feature Flags ) 3) Storing sensitive values in a safe sealed Vault Using REDIS Run a Redis server installed or via docker: $ docker run -d -p 6379:6379 redis Install support for redis in dynaconf $ pip install dynaconf[redis] In your .env file or in exported environment variables define: REDIS_ENABLED_FOR_DYNACONF=true REDIS_HOST_FOR_DYNACONF=localhost REDIS_PORT_FOR_DYNACONF=6379 You can now write variables direct in to a redis hash named DYNACONF_< env > for example: DYNACONF_DEFAULT : default values DYNACONF_DEVELOPMENT : loaded only when ENV_FOR_DYNACONF=development (default) DYNACONF_PRODUCTION : loaded only when ENV_FOR_DYNACONF=production DYNACONF_CUSTOM : loaded only when ENV_FOR_DYNACONF=custom You can also use the redis writer $ dynaconf write redis -v name=Bruno -v database=localhost -v port=1234 The above data will be recorded in redis as a hash: DYNACONF_DEFAULT { NAME='Bruno' DATABASE='localhost' PORT='@int 1234' } If you want to write to specific env pass the -e option. $ dynaconf write redis -v name=Bruno -v database=localhost -v port=1234 -e production The above data will be recorded in redis as a hash: DYNACONF_PRODUCTION { NAME='Bruno' DATABASE='localhost' PORT='@int 1234' } Then to access that values you can set export ENV_FOR_DYNACONF=production or directly via settings.from_env('production').NAME if you want to skip type casting, write as string intead of PORT=1234 use PORT=\"'1234'\". Data is read from redis and another loaders only once when dynaconf.settings is first accessed or when from_env , .setenv() or using_env() are invoked. You can access the fresh value using settings.get_fresh(key) There is also the fresh context manager from dynaconf import settings print(settings.FOO) # this data was loaded once on import with settings.fresh(): print(settings.FOO) # this data is being freshly reloaded from source print(settings.get('FOO', fresh=True)) # this data is being freshly reloaded from source And you can also force some variables to be fresh setting in your setting file FRESH_VARS_FOR_DYNACONF = ['MYSQL_HOST'] or using env vars export FRESH_VARS_FOR_DYNACONF='[\"MYSQL_HOST\", \"OTHERVAR\"]' Then from dynaconf import settings print(settings.FOO) # This data was loaded once on import print(settings.MYSQL_HOST) # This data is being read from redis imediatelly! Using Hashicorp Vault to store secrets Read more in Using Vault Server section Custom Storages Do you want to store settings in other databases like NoSQL, Relational Databases or other services? Please see how to extend dynaconf to add your custom loaders.","title":"External storages"},{"location":"guides/external_storages/#external-storages","text":"An external storage is needed in some programs for scenarios like: 1) Having a single storage for settings and distribute across multiple instances 2) The need to change settings on the fly without redeploying or restarting the app (see Feature Flags ) 3) Storing sensitive values in a safe sealed Vault","title":"External storages"},{"location":"guides/external_storages/#using-redis","text":"Run a Redis server installed or via docker: $ docker run -d -p 6379:6379 redis Install support for redis in dynaconf $ pip install dynaconf[redis] In your .env file or in exported environment variables define: REDIS_ENABLED_FOR_DYNACONF=true REDIS_HOST_FOR_DYNACONF=localhost REDIS_PORT_FOR_DYNACONF=6379 You can now write variables direct in to a redis hash named DYNACONF_< env > for example: DYNACONF_DEFAULT : default values DYNACONF_DEVELOPMENT : loaded only when ENV_FOR_DYNACONF=development (default) DYNACONF_PRODUCTION : loaded only when ENV_FOR_DYNACONF=production DYNACONF_CUSTOM : loaded only when ENV_FOR_DYNACONF=custom You can also use the redis writer $ dynaconf write redis -v name=Bruno -v database=localhost -v port=1234 The above data will be recorded in redis as a hash: DYNACONF_DEFAULT { NAME='Bruno' DATABASE='localhost' PORT='@int 1234' } If you want to write to specific env pass the -e option. $ dynaconf write redis -v name=Bruno -v database=localhost -v port=1234 -e production The above data will be recorded in redis as a hash: DYNACONF_PRODUCTION { NAME='Bruno' DATABASE='localhost' PORT='@int 1234' } Then to access that values you can set export ENV_FOR_DYNACONF=production or directly via settings.from_env('production').NAME if you want to skip type casting, write as string intead of PORT=1234 use PORT=\"'1234'\". Data is read from redis and another loaders only once when dynaconf.settings is first accessed or when from_env , .setenv() or using_env() are invoked. You can access the fresh value using settings.get_fresh(key) There is also the fresh context manager from dynaconf import settings print(settings.FOO) # this data was loaded once on import with settings.fresh(): print(settings.FOO) # this data is being freshly reloaded from source print(settings.get('FOO', fresh=True)) # this data is being freshly reloaded from source And you can also force some variables to be fresh setting in your setting file FRESH_VARS_FOR_DYNACONF = ['MYSQL_HOST'] or using env vars export FRESH_VARS_FOR_DYNACONF='[\"MYSQL_HOST\", \"OTHERVAR\"]' Then from dynaconf import settings print(settings.FOO) # This data was loaded once on import print(settings.MYSQL_HOST) # This data is being read from redis imediatelly!","title":"Using REDIS"},{"location":"guides/external_storages/#using-hashicorp-vault-to-store-secrets","text":"Read more in Using Vault Server section","title":"Using Hashicorp Vault to store secrets"},{"location":"guides/external_storages/#custom-storages","text":"Do you want to store settings in other databases like NoSQL, Relational Databases or other services? Please see how to extend dynaconf to add your custom loaders.","title":"Custom Storages"},{"location":"guides/feature_flag/","text":"Feature flag system feature toggles Feature flagging is a system to dynamically toggle features in your application based in some settings value. The advantage of using it is to perform changes on the fly without the need to redeploy ou restart the application. Learn more on how to design your program using Feature Flags: http://martinfowler.com/articles/feature-toggles.md Example: Lets say you have 2 versions of your app dashboard and you want to serve the new version only for premium users. write flags to redis $ dynaconf write redis -s NEWDASHBOARD=true -e premiumuser In your program do: usertype = 'premiumuser' # assume you loaded it as part of your auth # user has access to new dashboard? if settings.flag('newdashboard', usertype): activate_new_dashboard() else: # User will have old dashboard if not a premiumuser activate_old_dashboard() The value is ensured to be loaded fresh from redis server so features can be enabled or disabled at any time without the need to redeploy. It also works with file settings but the recommended is redis as the data can be loaded once it is updated.","title":"Feature flag system"},{"location":"guides/feature_flag/#feature-flag-system","text":"","title":"Feature flag system"},{"location":"guides/feature_flag/#feature-toggles","text":"Feature flagging is a system to dynamically toggle features in your application based in some settings value. The advantage of using it is to perform changes on the fly without the need to redeploy ou restart the application. Learn more on how to design your program using Feature Flags: http://martinfowler.com/articles/feature-toggles.md Example: Lets say you have 2 versions of your app dashboard and you want to serve the new version only for premium users. write flags to redis $ dynaconf write redis -s NEWDASHBOARD=true -e premiumuser In your program do: usertype = 'premiumuser' # assume you loaded it as part of your auth # user has access to new dashboard? if settings.flag('newdashboard', usertype): activate_new_dashboard() else: # User will have old dashboard if not a premiumuser activate_old_dashboard() The value is ensured to be loaded fresh from redis server so features can be enabled or disabled at any time without the need to redeploy. It also works with file settings but the recommended is redis as the data can be loaded once it is updated.","title":"feature toggles"},{"location":"guides/flask/","text":"Flask Extension Dynaconf provides a drop in replacement for app.config . As Flask encourages the composition by overriding the config_class attribute this extension follows the patterns of Flask and turns your Flask's app.config in to a dynaconf instance. Initialize the extension Initialize the FlaskDynaconf extension in your app from flask import Flask from dynaconf import FlaskDynaconf app = Flask(__name__) FlaskDynaconf(app) You can optionally use init_app as well. Use FLASK_ environment variables Then the app.config will work as a dynaconf.settings instance and FLASK_ will be the global prefix for exporting environment variables. Example: export FLASK_DEBUG=true # app.config.DEBUG export FLASK_INTVALUE=1 # app.config['INTVALUE'] export FLASK_MAIL_SERVER='host.com' # app.config.get('MAIL_SERVER') Settings files You can also have settings files for your Flask app, in the root directory (the same where you execute flask run ) put your settings.toml and .secrets.toml files and then define your environments [default] , [development] and [production] . To switch the working environment the FLASK_ENV variable can be used, so FLASK_ENV=development to work in development mode or FLASK_ENV=production to switch to production. IMPORTANT : To use $ dynaconf CLI the FLASK_APP must be defined. IF you don't want to manually create your config files take a look at the CLI Customizations It is possible to customize how your Flask project will load settings, example: You want your users to customize a settings file defined in export PROJECTNAME_SETTINGS=/path/to/settings.toml and you want environment variables to be loaded from PROJECTNAME_VARNAME your flask app.py (or wherever you setup dynaconf) ENVVAR_PREFIX_FOR_DYNACONF = \"PROJECTNAME\" \"\"\"This defines which environment variable global prefix dynaconf will load That means that `export PROJECTNAME_FOO=1` will be loaded to `app.config.FOO On command line it is possible to check it with `dynaconf list -k foo`\"\"\" ENVVAR_FOR_DYNACONF = \"PROJECTNAME_SETTINGS\" \"\"\"This defines which path dynaconf will look to load config files example: export PROJECTNAME_SETTINGS=/path/to/settings.toml and the format can be .ini, .json, .yaml or .toml e.g:: export PROJECTNAME_SETTINGS=settings.toml [default] FOO = 1 [development] FOO = 2 [production] FOO = 3 OR:: export PROJECTNAME_SETTINGS=settings.yaml default: foo: 1 development: foo: 2 production: foo: 3 It is also possible to pass a list of files:: export PROJECTNAME_SETTINGS=settings.toml,other_settings.yaml,another.json The variables will be cascaded in the defined order (last wins the precedence) The environment variables wins precedence over all! \"\"\" # load dynaconf app = Flask(__name__) FlaskDynaconf( app, ENVVAR_PREFIX_FOR_DYNACONF=ENVVAR_PREFIX_FOR_DYNACONF, ENVVAR_FOR_DYNACONF=ENVVAR_FOR_DYNACONF ) Then the working environment can now be switched using export PROJECTNAME_ENV=production Loading Flask Extensions Dynamically You can tell Dynaconf to load your Flask Extensions dynamically as long as the extensions follows the Pattens of Flask extensions. The only requirement is that the extension must be a callable that accepts app as first argument. e.g: flask_admin:Admin or custom_extension.module:init_app and of course the extension must be in Python namespace to be imported. For extensions initialized just use the class or function path like: \"flask_admin:Admin\" or \"extension.module:init_app\" having a settings.toml [default] EXTENSIONS = [ \"flask_admin:Admin\", \"flask_bootstrap:Bootstrap\", \"custom_extension.module:init_app\" ] Considering an app.py like: from flask import Flask from dynaconf import FlaskDynaconf app = Flask(__name__) flask_dynaconf = FlaskDynaconf(app) app.config.load_extensions() Optionally you can pass load_extensions(key=\"OTHER_NAME\") pointing to your list of extensions. It is also possible to use environment variables to set the extensions to be loaded. # .env export FLASK_EXTENSIONS=\"['flask_admin:Admin']\" The extensions will be loaded in order. Develoment extensions It is also possible to have extensions that loads only in development environment. [default] EXTENSIONS = [ \"flask_admin:Admin\", \"flask_bootstrap:Bootstrap\", \"custom_extension.module:init_app\" ] [development] EXTENSIONS = [ \"dynaconf_merge\", \"flask_debugtoolbar:DebugToolbar\" ]","title":"Flask"},{"location":"guides/flask/#flask-extension","text":"Dynaconf provides a drop in replacement for app.config . As Flask encourages the composition by overriding the config_class attribute this extension follows the patterns of Flask and turns your Flask's app.config in to a dynaconf instance.","title":"Flask Extension"},{"location":"guides/flask/#initialize-the-extension","text":"Initialize the FlaskDynaconf extension in your app from flask import Flask from dynaconf import FlaskDynaconf app = Flask(__name__) FlaskDynaconf(app) You can optionally use init_app as well.","title":"Initialize the extension"},{"location":"guides/flask/#use-flask_-environment-variables","text":"Then the app.config will work as a dynaconf.settings instance and FLASK_ will be the global prefix for exporting environment variables. Example: export FLASK_DEBUG=true # app.config.DEBUG export FLASK_INTVALUE=1 # app.config['INTVALUE'] export FLASK_MAIL_SERVER='host.com' # app.config.get('MAIL_SERVER')","title":"Use FLASK_ environment variables"},{"location":"guides/flask/#settings-files","text":"You can also have settings files for your Flask app, in the root directory (the same where you execute flask run ) put your settings.toml and .secrets.toml files and then define your environments [default] , [development] and [production] . To switch the working environment the FLASK_ENV variable can be used, so FLASK_ENV=development to work in development mode or FLASK_ENV=production to switch to production. IMPORTANT : To use $ dynaconf CLI the FLASK_APP must be defined. IF you don't want to manually create your config files take a look at the CLI","title":"Settings files"},{"location":"guides/flask/#customizations","text":"It is possible to customize how your Flask project will load settings, example: You want your users to customize a settings file defined in export PROJECTNAME_SETTINGS=/path/to/settings.toml and you want environment variables to be loaded from PROJECTNAME_VARNAME your flask app.py (or wherever you setup dynaconf) ENVVAR_PREFIX_FOR_DYNACONF = \"PROJECTNAME\" \"\"\"This defines which environment variable global prefix dynaconf will load That means that `export PROJECTNAME_FOO=1` will be loaded to `app.config.FOO On command line it is possible to check it with `dynaconf list -k foo`\"\"\" ENVVAR_FOR_DYNACONF = \"PROJECTNAME_SETTINGS\" \"\"\"This defines which path dynaconf will look to load config files example: export PROJECTNAME_SETTINGS=/path/to/settings.toml and the format can be .ini, .json, .yaml or .toml e.g:: export PROJECTNAME_SETTINGS=settings.toml [default] FOO = 1 [development] FOO = 2 [production] FOO = 3 OR:: export PROJECTNAME_SETTINGS=settings.yaml default: foo: 1 development: foo: 2 production: foo: 3 It is also possible to pass a list of files:: export PROJECTNAME_SETTINGS=settings.toml,other_settings.yaml,another.json The variables will be cascaded in the defined order (last wins the precedence) The environment variables wins precedence over all! \"\"\" # load dynaconf app = Flask(__name__) FlaskDynaconf( app, ENVVAR_PREFIX_FOR_DYNACONF=ENVVAR_PREFIX_FOR_DYNACONF, ENVVAR_FOR_DYNACONF=ENVVAR_FOR_DYNACONF ) Then the working environment can now be switched using export PROJECTNAME_ENV=production","title":"Customizations"},{"location":"guides/flask/#loading-flask-extensions-dynamically","text":"You can tell Dynaconf to load your Flask Extensions dynamically as long as the extensions follows the Pattens of Flask extensions. The only requirement is that the extension must be a callable that accepts app as first argument. e.g: flask_admin:Admin or custom_extension.module:init_app and of course the extension must be in Python namespace to be imported. For extensions initialized just use the class or function path like: \"flask_admin:Admin\" or \"extension.module:init_app\" having a settings.toml [default] EXTENSIONS = [ \"flask_admin:Admin\", \"flask_bootstrap:Bootstrap\", \"custom_extension.module:init_app\" ] Considering an app.py like: from flask import Flask from dynaconf import FlaskDynaconf app = Flask(__name__) flask_dynaconf = FlaskDynaconf(app) app.config.load_extensions() Optionally you can pass load_extensions(key=\"OTHER_NAME\") pointing to your list of extensions. It is also possible to use environment variables to set the extensions to be loaded. # .env export FLASK_EXTENSIONS=\"['flask_admin:Admin']\" The extensions will be loaded in order.","title":"Loading Flask Extensions Dynamically"},{"location":"guides/flask/#develoment-extensions","text":"It is also possible to have extensions that loads only in development environment. [default] EXTENSIONS = [ \"flask_admin:Admin\", \"flask_bootstrap:Bootstrap\", \"custom_extension.module:init_app\" ] [development] EXTENSIONS = [ \"dynaconf_merge\", \"flask_debugtoolbar:DebugToolbar\" ]","title":"Develoment extensions"},{"location":"guides/modules/","text":"ToDo","title":"Module reference"},{"location":"guides/modules/#todo","text":"","title":"ToDo"},{"location":"guides/sensitive_secrets/","text":"Sensitive secrets Using .secrets files To safely store sensitive data Dynaconf also searches for a .secrets.{toml|py|json|ini|yaml} file to look for data like tokens and passwords. example .secrets.toml : [default] password = \"sek@987342$\" The secrets file supports all the environment definitions supported in the settings file. IMPORTANT : The reason to use a .secrets.* file is the ability to omit this file when committing to the repository so a recommended .gitignore should include .secrets.* line. Using Vault server The vaultproject.io/ is a key:value store for secrets and Dynaconf can load variables from a Vault secret. Run a vault server Run a Vault server installed or via docker: $ docker run -d -e 'VAULT_DEV_ROOT_TOKEN_ID=myroot' -p 8200:8200 vault Install support for vault in dynaconf $ pip install dynaconf[vault] In your .env file or in exported environment variables define: VAULT_ENABLED_FOR_DYNACONF=true VAULT_URL_FOR_DYNACONF=\"http://localhost:8200\" VAULT_TOKEN_FOR_DYNACONF=\"myroot\" Now you can have keys like PASSWORD and TOKEN defined in the vault and dynaconf will read it. To write a new secret you can use http://localhost:8200 web admin and write keys under the /secret/dynaconf/< env > secret database. You can also use the Dynaconf writer via console: # writes {'password': 123456} to secret/dynaconf/default $ dynaconf write vault -s password=123456 # writes {'password': 123456, 'username': 'admin'} to secret/dynaconf/default $ dynaconf write vault -s password=123456 -s username=admin # writes {'password': 555555} to secret/dynaconf/development $ dynaconf write vault -s password=555555 -e development # writes {'password': 777777, 'username': 'admin'} to secret/dynaconf/production $ dynaconf write vault -s password=777777 -s username=produser -e production then you can access values normally in your program from dynaconf import settings settings.PASSWORD == 555555 # if ENV_FOR_DYNACONF is the default `development` settings.USERNAME == 'admin' # if ENV_FOR_DYNACONF is the default `development` settings.PASSWORD == 777777 # if ENV_FOR_DYNACONF is `production` settings.USERNAME == 'produser' # if ENV_FOR_DYNACONF is `production` You can also ask settings to be loaded from specific env with from_env method: settings.from_env('production').PASSWORD == 777777 settings.from_env('production').USERNAME == 'produser' Additional secrets file (for CI, jenkins etc.) It is common to have an extra secrets file that is available only when running on specific CI environment like Jenkins , usually there will be an environment variable pointing to the file. On Jenkins it is done on job settings by exporting the secrets information. Dynaconf can handle this via SECRETS_FOR_DYNACONF environment variable. ex: export SECRETS_FOR_DYNACONF=/path/to/secrets.toml{json|py|ini|yaml} If that variable exists in your environment then Dynaconf will also load it.","title":"Sensitive secrets"},{"location":"guides/sensitive_secrets/#sensitive-secrets","text":"","title":"Sensitive secrets"},{"location":"guides/sensitive_secrets/#using-secrets-files","text":"To safely store sensitive data Dynaconf also searches for a .secrets.{toml|py|json|ini|yaml} file to look for data like tokens and passwords. example .secrets.toml : [default] password = \"sek@987342$\" The secrets file supports all the environment definitions supported in the settings file. IMPORTANT : The reason to use a .secrets.* file is the ability to omit this file when committing to the repository so a recommended .gitignore should include .secrets.* line.","title":"Using .secrets files"},{"location":"guides/sensitive_secrets/#using-vault-server","text":"The vaultproject.io/ is a key:value store for secrets and Dynaconf can load variables from a Vault secret. Run a vault server Run a Vault server installed or via docker: $ docker run -d -e 'VAULT_DEV_ROOT_TOKEN_ID=myroot' -p 8200:8200 vault Install support for vault in dynaconf $ pip install dynaconf[vault] In your .env file or in exported environment variables define: VAULT_ENABLED_FOR_DYNACONF=true VAULT_URL_FOR_DYNACONF=\"http://localhost:8200\" VAULT_TOKEN_FOR_DYNACONF=\"myroot\" Now you can have keys like PASSWORD and TOKEN defined in the vault and dynaconf will read it. To write a new secret you can use http://localhost:8200 web admin and write keys under the /secret/dynaconf/< env > secret database. You can also use the Dynaconf writer via console: # writes {'password': 123456} to secret/dynaconf/default $ dynaconf write vault -s password=123456 # writes {'password': 123456, 'username': 'admin'} to secret/dynaconf/default $ dynaconf write vault -s password=123456 -s username=admin # writes {'password': 555555} to secret/dynaconf/development $ dynaconf write vault -s password=555555 -e development # writes {'password': 777777, 'username': 'admin'} to secret/dynaconf/production $ dynaconf write vault -s password=777777 -s username=produser -e production then you can access values normally in your program from dynaconf import settings settings.PASSWORD == 555555 # if ENV_FOR_DYNACONF is the default `development` settings.USERNAME == 'admin' # if ENV_FOR_DYNACONF is the default `development` settings.PASSWORD == 777777 # if ENV_FOR_DYNACONF is `production` settings.USERNAME == 'produser' # if ENV_FOR_DYNACONF is `production` You can also ask settings to be loaded from specific env with from_env method: settings.from_env('production').PASSWORD == 777777 settings.from_env('production').USERNAME == 'produser'","title":"Using Vault server"},{"location":"guides/sensitive_secrets/#additional-secrets-file-for-ci-jenkins-etc","text":"It is common to have an extra secrets file that is available only when running on specific CI environment like Jenkins , usually there will be an environment variable pointing to the file. On Jenkins it is done on job settings by exporting the secrets information. Dynaconf can handle this via SECRETS_FOR_DYNACONF environment variable. ex: export SECRETS_FOR_DYNACONF=/path/to/secrets.toml{json|py|ini|yaml} If that variable exists in your environment then Dynaconf will also load it.","title":"Additional secrets file (for CI, jenkins etc.)"},{"location":"guides/testing/","text":"Testing For testing it is recommended to just switch to testing environment and read the same config files. settings.toml [default] value = \"On Default\" [testing] value = \"On Testing\" program.py from dynaconf import settings print(settings.VALUE) ENV_FOR_DYNACONF=testing python program.py Then your program.py will print \"On Testing\" red from [testing] environment. Pytest For pytest it is common to create fixtures to provide pre-configured settings object or to configure the settings before all the tests are collected. Examples available on https://github.com/rochacbruno/dynaconf/tree/master/example/pytest_example With pytest fixtures it is recommended to use the FORCE_ENV_FOR_DYNACONF isntead of just ENV_FOR_DYNACONF because it has precedence. A python program settings.toml with the [testing] environment. [default] VALUE = \"On Default\" [testing] VALUE = \"On Testing\" app.py that reads that value from current environment. from dynaconf import settings def return_a_value(): return settings.VALUE tests/conftest.py with a fixture to force settings to run pointing to [testing] environment. import pytest from dynaconf import settings @pytest.fixture(scope=\"session\", autouse=True) def set_test_settings(): settings.configure(FORCE_ENV_FOR_DYNACONF=\"testing\") tests/test_dynaconf.py to assert that the correct environment is loaded from app import return_a_value def test_dynaconf_is_in_testing_env(): assert return_a_value() == \"On Testing\" A Flask program settings.toml with the [testing] environment. [default] VALUE = \"On Default\" [testing] VALUE = \"On Testing\" src.py that has a Flask application factory from flask import Flask from dynaconf.contrib import FlaskDynaconf def create_app(**config): app = Flask(__name__) FlaskDynaconf(app, **config) return app tests/conftest.py with a fixture to provide app dependency injection to all the tests, And force this app to point to [testing] config environment. import pytest from src import create_app @pytest.fixture(scope=\"session\") def app(): app = create_app(FORCE_ENV_FOR_DYNACONF=\"testing\") return app tests/test_flask_dynaconf.py to assert that the correct environment is loaded def test_dynaconf_is_on_testing_env(app): assert app.config[\"VALUE\"] == \"On Testing\" assert app.config.current_env == \"testing\" Mocking But it is common in unit tests to mock some objects and you may need in rare cases to mock the dynaconf.settings when running your tests. from dynaconf.utils import DynaconfDict mocked_settings = DynaconfDict({'FOO': 'BAR'}) DynaconfDict is a dict like obj that can be populated from a file: from dynaconf.loaders import toml_loader toml_loader.load(mocked_settings, filename='my_file.toml', env='testing')","title":"Testing"},{"location":"guides/testing/#testing","text":"For testing it is recommended to just switch to testing environment and read the same config files. settings.toml [default] value = \"On Default\" [testing] value = \"On Testing\" program.py from dynaconf import settings print(settings.VALUE) ENV_FOR_DYNACONF=testing python program.py Then your program.py will print \"On Testing\" red from [testing] environment.","title":"Testing"},{"location":"guides/testing/#pytest","text":"For pytest it is common to create fixtures to provide pre-configured settings object or to configure the settings before all the tests are collected. Examples available on https://github.com/rochacbruno/dynaconf/tree/master/example/pytest_example With pytest fixtures it is recommended to use the FORCE_ENV_FOR_DYNACONF isntead of just ENV_FOR_DYNACONF because it has precedence.","title":"Pytest"},{"location":"guides/testing/#a-python-program","text":"settings.toml with the [testing] environment. [default] VALUE = \"On Default\" [testing] VALUE = \"On Testing\" app.py that reads that value from current environment. from dynaconf import settings def return_a_value(): return settings.VALUE tests/conftest.py with a fixture to force settings to run pointing to [testing] environment. import pytest from dynaconf import settings @pytest.fixture(scope=\"session\", autouse=True) def set_test_settings(): settings.configure(FORCE_ENV_FOR_DYNACONF=\"testing\") tests/test_dynaconf.py to assert that the correct environment is loaded from app import return_a_value def test_dynaconf_is_in_testing_env(): assert return_a_value() == \"On Testing\"","title":"A python program"},{"location":"guides/testing/#a-flask-program","text":"settings.toml with the [testing] environment. [default] VALUE = \"On Default\" [testing] VALUE = \"On Testing\" src.py that has a Flask application factory from flask import Flask from dynaconf.contrib import FlaskDynaconf def create_app(**config): app = Flask(__name__) FlaskDynaconf(app, **config) return app tests/conftest.py with a fixture to provide app dependency injection to all the tests, And force this app to point to [testing] config environment. import pytest from src import create_app @pytest.fixture(scope=\"session\") def app(): app = create_app(FORCE_ENV_FOR_DYNACONF=\"testing\") return app tests/test_flask_dynaconf.py to assert that the correct environment is loaded def test_dynaconf_is_on_testing_env(app): assert app.config[\"VALUE\"] == \"On Testing\" assert app.config.current_env == \"testing\"","title":"A Flask program"},{"location":"guides/testing/#mocking","text":"But it is common in unit tests to mock some objects and you may need in rare cases to mock the dynaconf.settings when running your tests. from dynaconf.utils import DynaconfDict mocked_settings = DynaconfDict({'FOO': 'BAR'}) DynaconfDict is a dict like obj that can be populated from a file: from dynaconf.loaders import toml_loader toml_loader.load(mocked_settings, filename='my_file.toml', env='testing')","title":"Mocking"},{"location":"guides/usage/","text":"Getting Started Installation Python 3.x is required $ pip install dynaconf Default installation supports .toml, .py and .json file formats and also environment variables (.env supported) - to support YAML add pip install dynaconf[yaml] or pip install dynaconf[all] Usage Accessing config variables in your Python application In your Python program wherever you need to access a settings variable you use the canonical object from dynaconf import settings : Example of program to connect to some database from some.db import Client from dynaconf import settings conn = Client( username=settings.USERNAME, # attribute style access password=settings.get('PASSWORD'), # dict get style access port=settings['PORT'], # dict item style access timeout=settings.as_int('TIMEOUT'), # Forcing casting if needed host=settings.get('HOST', 'localhost') # Providing defaults ) Understanding the settings Dynaconf aims to have a flexible and usable configuration system. Your applications can be configured via a configuration files , through environment variables , or both. Configurations can be separated into environments: [default], [development], [staging], [testing] and [production] . The working environment is switched via an environment variable. But this is all optional you can of course follow strictly the 12 factor app guide, have your configuration coming only from environment variables and provide files only to store [default] values. (take also a look on how to add a dynaconf validation file to your project). Sensitive data like tokens, secret keys and password can be stored in .secrets.* files and/or external storages like Redis or vault secrets server. Besides the built-in optional support to Redis as settings storage dynaconf allows you to create Custom Loaders and store the data wherever you want e.g: databases, memory storages, other file formats, nosql databases etc. Working environments At any point in time, your application is operating in a given configuration environment. By default there are four such environments: [development] (selected by default) [staging] [testing] [production] [{custom}] <-- You can create named environments that you need There is also the pseudo-envs [default] to provide comprehensive default values and [global] to provide global values to override in any other environment. Without any action, your applications by default run in the [development] environment. The environment can be changed via the ENV_FOR_DYNACONF environment variable. For example, to launch an application in the [staging] environment, we can run: export ENV_FOR_DYNACONF=staging or ENV_FOR_DYNACONF=staging python yourapp.py NOTE: When using Flask Extension the environment can be changed via FLASK_ENV variable and for Django Extension you can use DJANGO_ENV . The settings files NOTE: The settings files are optional. If it is not present, only the values from environment variables and enabled external loaders are used ( .env file is also supported). Dynaconf will search for the settings files defined in SETTINGS_FILE_FOR_DYNACONF which by default is a list containing combinations of settings.{py|toml|json|ini|yaml} and .secrets.{py|toml|json|ini|yaml} and dynaconf will try to find each one of those combinations, optionally it is possible to configure it to a different set of files e.g: export SETTINGS_FILE_FOR_DYNACONF='[\"myfilename.toml\", \"another.json\"]' , this value contains a list of relative or absolute paths, can be a toml-like list or a comma/semicolon separated string and can be exported to envvars , write to .env file or passed directly to Dynaconf instance. IMPORTANT: Dynaconf by default reads settings files using utf-8 encoding, if you have settings files written in other encoding please set ENCODING_FOR_DYNACONF environment variable. See more details in configuration Settings files location To find the files defined in SETTINGS_FILE_FOR_DYNACONF the search will start at the path defined in ROOT_PATH_FOR_DYNACONF (if defined), then will recursively walk to its root and then will try the folder where the called program is located and then it will recursively try its parent directories until the root parent is reached which can be File System / or the current working dir then finally will try the current working directory as the last option. NOTE : If by any reason you need Dynaconf to first look at the current working dir you can customize the ROOT_PATH_FOR_DYNACONF via environment variable or by creating a custom settings object Some people prefer to put settings in a sub-folder so for each of the paths it will also search in a relative folder called config/ . And for each file dynaconf will also try to load a .local. file, for example, if you have a settings.toml after loading it Dynaconf will also try to find a settings.local.toml if exists. Dynaconf will stop searching on the first match for each file and if no file is found it will fail silently unless SILENT_ERRORS_FOR_DYNACONF=false is exported. Illustrative Example New in 2.0.0 If your program has the following structure: |_ myprogram/ |_ src/ |_ app.py # from dynaconf import settings # print(settings.NAME) # print(settings.PASSWORD) # print(settings.FOO) |_ config |_ settings.toml # [default] # name = \"Jon Doe\" |_ settings.local.toml # [default] # name = \"Oscar Wilde\" |_ .env # DYNACONF_FOO='BAR' |_ .secrets.toml # [default] # password = \"Utopi@\" And you call it from myprogram working dir. cd myprogram python src/app.py What happens is: NOTE: The behavior explained here is valid only for the above file structure, other arrangements are possible and depending on how folders are organized dynaconf can behave differently. app.py:1 does from dynaconf import settings Only the .env file will be searched, other settings are lazy evaluated. .env will be searched starting on myprogram/src/.env if not found then myprogram/src/config/.env if not found then myprogram/.env actually found here so stops searching if not found then myprogram/config/.env It will load all values from .env to the environment variables and create the instance of settings app.py:2 does the first access to a settings on print(settings.NAME) Dynaconf will execute the loaders defined in CORE_LOADERS and LOADERS , it will initialize the settings object and start the file search. settings.{py|toml|json|ini|yaml} will be searched on myprogram/src/ if not found then myprogram/src/config if not found then myprogram/ if not found then myprogram/config settings.toml actually found here so stops searching for toml It will load all the values defined in the settings.toml It will continue to look all the other files e.g: settings.json, settings.ini, settings.yaml etc. Then It will search for .secrets.{py|toml|json|ini|yaml} on myprogram/src/ if not found then myprogram/src/config if not found then myprogram/ .secrets.toml actually found here so stops searching for toml if not found then myprogram/config It will load all the values defined in .secrets.toml (if filename is *.secret.* values are hidden on logs) It will continue to look all the other files e.g: .secrets.json, .secrets.ini, .secrets.yaml etc. Then It will iterate the list of loaded files containing [settings.toml, .secrets.toml] and for each of them it will also try to find a settings.local.toml ( found in myprogram/settings.local.toml ) and a .secrets.local.toml using the same search tree until it is found or it will skip if not found. Then It will execute external loaders like Redis and Vault if enabled. It will execute custom loaders if configured. Then finally It will read all environment variables prefixed with DYNACONF_ and load its values, in our example it loads FOO='BAR' from .env file. app.py:3 does second access to a settings on print(settings.PASSWORD) All the loaders, loaded files, config options and vars are now cached no loading has been executed. Only if settings.get_fresh('PASSWORD') is used, dynaconf will force a re-load of everything to ensure the fresh value. Also if settings.using_env|from_env or ENV_FOR_DYNACONF switched, e.g: from [development] to [staging] , then re-load happens. It is also possible to explicitly force a load or reload . Complete program output is: Oscar Wilde Utopi@ BAR TIP: If you add DEBUG_LEVEL_FOR_DYNACONF=DEBUG on .env or export this variable then you can follow the dynaconf loading process. Loading order Dynaconf loads file in a overriding cascade loading order using the predefined order: First the environment variables (and .env file) to read for configuration options Then the paths provided in PRELOAD_FOR_DYNACONF using all enabled loaders. Then the files defined in SETTINGS_FILE_FOR_DYNACONF using all enabled loaders. Files containing .local. in its name will be loaded at the end. e.g: settings.local.yaml Then contents of SECRETS_FOR_DYNACONF envvar filename if defined (useful for jenkins and other CI) Then the loaders defined in LOADERS_FOR_DYNACONF Redis if enabled by REDIS_FOR_DYNACONF=1 Vault if enabled by Vault_FOR_DYNACONF=1 Custom loaders if any added Environment variables loader will be the last always If there is any DYNACONF_INCLUDE key found or INCLUDES_FOR_DYNACONF env vars this will be loaded. The order can be changed by overriding the SETTINGS_FILE_FOR_DYNACONF the CORE_LOADERS_FOR_DYNACONF and LOADERS_FOR_DYNACONF variables. NOTE : Dynaconf works in an layered override mode based on the above order, so if you have multiple file formats with conflicting keys defined, the precedence will be based on the loading order. If you dont want to have values like lists and dicts overwritten take a look on how to merge existing values Local configuration files and merging to existing data New in 2.2.0 This feature is useful for maintaining a shared set of config files for a team, while still allowing for local configuration. Any file matched by the glob *.local.* will be read at the end of file loading order. So it is possible to have local settings files that are for example not committed to the version controlled repository. (e:g add **/*.local* to your .gitignore ) So if you have settings.toml Dynaconf will load it and after all will also try to load a file named settings.local.toml if it does exist. And the same applies to all the other supported extensions settings.local.{py,json,yaml,toml,ini,cfg} Example: # settings.toml # <-- 1st loaded [default] colors = [\"green\", \"blue\"] parameters = {enabled=true, number=42} # .secrets.toml # <-- 2nd loaded (overrides previous existing vars) [default] password = 1234 # settings.local.toml # <-- 3rd loaded (overrides previous existing vars) [default] colors = [\"pink\"] parameters = {enabled=false} password = 9999 So with above the values will be: settings.COLORS == [\"pink\"] settings.PARAMETERS == {\"enabled\": False} settings.PASSWORD == 9999 For each loaded file dynaconf will override previous existing keys so if you want to append new values to existing variables you can use 3 strategies. Mark the local file to be entirely merged New in 2.2.0 # settings.local.toml dynaconf_merge = true [default] colors = [\"pink\"] parameters = {enabled=false} By adding dynaconf_merge to the top root of the file mark entire file to be merged. And then the values will be updated in to existing data structures. settings.COLORS == [\"pink\", \"green\", \"blue\"] settings.PARAMETERS == {\"enabled\": False, \"number\": 42} settings.PASSWORD == 9999 You can also mark a single env like [development] to be merged. # settings.local.toml [development] dynaconf_merge = true colors = [\"pink\"] parameters = {enabled=false} dynaconf merge token # settings.local.toml [default] colors = [\"pink\", \"dynaconf_merge\"] parameters = {enabled=false, dynaconf_merge=true} By adding dynaconf_merge to a list or dict marks it as a merge candidate. And then the values will be updated in to existing data structures. settings.COLORS == [\"pink\", \"green\", \"blue\"] settings.PARAMETERS == {\"enabled\": False, \"number\": 42} settings.PASSWORD == 9999 New in 2.2.0 And it also works having dynaconf_merge as dict keys holding the value to be merged. # settings.local.toml [default.colors] dynaconf_merge = [\"pink\"] # <-- value [\"pink\"] will be merged in to existing colors [default.parameters] dynaconf_merge = {enabled=false} Dunder merging for nested structures For nested structures the recommendation is to use dunder merging because it it easier to read and also it has no limitations in terms of nesting levels. # settings.local.yaml [default] parameters__enabled = false The use of __ to denote nested level will ensure the key is merged with existing values read more in merging existing values . Global merge export MERGE_ENABLED_FOR_DYNACONF=true or put it in your .env file then Dynaconf will automatically merge all existing variables. BEWARE : Using MERGE_ENABLED_FOR_DYNACONF can lead to unexpected results because you do not have granular control of what is being merged or overwritten so the recommendation is to use other options. Settings File Formats The recommended file format is TOML but you can choose to use any of .{py|toml|json|ini|yaml} . The file must be a series of sections, at least one for [default] , optionally one for each [environment] , and an optional [global] section. Each section contains key-value pairs corresponding to configuration parameters for that [environment] . If a configuration parameter is missing, the value from [default] is used. The following is a complete settings.toml file, where every standard configuration parameter is specified within the [default] section: NOTE : if the file format choosen is .py as it does not support sections you can create multiple files like settings.py for [default], development_settings.py , production_settings.py and global_settings.py . ATTENTION : using .py is not recommended for configuration - prefer to use static files like TOML ! [default] username = \"admin\" port = 5000 host = \"localhost\" message = \"default message\" value = \"default value\" [development] username = \"devuser\" [staging] host = \"staging.server.com\" [testing] host = \"testing.server.com\" [production] host = \"server.com\" [awesomeenv] value = \"this value is set for custom [awesomeenv]\" [global] message = \"This value overrides message of default and other envs\" The [global] pseudo-environment can be used to set and/or override configuration parameters globally. A parameter defined in a [global] section sets, or overrides if already present, that parameter in every environment. IMPORTANT: the environments and pseudo envs such as [global], ['default'] affects only the current file, it means that a value in [global] will override values defined only on that file or previous loaded files, if in another file the value is reloaded then the global values is overwritten. Dynaconf supports multiple file formats but the recommendation is not to mix them, choose a format and stick with it. For example, given the following settings.toml file, the value of address will be \"1.2.3.4\" in every environment: [global] address = \"1.2.3.4\" [development] address = \"localhost\" [production] address = \"0.0.0.0\" NOTE : The [env] name and first level variables are case insensitive as internally dynaconf will always use upper case, that means [development] and [DEVELOPMENT] are equivalent and address and ADDRESS are also equivalent. But the recommendation is to always use lower case in files and always use upper case in env vars and .py files (This rule does not apply for inner data structures as dictionaries and arrays). Supported file formats By default toml is the recommended format to store your configuration, however you can switch to a different supported format. # If you wish to include support for more sources pip3 install dynaconf[yaml|ini|redis|vault] # for a complete installation pip3 install dynaconf[all] Once the support is installed no extra configuration is needed to load data from those files. If you need a different file format take a look on how to extend dynaconf writing a custom loader Additional secrets file (for CI, jenkins etc.) It is common to have an extra secrets file that is available only when running on specific CI environment like Jenkins , usually there will be an environment variable pointing to the file. On Jenkins it is done on job settings by exporting the secrets information. Dynaconf can handle this via SECRETS_FOR_DYNACONF environment variable. ex: export SECRETS_FOR_DYNACONF=/path/to/settings.toml{json|py|ini|yaml} If that variable exists in your environment then Dynaconf will also load it. Including files inside files Sometimes you have multiple fragments of settings in different files, dynaconf allow easy merging of those files via dynaconf_include . Example: plugin1.toml [development] plugin_specific_variable = 'value for development' and even mixing different formats: plugin2.yaml production: plugin_specific_variable: 'value for production' Then it can be merged on main settings.toml file via dynaconf_include settings.toml [default] dynaconf_include = [\"plugin1.toml\", \"plugin2.yaml\"] DEBUG = false SERVER = \"base.example.com\" PORT = 6666 A settings file can include a dynaconf_include stanza, whose exact syntax will depend on the type of settings file (json, yaml, toml, etc) being used: cfg [default] dynaconf_include = [\"/absolute/path/to/plugin1.toml\", \"relative/path/to/plugin2.toml\"] DEBUG = false SERVER = \"www.example.com\" When loaded, the files located at the (relative or absolute) paths in the dynaconf_include key will be parsed, in order, and override any base settings that may exist in your current configuration. The paths can be relative to the base settings.(toml|yaml|json|ini|py) file, or can be absolute paths. The idea here is that plugins or extensions for whatever framework or architecture you are using can provide their own configuration values when necessary. It is also possible to specify glob-based patterns: cfg [default] dynaconf_include = [\"configurations/*.toml\"] DEBUG = false SERVER = \"www.example.com\" Currently, only a single level of includes is permitted to keep things simple and straightforward. Including via environment variable It is also possible to setup includes using environment variable. # A glob pattern export INCLUDES_FOR_DYNACONF='/etc/myprogram/conf.d/*.toml' # a single path export INCLUDES_FOR_DYNACONF='/path/to/file.yaml' # multiple files export INCLUDES_FOR_DYNACONF='/path/to/file.yaml;/other/path/to/file.toml' Programmatically loading a settings file from dynaconf import settings settings.load_file(path=\"/path/to/file.toml\") # list or `;/,` separated allowed NOTE : programmatically loaded file is not persisted, once env is changed via setenv|ugin_env , or a reload or configure is invoked it will be cleaned, to persist it needs to go to INCLUDES_FOR_DYNACONF variable or you need to load it programmatically again. Template substitutions Dynaconf has 2 tokens to enable string substitutions @format and @jinja . @format token Dynaconf allows template substitutions for strings values, by using the @format token prefix and including placeholders accepted by Python's str.format method Dynaconf will call it lazily upon access time. The call will be like: \"<YOURVALUE>\".format(env=os.environ, this=dynaconf.settings) So in your string you can refer to environment variables via env object, and also to variables defined int the settings object itself via this reference. It is lazily evaluated on access it will use the final value for a settings regardless the order of load. Example: export PROGRAM_NAME=calculator settings.toml [default] DB_NAME = \"mydb.db\" [development] DB_PATH = \"@format {env[HOME]}/{this.current_env}/{env[PROGRAM_NAME]}/{this.DB_NAME}\" {env[HOME]} is the same as os.environ[\"HOME\"] or $HOME in the shell. {this.current_env} is the same as settings.current_env {env[PROGRAM_NAME]} is the same as os.environ[\"PROGRAM_NAME\"] or $PROGRAM_NAME in the shell. {this.DB_NAME} is the same as settins.DB_NAME or settings[\"DB_NAME\"] so in your program from dynaconf import settings settings.DB_PATH == '~/DEVELOPMENT/calculator/mydb.db' @jinja token If jinja2 package is installed then dynaconf will also allow the use jinja to render string values. Example: export PROGRAM_NAME=calculator settings.toml [default] DB_NAME = \"mydb.db\" [development] DB_NAME = \"@jinja {{env.HOME}}/{{this.current_env | lower}}/{{env[\"PROGRAM_NAME\"]}}/{{this.DB_NAME}}\" so in your program from dynaconf import settings settings.DB_PATH == '~/development/calculator/mydb.db' The main difference is that Jinja allows some Python expressions to be avaluated such as {% for, if, while %} and also supports calling methods and has lots of filters like | lower . Jinja supports its built-in filters listed in Builtin Filters Page and Dynaconf includes aditional filters for os.path module: abspath . realpath , relpath , basename and dirname and usage is like: VALUE = \"@jinja {{this.FOO | abspath}}\" Merging existing data structures If your settings has existing variables of types list ot dict and you want to merge instead of override then the dynaconf_merge and dynaconf_merge_unique stanzas can mark that variable as a candidate for merging. For dict value: Your main settings file (e.g settings.toml ) has an existing DATABASE dict setting on [default] env. Now you want to contribute to the same DATABASE key by adding new keys, so you can use dynaconf_merge at the end of your dict: In specific [envs] [default] database = {host=\"server.com\", user=\"default\"} [development] database = {user=\"dev_user\", dynaconf_merge=true} [production] database = {user=\"prod_user\", dynaconf_merge=true} also allowed the alternative short format [default] database = {host=\"server.com\", user=\"default\"} [development.database] dynaconf_merge = {user=\"dev_user\"} [production.database] dynaconf_merge = {user=\"prod_user\"} In an environment variable: Using @merge mark # Toml formatted envvar export DYNACONF_DATABASE='@merge {password=1234}' or @merge mark short format # Toml formatted envvar export DYNACONF_DATABASE='@merge password=1234' It is also possible to use nested dunder traversal like: export DYNACONF_DATABASE__password=1234 export DYNACONF_DATABASE__user=admin export DYNACONF_DATABASE__ARGS__timeout=30 export DYNACONF_DATABASE__ARGS__retries=5 Each __ is parsed as a level traversing thought dict keys. read more in environment variables So the above will result in DATABASE = {'password': 1234, 'user': 'admin', 'ARGS': {'timeout': 30, 'retries': 5}} IMPORTANT lower case keys are respected only on *nix systems, unfortunately Windows environment variables are case insensitive and Python reads it as all upper cases, that means that if you are running on Windows the dictionary can have only upper case keys. You can also export a toml dictionary. # Toml formatted envvar export DYNACONF_DATABASE='{password=1234, dynaconf_merge=true}' Or in an additional file (e.g settings.yaml, .secrets.yaml, etc ) by using dynaconf_merge token: default: database: password: 1234 dynaconf_merge: true or default: database: dynaconf_merge: password: 1234 The dynaconf_merge token will mark that object to be merged with existing values (of course dynaconf_merge key will not be added to the final settings it is just a mark) The end result will be on [development] env: settings.DATABASE == {'host': 'server.com', 'user': 'dev_user', 'password': 1234} The same can be applied to lists : settings.toml [default] plugins = [\"core\"] [development] plugins = [\"debug_toolbar\", \"dynaconf_merge\"] or [default] plugins = [\"core\"] [development.plugins] dynaconf_merge = [\"debug_toolbar\"] And in environment variable using @merge token export DYNACONF_PLUGINS='@merge [\"ci_plugin\"]' or short version export DYNACONF_PLUGINS='@merge ci_plugin' comma separated values also supported: export DYNACONF_PLUGINS='@merge ci_plugin,other_plugin' or explicitly export DYNACONF_PLUGINS='[\"ci_plugin\", \"dynaconf_merge\"]' Then the end result on [development] is: settings.PLUGINS == [\"ci_plugin\", \"debug_toolbar\", \"core\"] If your value is a dictionary: export DYNACONF_DATA=\"@merge {foo='bar'}\" # or the short export DYNACONF_DATA=\"@merge foo=bar\" Avoiding duplications on lists The dynaconf_merge_unique is the token for when you want to avoid duplications in a list. Example: [default] scripts = ['install.sh', 'deploy.sh'] [development] scripts = ['dev.sh', 'test.sh', 'deploy.sh', 'dynaconf_merge_unique'] export DYNACONF_SCRIPTS='[\"deploy.sh\", \"run.sh\", \"dynaconf_merge_unique\"]' The end result for [development] will be: settings.SCRIPTS == ['install.sh', 'dev.sh', 'test.sh', 'deploy.sh', 'run.sh'] Note that deploy.sh is set 3 times but it is not repeated in the final settings. Known caveats The dynaconf_merge and @merge functionalities works only for the first level keys, it will not merge subdicts or nested lists (yet). For deeper nested objects use dunder merge . Global merge export MERGE_ENABLED_FOR_DYNACONF=true or put it in your .env file then Dynaconf will automatically merge all existing variables. BEWARE : Using MERGE_ENABLED_FOR_DYNACONF can lead to unexpected results because you do not have granular control of what is being merged or overwritten so the recommendation is to use other options. More examples Take a look at the example folder to see some examples of use with different file formats and features.","title":"Getting started"},{"location":"guides/usage/#getting-started","text":"","title":"Getting Started"},{"location":"guides/usage/#installation","text":"Python 3.x is required $ pip install dynaconf Default installation supports .toml, .py and .json file formats and also environment variables (.env supported) - to support YAML add pip install dynaconf[yaml] or pip install dynaconf[all]","title":"Installation"},{"location":"guides/usage/#usage","text":"","title":"Usage"},{"location":"guides/usage/#accessing-config-variables-in-your-python-application","text":"In your Python program wherever you need to access a settings variable you use the canonical object from dynaconf import settings :","title":"Accessing config variables in your Python application"},{"location":"guides/usage/#example-of-program-to-connect-to-some-database","text":"from some.db import Client from dynaconf import settings conn = Client( username=settings.USERNAME, # attribute style access password=settings.get('PASSWORD'), # dict get style access port=settings['PORT'], # dict item style access timeout=settings.as_int('TIMEOUT'), # Forcing casting if needed host=settings.get('HOST', 'localhost') # Providing defaults )","title":"Example of program to connect to some database"},{"location":"guides/usage/#understanding-the-settings","text":"Dynaconf aims to have a flexible and usable configuration system. Your applications can be configured via a configuration files , through environment variables , or both. Configurations can be separated into environments: [default], [development], [staging], [testing] and [production] . The working environment is switched via an environment variable. But this is all optional you can of course follow strictly the 12 factor app guide, have your configuration coming only from environment variables and provide files only to store [default] values. (take also a look on how to add a dynaconf validation file to your project). Sensitive data like tokens, secret keys and password can be stored in .secrets.* files and/or external storages like Redis or vault secrets server. Besides the built-in optional support to Redis as settings storage dynaconf allows you to create Custom Loaders and store the data wherever you want e.g: databases, memory storages, other file formats, nosql databases etc.","title":"Understanding the settings"},{"location":"guides/usage/#working-environments","text":"At any point in time, your application is operating in a given configuration environment. By default there are four such environments: [development] (selected by default) [staging] [testing] [production] [{custom}] <-- You can create named environments that you need There is also the pseudo-envs [default] to provide comprehensive default values and [global] to provide global values to override in any other environment. Without any action, your applications by default run in the [development] environment. The environment can be changed via the ENV_FOR_DYNACONF environment variable. For example, to launch an application in the [staging] environment, we can run: export ENV_FOR_DYNACONF=staging or ENV_FOR_DYNACONF=staging python yourapp.py NOTE: When using Flask Extension the environment can be changed via FLASK_ENV variable and for Django Extension you can use DJANGO_ENV .","title":"Working environments"},{"location":"guides/usage/#the-settings-files","text":"NOTE: The settings files are optional. If it is not present, only the values from environment variables and enabled external loaders are used ( .env file is also supported). Dynaconf will search for the settings files defined in SETTINGS_FILE_FOR_DYNACONF which by default is a list containing combinations of settings.{py|toml|json|ini|yaml} and .secrets.{py|toml|json|ini|yaml} and dynaconf will try to find each one of those combinations, optionally it is possible to configure it to a different set of files e.g: export SETTINGS_FILE_FOR_DYNACONF='[\"myfilename.toml\", \"another.json\"]' , this value contains a list of relative or absolute paths, can be a toml-like list or a comma/semicolon separated string and can be exported to envvars , write to .env file or passed directly to Dynaconf instance. IMPORTANT: Dynaconf by default reads settings files using utf-8 encoding, if you have settings files written in other encoding please set ENCODING_FOR_DYNACONF environment variable. See more details in configuration","title":"The settings files"},{"location":"guides/usage/#settings-files-location","text":"To find the files defined in SETTINGS_FILE_FOR_DYNACONF the search will start at the path defined in ROOT_PATH_FOR_DYNACONF (if defined), then will recursively walk to its root and then will try the folder where the called program is located and then it will recursively try its parent directories until the root parent is reached which can be File System / or the current working dir then finally will try the current working directory as the last option. NOTE : If by any reason you need Dynaconf to first look at the current working dir you can customize the ROOT_PATH_FOR_DYNACONF via environment variable or by creating a custom settings object Some people prefer to put settings in a sub-folder so for each of the paths it will also search in a relative folder called config/ . And for each file dynaconf will also try to load a .local. file, for example, if you have a settings.toml after loading it Dynaconf will also try to find a settings.local.toml if exists. Dynaconf will stop searching on the first match for each file and if no file is found it will fail silently unless SILENT_ERRORS_FOR_DYNACONF=false is exported.","title":"Settings files location"},{"location":"guides/usage/#illustrative-example","text":"New in 2.0.0 If your program has the following structure: |_ myprogram/ |_ src/ |_ app.py # from dynaconf import settings # print(settings.NAME) # print(settings.PASSWORD) # print(settings.FOO) |_ config |_ settings.toml # [default] # name = \"Jon Doe\" |_ settings.local.toml # [default] # name = \"Oscar Wilde\" |_ .env # DYNACONF_FOO='BAR' |_ .secrets.toml # [default] # password = \"Utopi@\" And you call it from myprogram working dir. cd myprogram python src/app.py What happens is: NOTE: The behavior explained here is valid only for the above file structure, other arrangements are possible and depending on how folders are organized dynaconf can behave differently. app.py:1 does from dynaconf import settings Only the .env file will be searched, other settings are lazy evaluated. .env will be searched starting on myprogram/src/.env if not found then myprogram/src/config/.env if not found then myprogram/.env actually found here so stops searching if not found then myprogram/config/.env It will load all values from .env to the environment variables and create the instance of settings app.py:2 does the first access to a settings on print(settings.NAME) Dynaconf will execute the loaders defined in CORE_LOADERS and LOADERS , it will initialize the settings object and start the file search. settings.{py|toml|json|ini|yaml} will be searched on myprogram/src/ if not found then myprogram/src/config if not found then myprogram/ if not found then myprogram/config settings.toml actually found here so stops searching for toml It will load all the values defined in the settings.toml It will continue to look all the other files e.g: settings.json, settings.ini, settings.yaml etc. Then It will search for .secrets.{py|toml|json|ini|yaml} on myprogram/src/ if not found then myprogram/src/config if not found then myprogram/ .secrets.toml actually found here so stops searching for toml if not found then myprogram/config It will load all the values defined in .secrets.toml (if filename is *.secret.* values are hidden on logs) It will continue to look all the other files e.g: .secrets.json, .secrets.ini, .secrets.yaml etc. Then It will iterate the list of loaded files containing [settings.toml, .secrets.toml] and for each of them it will also try to find a settings.local.toml ( found in myprogram/settings.local.toml ) and a .secrets.local.toml using the same search tree until it is found or it will skip if not found. Then It will execute external loaders like Redis and Vault if enabled. It will execute custom loaders if configured. Then finally It will read all environment variables prefixed with DYNACONF_ and load its values, in our example it loads FOO='BAR' from .env file. app.py:3 does second access to a settings on print(settings.PASSWORD) All the loaders, loaded files, config options and vars are now cached no loading has been executed. Only if settings.get_fresh('PASSWORD') is used, dynaconf will force a re-load of everything to ensure the fresh value. Also if settings.using_env|from_env or ENV_FOR_DYNACONF switched, e.g: from [development] to [staging] , then re-load happens. It is also possible to explicitly force a load or reload . Complete program output is: Oscar Wilde Utopi@ BAR TIP: If you add DEBUG_LEVEL_FOR_DYNACONF=DEBUG on .env or export this variable then you can follow the dynaconf loading process.","title":"Illustrative Example"},{"location":"guides/usage/#loading-order","text":"Dynaconf loads file in a overriding cascade loading order using the predefined order: First the environment variables (and .env file) to read for configuration options Then the paths provided in PRELOAD_FOR_DYNACONF using all enabled loaders. Then the files defined in SETTINGS_FILE_FOR_DYNACONF using all enabled loaders. Files containing .local. in its name will be loaded at the end. e.g: settings.local.yaml Then contents of SECRETS_FOR_DYNACONF envvar filename if defined (useful for jenkins and other CI) Then the loaders defined in LOADERS_FOR_DYNACONF Redis if enabled by REDIS_FOR_DYNACONF=1 Vault if enabled by Vault_FOR_DYNACONF=1 Custom loaders if any added Environment variables loader will be the last always If there is any DYNACONF_INCLUDE key found or INCLUDES_FOR_DYNACONF env vars this will be loaded. The order can be changed by overriding the SETTINGS_FILE_FOR_DYNACONF the CORE_LOADERS_FOR_DYNACONF and LOADERS_FOR_DYNACONF variables. NOTE : Dynaconf works in an layered override mode based on the above order, so if you have multiple file formats with conflicting keys defined, the precedence will be based on the loading order. If you dont want to have values like lists and dicts overwritten take a look on how to merge existing values","title":"Loading order"},{"location":"guides/usage/#local-configuration-files-and-merging-to-existing-data","text":"New in 2.2.0 This feature is useful for maintaining a shared set of config files for a team, while still allowing for local configuration. Any file matched by the glob *.local.* will be read at the end of file loading order. So it is possible to have local settings files that are for example not committed to the version controlled repository. (e:g add **/*.local* to your .gitignore ) So if you have settings.toml Dynaconf will load it and after all will also try to load a file named settings.local.toml if it does exist. And the same applies to all the other supported extensions settings.local.{py,json,yaml,toml,ini,cfg} Example: # settings.toml # <-- 1st loaded [default] colors = [\"green\", \"blue\"] parameters = {enabled=true, number=42} # .secrets.toml # <-- 2nd loaded (overrides previous existing vars) [default] password = 1234 # settings.local.toml # <-- 3rd loaded (overrides previous existing vars) [default] colors = [\"pink\"] parameters = {enabled=false} password = 9999 So with above the values will be: settings.COLORS == [\"pink\"] settings.PARAMETERS == {\"enabled\": False} settings.PASSWORD == 9999 For each loaded file dynaconf will override previous existing keys so if you want to append new values to existing variables you can use 3 strategies.","title":"Local configuration files and merging to existing data"},{"location":"guides/usage/#mark-the-local-file-to-be-entirely-merged","text":"New in 2.2.0 # settings.local.toml dynaconf_merge = true [default] colors = [\"pink\"] parameters = {enabled=false} By adding dynaconf_merge to the top root of the file mark entire file to be merged. And then the values will be updated in to existing data structures. settings.COLORS == [\"pink\", \"green\", \"blue\"] settings.PARAMETERS == {\"enabled\": False, \"number\": 42} settings.PASSWORD == 9999 You can also mark a single env like [development] to be merged. # settings.local.toml [development] dynaconf_merge = true colors = [\"pink\"] parameters = {enabled=false}","title":"Mark the local file to be entirely merged"},{"location":"guides/usage/#dynaconf-merge-token","text":"# settings.local.toml [default] colors = [\"pink\", \"dynaconf_merge\"] parameters = {enabled=false, dynaconf_merge=true} By adding dynaconf_merge to a list or dict marks it as a merge candidate. And then the values will be updated in to existing data structures. settings.COLORS == [\"pink\", \"green\", \"blue\"] settings.PARAMETERS == {\"enabled\": False, \"number\": 42} settings.PASSWORD == 9999 New in 2.2.0 And it also works having dynaconf_merge as dict keys holding the value to be merged. # settings.local.toml [default.colors] dynaconf_merge = [\"pink\"] # <-- value [\"pink\"] will be merged in to existing colors [default.parameters] dynaconf_merge = {enabled=false}","title":"dynaconf merge token"},{"location":"guides/usage/#dunder-merging-for-nested-structures","text":"For nested structures the recommendation is to use dunder merging because it it easier to read and also it has no limitations in terms of nesting levels. # settings.local.yaml [default] parameters__enabled = false The use of __ to denote nested level will ensure the key is merged with existing values read more in merging existing values .","title":"Dunder merging for nested structures"},{"location":"guides/usage/#global-merge","text":"export MERGE_ENABLED_FOR_DYNACONF=true or put it in your .env file then Dynaconf will automatically merge all existing variables. BEWARE : Using MERGE_ENABLED_FOR_DYNACONF can lead to unexpected results because you do not have granular control of what is being merged or overwritten so the recommendation is to use other options.","title":"Global merge"},{"location":"guides/usage/#settings-file-formats","text":"The recommended file format is TOML but you can choose to use any of .{py|toml|json|ini|yaml} . The file must be a series of sections, at least one for [default] , optionally one for each [environment] , and an optional [global] section. Each section contains key-value pairs corresponding to configuration parameters for that [environment] . If a configuration parameter is missing, the value from [default] is used. The following is a complete settings.toml file, where every standard configuration parameter is specified within the [default] section: NOTE : if the file format choosen is .py as it does not support sections you can create multiple files like settings.py for [default], development_settings.py , production_settings.py and global_settings.py . ATTENTION : using .py is not recommended for configuration - prefer to use static files like TOML ! [default] username = \"admin\" port = 5000 host = \"localhost\" message = \"default message\" value = \"default value\" [development] username = \"devuser\" [staging] host = \"staging.server.com\" [testing] host = \"testing.server.com\" [production] host = \"server.com\" [awesomeenv] value = \"this value is set for custom [awesomeenv]\" [global] message = \"This value overrides message of default and other envs\" The [global] pseudo-environment can be used to set and/or override configuration parameters globally. A parameter defined in a [global] section sets, or overrides if already present, that parameter in every environment. IMPORTANT: the environments and pseudo envs such as [global], ['default'] affects only the current file, it means that a value in [global] will override values defined only on that file or previous loaded files, if in another file the value is reloaded then the global values is overwritten. Dynaconf supports multiple file formats but the recommendation is not to mix them, choose a format and stick with it. For example, given the following settings.toml file, the value of address will be \"1.2.3.4\" in every environment: [global] address = \"1.2.3.4\" [development] address = \"localhost\" [production] address = \"0.0.0.0\" NOTE : The [env] name and first level variables are case insensitive as internally dynaconf will always use upper case, that means [development] and [DEVELOPMENT] are equivalent and address and ADDRESS are also equivalent. But the recommendation is to always use lower case in files and always use upper case in env vars and .py files (This rule does not apply for inner data structures as dictionaries and arrays).","title":"Settings File Formats"},{"location":"guides/usage/#supported-file-formats","text":"By default toml is the recommended format to store your configuration, however you can switch to a different supported format. # If you wish to include support for more sources pip3 install dynaconf[yaml|ini|redis|vault] # for a complete installation pip3 install dynaconf[all] Once the support is installed no extra configuration is needed to load data from those files. If you need a different file format take a look on how to extend dynaconf writing a custom loader","title":"Supported file formats"},{"location":"guides/usage/#additional-secrets-file-for-ci-jenkins-etc","text":"It is common to have an extra secrets file that is available only when running on specific CI environment like Jenkins , usually there will be an environment variable pointing to the file. On Jenkins it is done on job settings by exporting the secrets information. Dynaconf can handle this via SECRETS_FOR_DYNACONF environment variable. ex: export SECRETS_FOR_DYNACONF=/path/to/settings.toml{json|py|ini|yaml} If that variable exists in your environment then Dynaconf will also load it.","title":"Additional secrets file (for CI, jenkins etc.)"},{"location":"guides/usage/#including-files-inside-files","text":"Sometimes you have multiple fragments of settings in different files, dynaconf allow easy merging of those files via dynaconf_include . Example: plugin1.toml [development] plugin_specific_variable = 'value for development' and even mixing different formats: plugin2.yaml production: plugin_specific_variable: 'value for production' Then it can be merged on main settings.toml file via dynaconf_include settings.toml [default] dynaconf_include = [\"plugin1.toml\", \"plugin2.yaml\"] DEBUG = false SERVER = \"base.example.com\" PORT = 6666 A settings file can include a dynaconf_include stanza, whose exact syntax will depend on the type of settings file (json, yaml, toml, etc) being used: cfg [default] dynaconf_include = [\"/absolute/path/to/plugin1.toml\", \"relative/path/to/plugin2.toml\"] DEBUG = false SERVER = \"www.example.com\" When loaded, the files located at the (relative or absolute) paths in the dynaconf_include key will be parsed, in order, and override any base settings that may exist in your current configuration. The paths can be relative to the base settings.(toml|yaml|json|ini|py) file, or can be absolute paths. The idea here is that plugins or extensions for whatever framework or architecture you are using can provide their own configuration values when necessary. It is also possible to specify glob-based patterns: cfg [default] dynaconf_include = [\"configurations/*.toml\"] DEBUG = false SERVER = \"www.example.com\" Currently, only a single level of includes is permitted to keep things simple and straightforward.","title":"Including files inside files"},{"location":"guides/usage/#including-via-environment-variable","text":"It is also possible to setup includes using environment variable. # A glob pattern export INCLUDES_FOR_DYNACONF='/etc/myprogram/conf.d/*.toml' # a single path export INCLUDES_FOR_DYNACONF='/path/to/file.yaml' # multiple files export INCLUDES_FOR_DYNACONF='/path/to/file.yaml;/other/path/to/file.toml'","title":"Including via environment variable"},{"location":"guides/usage/#programmatically-loading-a-settings-file","text":"from dynaconf import settings settings.load_file(path=\"/path/to/file.toml\") # list or `;/,` separated allowed NOTE : programmatically loaded file is not persisted, once env is changed via setenv|ugin_env , or a reload or configure is invoked it will be cleaned, to persist it needs to go to INCLUDES_FOR_DYNACONF variable or you need to load it programmatically again.","title":"Programmatically loading a settings file"},{"location":"guides/usage/#template-substitutions","text":"Dynaconf has 2 tokens to enable string substitutions @format and @jinja .","title":"Template substitutions"},{"location":"guides/usage/#format-token","text":"Dynaconf allows template substitutions for strings values, by using the @format token prefix and including placeholders accepted by Python's str.format method Dynaconf will call it lazily upon access time. The call will be like: \"<YOURVALUE>\".format(env=os.environ, this=dynaconf.settings) So in your string you can refer to environment variables via env object, and also to variables defined int the settings object itself via this reference. It is lazily evaluated on access it will use the final value for a settings regardless the order of load. Example: export PROGRAM_NAME=calculator settings.toml [default] DB_NAME = \"mydb.db\" [development] DB_PATH = \"@format {env[HOME]}/{this.current_env}/{env[PROGRAM_NAME]}/{this.DB_NAME}\" {env[HOME]} is the same as os.environ[\"HOME\"] or $HOME in the shell. {this.current_env} is the same as settings.current_env {env[PROGRAM_NAME]} is the same as os.environ[\"PROGRAM_NAME\"] or $PROGRAM_NAME in the shell. {this.DB_NAME} is the same as settins.DB_NAME or settings[\"DB_NAME\"] so in your program from dynaconf import settings settings.DB_PATH == '~/DEVELOPMENT/calculator/mydb.db'","title":"@format token"},{"location":"guides/usage/#jinja-token","text":"If jinja2 package is installed then dynaconf will also allow the use jinja to render string values. Example: export PROGRAM_NAME=calculator settings.toml [default] DB_NAME = \"mydb.db\" [development] DB_NAME = \"@jinja {{env.HOME}}/{{this.current_env | lower}}/{{env[\"PROGRAM_NAME\"]}}/{{this.DB_NAME}}\" so in your program from dynaconf import settings settings.DB_PATH == '~/development/calculator/mydb.db' The main difference is that Jinja allows some Python expressions to be avaluated such as {% for, if, while %} and also supports calling methods and has lots of filters like | lower . Jinja supports its built-in filters listed in Builtin Filters Page and Dynaconf includes aditional filters for os.path module: abspath . realpath , relpath , basename and dirname and usage is like: VALUE = \"@jinja {{this.FOO | abspath}}\"","title":"@jinja token"},{"location":"guides/usage/#merging-existing-data-structures","text":"If your settings has existing variables of types list ot dict and you want to merge instead of override then the dynaconf_merge and dynaconf_merge_unique stanzas can mark that variable as a candidate for merging. For dict value: Your main settings file (e.g settings.toml ) has an existing DATABASE dict setting on [default] env. Now you want to contribute to the same DATABASE key by adding new keys, so you can use dynaconf_merge at the end of your dict: In specific [envs] [default] database = {host=\"server.com\", user=\"default\"} [development] database = {user=\"dev_user\", dynaconf_merge=true} [production] database = {user=\"prod_user\", dynaconf_merge=true} also allowed the alternative short format [default] database = {host=\"server.com\", user=\"default\"} [development.database] dynaconf_merge = {user=\"dev_user\"} [production.database] dynaconf_merge = {user=\"prod_user\"} In an environment variable: Using @merge mark # Toml formatted envvar export DYNACONF_DATABASE='@merge {password=1234}' or @merge mark short format # Toml formatted envvar export DYNACONF_DATABASE='@merge password=1234' It is also possible to use nested dunder traversal like: export DYNACONF_DATABASE__password=1234 export DYNACONF_DATABASE__user=admin export DYNACONF_DATABASE__ARGS__timeout=30 export DYNACONF_DATABASE__ARGS__retries=5 Each __ is parsed as a level traversing thought dict keys. read more in environment variables So the above will result in DATABASE = {'password': 1234, 'user': 'admin', 'ARGS': {'timeout': 30, 'retries': 5}} IMPORTANT lower case keys are respected only on *nix systems, unfortunately Windows environment variables are case insensitive and Python reads it as all upper cases, that means that if you are running on Windows the dictionary can have only upper case keys. You can also export a toml dictionary. # Toml formatted envvar export DYNACONF_DATABASE='{password=1234, dynaconf_merge=true}' Or in an additional file (e.g settings.yaml, .secrets.yaml, etc ) by using dynaconf_merge token: default: database: password: 1234 dynaconf_merge: true or default: database: dynaconf_merge: password: 1234 The dynaconf_merge token will mark that object to be merged with existing values (of course dynaconf_merge key will not be added to the final settings it is just a mark) The end result will be on [development] env: settings.DATABASE == {'host': 'server.com', 'user': 'dev_user', 'password': 1234} The same can be applied to lists : settings.toml [default] plugins = [\"core\"] [development] plugins = [\"debug_toolbar\", \"dynaconf_merge\"] or [default] plugins = [\"core\"] [development.plugins] dynaconf_merge = [\"debug_toolbar\"] And in environment variable using @merge token export DYNACONF_PLUGINS='@merge [\"ci_plugin\"]' or short version export DYNACONF_PLUGINS='@merge ci_plugin' comma separated values also supported: export DYNACONF_PLUGINS='@merge ci_plugin,other_plugin' or explicitly export DYNACONF_PLUGINS='[\"ci_plugin\", \"dynaconf_merge\"]' Then the end result on [development] is: settings.PLUGINS == [\"ci_plugin\", \"debug_toolbar\", \"core\"] If your value is a dictionary: export DYNACONF_DATA=\"@merge {foo='bar'}\" # or the short export DYNACONF_DATA=\"@merge foo=bar\"","title":"Merging existing data structures"},{"location":"guides/usage/#avoiding-duplications-on-lists","text":"The dynaconf_merge_unique is the token for when you want to avoid duplications in a list. Example: [default] scripts = ['install.sh', 'deploy.sh'] [development] scripts = ['dev.sh', 'test.sh', 'deploy.sh', 'dynaconf_merge_unique'] export DYNACONF_SCRIPTS='[\"deploy.sh\", \"run.sh\", \"dynaconf_merge_unique\"]' The end result for [development] will be: settings.SCRIPTS == ['install.sh', 'dev.sh', 'test.sh', 'deploy.sh', 'run.sh'] Note that deploy.sh is set 3 times but it is not repeated in the final settings.","title":"Avoiding duplications on lists"},{"location":"guides/usage/#known-caveats","text":"The dynaconf_merge and @merge functionalities works only for the first level keys, it will not merge subdicts or nested lists (yet). For deeper nested objects use dunder merge .","title":"Known caveats"},{"location":"guides/usage/#global-merge_1","text":"export MERGE_ENABLED_FOR_DYNACONF=true or put it in your .env file then Dynaconf will automatically merge all existing variables. BEWARE : Using MERGE_ENABLED_FOR_DYNACONF can lead to unexpected results because you do not have granular control of what is being merged or overwritten so the recommendation is to use other options.","title":"Global merge"},{"location":"guides/usage/#more-examples","text":"Take a look at the example folder to see some examples of use with different file formats and features.","title":"More examples"},{"location":"guides/validation/","text":"Validation Dynaconf allows the validation of settings parameters, in some cases you may want to validate the settings before starting the program. Lets say you have settings.toml [default] version = \"1.0.0\" age = 35 name = \"Bruno\" DEV_SERVERS = ['127.0.0.1', 'localhost', 'development.com'] PORT = 8001 [production] PROJECT = \"This is not hello_world\" Validating in Python programatically At any point of your program you can do: from dynaconf import settings, Validator # Register validators settings.validators.register( # Ensure some parameters exists (are required) Validator('VERSION', 'AGE', 'NAME', must_exist=True), # Ensure some password cannot exist Validator('PASSWORD', must_exist=False), # Ensure some parameter mets a condition # conditions: (eq, ne, lt, gt, lte, gte, identity, is_type_of, is_in, is_not_in) Validator('AGE', lte=30, gte=10), # validate a value is eq in specific env Validator('PROJECT', eq='hello_world', env='production'), # Ensure some parameter (string) meets a condition # conditions: (len_eq, len_ne, len_min, len_max, cont) # Determines the minimum and maximum length for the value Validator(\"NAME\", len_min=3, len_max=125), # Signifies the presence of the value in a set, text or word Validator(\"DEV_SERVERS\", cont='localhost'), # Checks whether the length is the same as defined. Validator(\"PORT\", len_eq=4), ) # Fire the validator settings.validators.validate() The above will raise dynaconf.validators.ValidationError(\"AGE must be lte=30 but it is 35 in env DEVELOPMENT\") and dynaconf.validators.ValidationError(\"PROJECT must be eq='hello_world' but it is 'This is not hello_world' in env PRODUCTION\") You can also use dot-delimited paths for registering validators on nested structures: from dynaconf import settings, Validator # Register validators settings.validators.register( # Ensure the database.host field exists. Validator('DATABASE.HOST', must_exist=True), # Make the database.password field optional. This is a default behavior. Validator('DATABASE.PASSWORD', must_exist=None), ) # Fire the validator settings.validators.validate() CLI and dynaconf_validators.toml NEW in 1.0.1 Starting on version 1.0.1 it is possible to define validators in TOML file called dynaconf_validators.toml placed in the same fodler as your settings files. dynaconf_validators.toml equivalent to program above [default] version = {must_exist=true} name = {must_exist=true} password = {must_exist=false} # dot notation is also supported 'a_big_dict.nested_1.nested_2.nested_3.nested_4' = {must_exist=true, eq=1} [default.age] must_exist = true lte = 30 gte = 10 [production] project = {eq=\"hello_world\"} Then to fire the validation use: $ dynaconf validate This returns code 0 (success) if validation is ok.","title":"Validation"},{"location":"guides/validation/#validation","text":"Dynaconf allows the validation of settings parameters, in some cases you may want to validate the settings before starting the program. Lets say you have settings.toml [default] version = \"1.0.0\" age = 35 name = \"Bruno\" DEV_SERVERS = ['127.0.0.1', 'localhost', 'development.com'] PORT = 8001 [production] PROJECT = \"This is not hello_world\"","title":"Validation"},{"location":"guides/validation/#validating-in-python-programatically","text":"At any point of your program you can do: from dynaconf import settings, Validator # Register validators settings.validators.register( # Ensure some parameters exists (are required) Validator('VERSION', 'AGE', 'NAME', must_exist=True), # Ensure some password cannot exist Validator('PASSWORD', must_exist=False), # Ensure some parameter mets a condition # conditions: (eq, ne, lt, gt, lte, gte, identity, is_type_of, is_in, is_not_in) Validator('AGE', lte=30, gte=10), # validate a value is eq in specific env Validator('PROJECT', eq='hello_world', env='production'), # Ensure some parameter (string) meets a condition # conditions: (len_eq, len_ne, len_min, len_max, cont) # Determines the minimum and maximum length for the value Validator(\"NAME\", len_min=3, len_max=125), # Signifies the presence of the value in a set, text or word Validator(\"DEV_SERVERS\", cont='localhost'), # Checks whether the length is the same as defined. Validator(\"PORT\", len_eq=4), ) # Fire the validator settings.validators.validate() The above will raise dynaconf.validators.ValidationError(\"AGE must be lte=30 but it is 35 in env DEVELOPMENT\") and dynaconf.validators.ValidationError(\"PROJECT must be eq='hello_world' but it is 'This is not hello_world' in env PRODUCTION\") You can also use dot-delimited paths for registering validators on nested structures: from dynaconf import settings, Validator # Register validators settings.validators.register( # Ensure the database.host field exists. Validator('DATABASE.HOST', must_exist=True), # Make the database.password field optional. This is a default behavior. Validator('DATABASE.PASSWORD', must_exist=None), ) # Fire the validator settings.validators.validate()","title":"Validating in Python programatically"},{"location":"guides/validation/#cli-and-dynaconf_validatorstoml","text":"NEW in 1.0.1 Starting on version 1.0.1 it is possible to define validators in TOML file called dynaconf_validators.toml placed in the same fodler as your settings files. dynaconf_validators.toml equivalent to program above [default] version = {must_exist=true} name = {must_exist=true} password = {must_exist=false} # dot notation is also supported 'a_big_dict.nested_1.nested_2.nested_3.nested_4' = {must_exist=true, eq=1} [default.age] must_exist = true lte = 30 gte = 10 [production] project = {eq=\"hello_world\"} Then to fire the validation use: $ dynaconf validate This returns code 0 (success) if validation is ok.","title":"CLI and dynaconf_validators.toml"}]}