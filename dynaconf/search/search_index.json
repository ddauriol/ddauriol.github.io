{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"license/","text":"The MIT License (MIT) Copyright (c) 2015 Bruno Rocha Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#the-mit-license-mit","text":"","title":"The MIT License (MIT)"},{"location":"license/#copyright-c-2015-bruno-rocha","text":"Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"Copyright (c) 2015 Bruno Rocha"},{"location":"more/","text":"DYNACONF a layered configuration system for Python applications -with strong support for 12-factor applications and extensions for Flask and Django . Release v|{dynaconf.release}|. ( Installation ) Dynaconf - Easy and Powerful Settings Configuration for Python Strict separation of settings from code (following 12-factor applications Guide). Define comprehensive default values. Store parameters in multiple file formats ( .toml , .json, .yaml, .ini and .py). Sensitive secrets like tokens and passwords can be stored in safe places like .secrets file or vault server. Parameters can optionally be stored in external services like Redis server. Simple feature flag system. Layered [environment] system. Environment variables can be used to override parameters. Support for .env files to automate the export of environment variables. Correct data types (even for environment variables). Have only one canonical settings module to rule all your instances. Drop in extension for Flask app.config object. Drop in extension for Django conf.settings object. Powerful \\$ dynaconf CLI to help you manage your settings via console. Customizable Validation System to ensure correct config parameters. Allow the change of dynamic parameters on the fly without the need to redeploy your application. Who is using Dynaconf? Pulp Project - Django - (RedHat) Ansible Galaxy - Django - (RedHat) Insights QE (RedHat) CloudForms QE (RedHat) Seek AI & Catho Job boards - Flask - (on AI APIs) Quokka CMS - Flask iNNOVO Cloud GmbH Teraki ARA Records Ansible - Django Are you using Dynaconf? Please give feedback Indices and tables genindex modindex search","title":"More"},{"location":"more/#dynaconf-easy-and-powerful-settings-configuration-for-python","text":"Strict separation of settings from code (following 12-factor applications Guide). Define comprehensive default values. Store parameters in multiple file formats ( .toml , .json, .yaml, .ini and .py). Sensitive secrets like tokens and passwords can be stored in safe places like .secrets file or vault server. Parameters can optionally be stored in external services like Redis server. Simple feature flag system. Layered [environment] system. Environment variables can be used to override parameters. Support for .env files to automate the export of environment variables. Correct data types (even for environment variables). Have only one canonical settings module to rule all your instances. Drop in extension for Flask app.config object. Drop in extension for Django conf.settings object. Powerful \\$ dynaconf CLI to help you manage your settings via console. Customizable Validation System to ensure correct config parameters. Allow the change of dynamic parameters on the fly without the need to redeploy your application.","title":"Dynaconf - Easy and Powerful Settings Configuration for Python"},{"location":"more/#who-is-using-dynaconf","text":"Pulp Project - Django - (RedHat) Ansible Galaxy - Django - (RedHat) Insights QE (RedHat) CloudForms QE (RedHat) Seek AI & Catho Job boards - Flask - (on AI APIs) Quokka CMS - Flask iNNOVO Cloud GmbH Teraki ARA Records Ansible - Django Are you using Dynaconf? Please give feedback","title":"Who is using Dynaconf?"},{"location":"more/#indices-and-tables","text":"genindex modindex search","title":"Indices and tables"},{"location":"guides/accessing_values/","text":"Accessing parameters Dynaconf offers different ways to access settings parameters Assuming the following settings.toml file [default] host = \"server\" port = 5555 auth = {user=\"admin\", passwd=\"1234\"} As attributes (dot notation) Using dot notation settings.HOST Raises: AttributeError if not defined As dictionary [item] Using item access settings['PORT'] Raises: KeyError if not defined Default values (get) Using dict style get settings.get('TIMEOUT', 300) Returns the default (300) if not defined Using dotted-path lookup settings.get('AUTH.USER', 'anonymous') Returns the default ('anonymous') if not defined Explicitly disabling dotted-path lookup settings.get('AUTH.USER', dotted_lookup=False) Forcing type casting settings.as_int('PORT') Available casts: as_int as_float as_bool as_json Boxed values In Dynaconf values are Boxed, it means the dot notation can also be used to access dictionary members, example: settings.toml [default] mysql = {host=\"server.com\", port=3600, auth={user=\"admin\", passwd=1234}} You can now access from dynaconf import settings connect( host=settings.MYSQL.host, port=settings.MYSQL.port, username=settings.MYSQL.auth.user, passwd=settings.MYSQL.auth.get('passwd'), ) Export settings as a Python dictionary After exporting the settings to a python dictionary it is easy to use it to serialize as a JSON, YAML or any other format you may need. Programmatically from dynaconf import settings settings.as_dict() # a dict with only user defined values in current env settings.as_dict(env='production') # a dict with only user defined values in production env settings.as_dict(internal=True) # a dict with all values, user defined and dynaconf internal CLI (export to json) from your project root folder (generally the same place where you have .env or from where you call your scripts. dynaconf list -o path/to/file.json dynaconf list -e production -o path/to/file.json","title":"Accessing parameters"},{"location":"guides/accessing_values/#accessing-parameters","text":"Dynaconf offers different ways to access settings parameters Assuming the following settings.toml file [default] host = \"server\" port = 5555 auth = {user=\"admin\", passwd=\"1234\"}","title":"Accessing parameters"},{"location":"guides/accessing_values/#as-attributes-dot-notation","text":"Using dot notation settings.HOST Raises: AttributeError if not defined","title":"As attributes (dot notation)"},{"location":"guides/accessing_values/#as-dictionary-item","text":"Using item access settings['PORT'] Raises: KeyError if not defined","title":"As dictionary [item]"},{"location":"guides/accessing_values/#default-values-get","text":"Using dict style get settings.get('TIMEOUT', 300) Returns the default (300) if not defined Using dotted-path lookup settings.get('AUTH.USER', 'anonymous') Returns the default ('anonymous') if not defined Explicitly disabling dotted-path lookup settings.get('AUTH.USER', dotted_lookup=False)","title":"Default values (get)"},{"location":"guides/accessing_values/#forcing-type-casting","text":"settings.as_int('PORT') Available casts: as_int as_float as_bool as_json","title":"Forcing type casting"},{"location":"guides/accessing_values/#boxed-values","text":"In Dynaconf values are Boxed, it means the dot notation can also be used to access dictionary members, example: settings.toml [default] mysql = {host=\"server.com\", port=3600, auth={user=\"admin\", passwd=1234}} You can now access from dynaconf import settings connect( host=settings.MYSQL.host, port=settings.MYSQL.port, username=settings.MYSQL.auth.user, passwd=settings.MYSQL.auth.get('passwd'), )","title":"Boxed values"},{"location":"guides/accessing_values/#export-settings-as-a-python-dictionary","text":"After exporting the settings to a python dictionary it is easy to use it to serialize as a JSON, YAML or any other format you may need.","title":"Export settings as a Python dictionary"},{"location":"guides/accessing_values/#programmatically","text":"from dynaconf import settings settings.as_dict() # a dict with only user defined values in current env settings.as_dict(env='production') # a dict with only user defined values in production env settings.as_dict(internal=True) # a dict with all values, user defined and dynaconf internal","title":"Programmatically"},{"location":"guides/accessing_values/#cli-export-to-json","text":"from your project root folder (generally the same place where you have .env or from where you call your scripts. dynaconf list -o path/to/file.json dynaconf list -e production -o path/to/file.json","title":"CLI (export to json)"},{"location":"guides/advanced_usage/","text":"Advanced Usage Yeah Dynamic is part of the name of this library so you can do lots of things :) Customizing the settings object Sometimes you want to override settings for your existing Package or Framework lets say you have a conf module exposing a config object and used to do: from myprogram.conf import config Now you want to use Dynaconf, open that conf.py or conf/__init__.py and do: # coding: utf-8 from dynaconf import LazySettings config = LazySettings(ENVVAR_PREFIX_FOR_DYNACONF=\"MYPROGRAM\") Now you can use export MYPROGRAM_FOO=bar instead of DYNACONF_FOO=bar Module impersonation In some cases you may need to impersonate your legacy settings module for example you already have a program that does. from myprogram import settings and now you want to use dynaconf without the need to change your whole codebase. Go to your myprogram/settings.py and apply the module impersonation. import sys from dynaconf import LazySettings sys.modules[__name__] = LazySettings() the last line of above code will make the module to replace itself with a dynaconf instance in the first time it is imported. Switching working environments You can switch between existing environments using: from_env : ( recommended ) Will create a new settings instance pointing to defined env. setenv : Will set the existing instance to defined env. using_env : Context manager that will have defined env only inside its scope. from_env New in 2.1.0 Return a new isolated settings object pointing to specified env. Example of settings.toml:: [development] message = 'This is in dev' foo = 1 [other] message = 'this is in other env' bar = 2 Program:: >>> from dynaconf import settings >>> print(settings.MESSAGE) 'This is in dev' >>> print(settings.FOO) 1 >>> print(settings.BAR) AttributeError: settings object has no attribute 'BAR' Then you can use from_env : >>> print(settings.from_env('other').MESSAGE) 'This is in other env' >>> print(settings.from_env('other').BAR) 2 >>> print(settings.from_env('other').FOO) AttributeError: settings object has no attribute 'FOO' The existing settings object remains the same. >>> print(settings.MESSAGE) 'This is in dev' You can assign new settings objects to different envs like: development_settings = settings.from_env('development') other_settings = settings.from_env('other') And you can choose if the variables from different envs will be chained and overridden in a sequence: all_settings = settings.from_env('development', keep=True).from_env('other', keep=True) >>> print(all_settings.MESSAGE) 'This is in other env' >>> print(all_settings.FOO) 1 >>> print(all_settings.BAR) 2 The variables from [development] are loaded keeping pre-loaded values, then the variables from [other] are loaded keeping pre-loaded from [development] and overriding it. It is also possible to pass additional configuration variables to from_env method. new_settings = settings.from_env('production', keep=True, SETTINGS_FILE_FOR_DYNACONF='another_file_path.yaml') Then the new_settings will inherit all the variables from existing env and also load the another_file_path.yaml production env. setenv Will change in_place the env for the existing object. from dynaconf import settings settings.setenv('other') # now values comes from [other] section of config assert settings.MESSAGE == 'This is in other env' settings.setenv() # now working env are back to previous using_env Using context manager from dynaconf import settings with settings.using_env('other'): # now values comes from [other] section of config assert settings.MESSAGE == 'This is in other env' # existing settings back to normal after the context manager scope assert settings.MESSAGE == 'This is in dev' Populating objects New in 2.0.0 You can use dynaconf values to populate Python objects (intances). example: class Obj: ... then you can do: from dynaconf import settings # assume it has DEBUG=True and VALUE=42.1 obj = Obj() settings.populate_obj(obj) assert obj.DEBUG is True assert obj.VALUE == 42.1 Also you can specify only some keys: from dynaconf import settings # assume it has DEBUG=True and VALUE=42.1 obj = Obj() settings.populate_obj(obj, keys=['DEBUG']) assert obj.DEBUG is True # ok assert obj.VALUE == 42.1 # AttributeError Customizations It is possible to customize how your project will load settings, example: You want your users to customize a settings file defined in export PROJECTNAME_SETTINGS=/path/to/settings.toml and you want environment variables to be loaded from PROJECTNAME_VARNAME ENVVAR_PREFIX_FOR_DYNACONF = \"PROJECTNAME\" \"\"\"This defines which environment variable global prefix dynaconf will load That means that `export PROJECTNAME_FOO=1` will be loaded to `duanconf.settings.FOO On command line it is possible to check it with `dynaconf list -k foo`\"\"\" ENV_SWITCHER_FOR_DYNACONF='PROJECTNAME_ENV' \"\"\"By default it is DYNACONF_ENV, this is the envvar used to switch from development to production but with this settings your users can do `export PROJECT_ENV=production` (new in 2.0.0)\"\"\" ENVVAR_FOR_DYNACONF = \"PROJECTNAME_SETTINGS\" \"\"\"This defines which path dynaconf will look to load config files example: export PROJECTNAME_SETTINGS=/path/to/settings.toml and the format can be .ini, .json, .yaml or .toml e.g:: export PROJECTNAME_SETTINGS=settings.toml [default] FOO = 1 [development] FOO = 2 [production] FOO = 3 OR:: export PROJECTNAME_SETTINGS=settings.yaml default: foo: 1 development: foo: 2 production: foo: 3 It is also possible to pass a list of files:: export PROJECTNAME_SETTINGS=settings.toml,other_settings.yaml,another.json The variables will be cascaded in the defined order (last wins the precedence) The environment variables wins precedence over all! \"\"\" # load dynaconf settings = LazySettings( ENVVAR_PREFIX_FOR_DYNACONF=ENVVAR_PREFIX_FOR_DYNACONF, ENVVAR_FOR_DYNACONF=ENVVAR_FOR_DYNACONF. ENV_SWITCHER_FOR_DYNACONF=ENV_SWITCHER_FOR_DYNACONF ) Then the working environment can now be switched using export PROJECTNAME_ENV=production Exporting You can generate a file with current configs by calling dynaconf list -o /path/to/file.ext see more in cli You can also do that programmatically with: from dynaconf import loaders from dynaconf import settings from dynaconf.utils.boxing import DynaBox # generates a dict with all the keys for `development` env data = settings.as_dict(env='development') # writes to a file, the format is inferred by extension # can be .yaml, .toml, .ini, .json, .py loaders.write('/path/to/file.yaml', DynaBox(data).to_dict(), merge=False, env='development') Preloading files New in 2.2.0 Useful for plugin based apps. from dynaconf import LazySettings settings = LazySettings( PRELOAD_FOR_DYNACONF=[\"/path/*\", \"other/settings.toml\"], # <-- Loaded first SETTINGS_FILE_FOR_DYNACONF=\"/etc/foo/settings.py\", # <-- Loaded second (the main file) INCLUDES_FOR_DYNACONF=[\"other.module.settings\", \"other/settings.yaml\"] # <-- Loaded at the end )","title":"Advanced Usage"},{"location":"guides/advanced_usage/#advanced-usage","text":"Yeah Dynamic is part of the name of this library so you can do lots of things :)","title":"Advanced Usage"},{"location":"guides/advanced_usage/#customizing-the-settings-object","text":"Sometimes you want to override settings for your existing Package or Framework lets say you have a conf module exposing a config object and used to do: from myprogram.conf import config Now you want to use Dynaconf, open that conf.py or conf/__init__.py and do: # coding: utf-8 from dynaconf import LazySettings config = LazySettings(ENVVAR_PREFIX_FOR_DYNACONF=\"MYPROGRAM\") Now you can use export MYPROGRAM_FOO=bar instead of DYNACONF_FOO=bar","title":"Customizing the settings object"},{"location":"guides/advanced_usage/#module-impersonation","text":"In some cases you may need to impersonate your legacy settings module for example you already have a program that does. from myprogram import settings and now you want to use dynaconf without the need to change your whole codebase. Go to your myprogram/settings.py and apply the module impersonation. import sys from dynaconf import LazySettings sys.modules[__name__] = LazySettings() the last line of above code will make the module to replace itself with a dynaconf instance in the first time it is imported.","title":"Module impersonation"},{"location":"guides/advanced_usage/#switching-working-environments","text":"You can switch between existing environments using: from_env : ( recommended ) Will create a new settings instance pointing to defined env. setenv : Will set the existing instance to defined env. using_env : Context manager that will have defined env only inside its scope.","title":"Switching working environments"},{"location":"guides/advanced_usage/#from_env","text":"New in 2.1.0 Return a new isolated settings object pointing to specified env. Example of settings.toml:: [development] message = 'This is in dev' foo = 1 [other] message = 'this is in other env' bar = 2 Program:: >>> from dynaconf import settings >>> print(settings.MESSAGE) 'This is in dev' >>> print(settings.FOO) 1 >>> print(settings.BAR) AttributeError: settings object has no attribute 'BAR' Then you can use from_env : >>> print(settings.from_env('other').MESSAGE) 'This is in other env' >>> print(settings.from_env('other').BAR) 2 >>> print(settings.from_env('other').FOO) AttributeError: settings object has no attribute 'FOO' The existing settings object remains the same. >>> print(settings.MESSAGE) 'This is in dev' You can assign new settings objects to different envs like: development_settings = settings.from_env('development') other_settings = settings.from_env('other') And you can choose if the variables from different envs will be chained and overridden in a sequence: all_settings = settings.from_env('development', keep=True).from_env('other', keep=True) >>> print(all_settings.MESSAGE) 'This is in other env' >>> print(all_settings.FOO) 1 >>> print(all_settings.BAR) 2 The variables from [development] are loaded keeping pre-loaded values, then the variables from [other] are loaded keeping pre-loaded from [development] and overriding it. It is also possible to pass additional configuration variables to from_env method. new_settings = settings.from_env('production', keep=True, SETTINGS_FILE_FOR_DYNACONF='another_file_path.yaml') Then the new_settings will inherit all the variables from existing env and also load the another_file_path.yaml production env.","title":"from_env"},{"location":"guides/advanced_usage/#setenv","text":"Will change in_place the env for the existing object. from dynaconf import settings settings.setenv('other') # now values comes from [other] section of config assert settings.MESSAGE == 'This is in other env' settings.setenv() # now working env are back to previous","title":"setenv"},{"location":"guides/advanced_usage/#using_env","text":"Using context manager from dynaconf import settings with settings.using_env('other'): # now values comes from [other] section of config assert settings.MESSAGE == 'This is in other env' # existing settings back to normal after the context manager scope assert settings.MESSAGE == 'This is in dev'","title":"using_env"},{"location":"guides/advanced_usage/#populating-objects","text":"New in 2.0.0 You can use dynaconf values to populate Python objects (intances). example: class Obj: ... then you can do: from dynaconf import settings # assume it has DEBUG=True and VALUE=42.1 obj = Obj() settings.populate_obj(obj) assert obj.DEBUG is True assert obj.VALUE == 42.1 Also you can specify only some keys: from dynaconf import settings # assume it has DEBUG=True and VALUE=42.1 obj = Obj() settings.populate_obj(obj, keys=['DEBUG']) assert obj.DEBUG is True # ok assert obj.VALUE == 42.1 # AttributeError","title":"Populating objects"},{"location":"guides/advanced_usage/#customizations","text":"It is possible to customize how your project will load settings, example: You want your users to customize a settings file defined in export PROJECTNAME_SETTINGS=/path/to/settings.toml and you want environment variables to be loaded from PROJECTNAME_VARNAME ENVVAR_PREFIX_FOR_DYNACONF = \"PROJECTNAME\" \"\"\"This defines which environment variable global prefix dynaconf will load That means that `export PROJECTNAME_FOO=1` will be loaded to `duanconf.settings.FOO On command line it is possible to check it with `dynaconf list -k foo`\"\"\" ENV_SWITCHER_FOR_DYNACONF='PROJECTNAME_ENV' \"\"\"By default it is DYNACONF_ENV, this is the envvar used to switch from development to production but with this settings your users can do `export PROJECT_ENV=production` (new in 2.0.0)\"\"\" ENVVAR_FOR_DYNACONF = \"PROJECTNAME_SETTINGS\" \"\"\"This defines which path dynaconf will look to load config files example: export PROJECTNAME_SETTINGS=/path/to/settings.toml and the format can be .ini, .json, .yaml or .toml e.g:: export PROJECTNAME_SETTINGS=settings.toml [default] FOO = 1 [development] FOO = 2 [production] FOO = 3 OR:: export PROJECTNAME_SETTINGS=settings.yaml default: foo: 1 development: foo: 2 production: foo: 3 It is also possible to pass a list of files:: export PROJECTNAME_SETTINGS=settings.toml,other_settings.yaml,another.json The variables will be cascaded in the defined order (last wins the precedence) The environment variables wins precedence over all! \"\"\" # load dynaconf settings = LazySettings( ENVVAR_PREFIX_FOR_DYNACONF=ENVVAR_PREFIX_FOR_DYNACONF, ENVVAR_FOR_DYNACONF=ENVVAR_FOR_DYNACONF. ENV_SWITCHER_FOR_DYNACONF=ENV_SWITCHER_FOR_DYNACONF ) Then the working environment can now be switched using export PROJECTNAME_ENV=production","title":"Customizations"},{"location":"guides/advanced_usage/#exporting","text":"You can generate a file with current configs by calling dynaconf list -o /path/to/file.ext see more in cli You can also do that programmatically with: from dynaconf import loaders from dynaconf import settings from dynaconf.utils.boxing import DynaBox # generates a dict with all the keys for `development` env data = settings.as_dict(env='development') # writes to a file, the format is inferred by extension # can be .yaml, .toml, .ini, .json, .py loaders.write('/path/to/file.yaml', DynaBox(data).to_dict(), merge=False, env='development')","title":"Exporting"},{"location":"guides/advanced_usage/#preloading-files","text":"New in 2.2.0 Useful for plugin based apps. from dynaconf import LazySettings settings = LazySettings( PRELOAD_FOR_DYNACONF=[\"/path/*\", \"other/settings.toml\"], # <-- Loaded first SETTINGS_FILE_FOR_DYNACONF=\"/etc/foo/settings.py\", # <-- Loaded second (the main file) INCLUDES_FOR_DYNACONF=[\"other.module.settings\", \"other/settings.yaml\"] # <-- Loaded at the end )","title":"Preloading files"},{"location":"guides/alternatives/","text":"Alternatives Dynaconf tries to define standard and good practices for config and aims to have flexibility and 100% of test coverage for Python 3.x. Dynaconf implements the best parts of the alternatives below, to implement Dynaconf lots of configuration libraries have been tested and studied. But if you are still looking for something different take a look at the following excellent alternatives. Python Decouple PrettyConf Profig Everett Configman PyMLconf AnyConfig Config Conman","title":"Alternatives"},{"location":"guides/alternatives/#alternatives","text":"Dynaconf tries to define standard and good practices for config and aims to have flexibility and 100% of test coverage for Python 3.x. Dynaconf implements the best parts of the alternatives below, to implement Dynaconf lots of configuration libraries have been tested and studied. But if you are still looking for something different take a look at the following excellent alternatives. Python Decouple PrettyConf Profig Everett Configman PyMLconf AnyConfig Config Conman","title":"Alternatives"},{"location":"guides/cli/","text":"The dynaconf CLI The $ dynaconf cli provides some useful commands IMPORTANT if you are using Flask Extension the env var FLASK_APP must be defined to use the CLI, and if using Django Extension the DJANGO_SETTINGS_MODULE must be defined. dynaconf --help Usage: dynaconf [OPTIONS] COMMAND [ARGS]... Dynaconf - Command Line Interface Options: --version Show dynaconf version --docs Open documentation in browser --banner Show awesome banner -i, --instance TEXT Custom instance of LazySettings --help Show this message and exit. Commands: init Inits a dynaconf project By default it... list Lists all defined config values write Writes data to specific source validate Validates based on dynaconf_validators.toml file dynaconf init Use init to easily configure your application configuration, once dynaconf is installed go to the root directory of your application and run: creates settings files in current directory $ dynaconf init -v key=value -v foo=bar -s token=1234 -e production The above command will create in the current directory settings.toml [default] KEY = \"default\" FOO = \"default\" [production] KEY = \"value\" FOO = \"bar\" also .secrets.toml [default] TOKEN = \"default\" [production] TOKEN = \"1234\" The command will also create a .env setting the working environment to [production] ENV_FOR_DYNACONF=\"PRODUCTION\" And will include the .secrets.toml in the .gitignore # Ignore dynaconf secret files .secrets.* For sensitive data in production is recommended using Vault Server Usage: dynaconf init [OPTIONS] Inits a dynaconf project By default it creates a settings.toml and a .secrets.toml for [default|development|staging|testing|production|global] envs. The format of the files can be changed passing --format=yaml|json|ini|py. This command must run on the project's root folder or you must pass --path=/myproject/root/folder. If you want to have a .env created with the ENV defined there e.g: `ENV_FOR_DYNACONF=production` just pass --env=production and then .env will also be created and the env defined to production. Options: -f, --format [ini|toml|yaml|json|py|env] -p, --path TEXT defaults to current directory -e, --env TEXT Sets the working env in `.env` file -v, --vars TEXT extra values to write to settings file file e.g: `dynaconf init -v NAME=foo -v X=2 -s, --secrets TEXT secret key values to be written in .secrets e.g: `dynaconf init -s TOKEN=kdslmflds --wg / --no-wg -y --django TEXT --help Show this message and exit. dynaconf list List all defined parameters and optionally export to a json file. Usage: dynaconf list [OPTIONS] Lists all user defined config values and if `--all` is passed it also shows dynaconf internal variables. Options: -e, --env TEXT Filters the env to get the values -k, --key TEXT Filters a single key -m, --more Pagination more|less style -l, --loader TEXT a loader identifier to filter e.g: toml|yaml -a, --all show dynaconf internal settings? -o, --output FILE Filepath to write the listed values as json --output-flat Output file is flat (do not include [env] name) --help Show this message and exit. Exporting current environment as a file dynaconf list -o path/to/file.yaml The above command will export all the items showed by dynaconf list to the desired format which is inferred by the -o file extension, supported formats yaml, toml, ini, json, py When using py you may want a flat output (without being nested inside the env key) dynaconf list -o path/to/file.py --output-flat dynaconf write Usage: dynaconf write [OPTIONS] TO Writes data to specific source Options: -v, --vars TEXT key values to be written e.g: `dynaconf write toml -e NAME=foo -e X=2 -s, --secrets TEXT secret key values to be written in .secrets e.g: `dynaconf write toml -s TOKEN=kdslmflds -s X=2 -p, --path TEXT defaults to current directory/settings.{ext} -e, --env TEXT env to write to defaults to DEVELOPMENT for files for external sources like Redis and Vault it will be DYNACONF or the value set in $ENVVAR_PREFIX_FOR_DYNACONF -y --help Show this message and exit. dynaconf validate NEW in 1.0.1 Starting on version 1.0.1 it is possible to define validators in TOML file called dynaconf_validators.toml placed in the same fodler as your settings files. dynaconf_validators.toml equivalent to program above [default] version = {must_exist=true} name = {must_exist=true} password = {must_exist=false} [default.age] must_exist = true lte = 30 gte = 10 [production] project = {eq=\"hello_world\"} Then to fire the validation use: $ dynaconf validate If validates it returns status 0 (success) and this command can be called in your CI/CD/Deploy jobs. dynaconf --version returns dynaconf version $ dynaconf --version 1.0.0 dynaconf --docs Opens Dynaconf documentation in browser dynaconf --banner Prints this awesome ascii made banner in the console :) $ dynaconf --banner \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u255a\u2588\u2588\u2557 \u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2551 \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551 \u255a\u2588\u2588\u2554\u255d \u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2551 \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551\u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d Learn more at: http://github.com/rochacbruno/dynaconf","title":"The dynaconf CLI"},{"location":"guides/cli/#the-dynaconf-cli","text":"The $ dynaconf cli provides some useful commands IMPORTANT if you are using Flask Extension the env var FLASK_APP must be defined to use the CLI, and if using Django Extension the DJANGO_SETTINGS_MODULE must be defined.","title":"The dynaconf CLI"},{"location":"guides/cli/#dynaconf-help","text":"Usage: dynaconf [OPTIONS] COMMAND [ARGS]... Dynaconf - Command Line Interface Options: --version Show dynaconf version --docs Open documentation in browser --banner Show awesome banner -i, --instance TEXT Custom instance of LazySettings --help Show this message and exit. Commands: init Inits a dynaconf project By default it... list Lists all defined config values write Writes data to specific source validate Validates based on dynaconf_validators.toml file","title":"dynaconf --help"},{"location":"guides/cli/#dynaconf-init","text":"Use init to easily configure your application configuration, once dynaconf is installed go to the root directory of your application and run: creates settings files in current directory $ dynaconf init -v key=value -v foo=bar -s token=1234 -e production The above command will create in the current directory settings.toml [default] KEY = \"default\" FOO = \"default\" [production] KEY = \"value\" FOO = \"bar\" also .secrets.toml [default] TOKEN = \"default\" [production] TOKEN = \"1234\" The command will also create a .env setting the working environment to [production] ENV_FOR_DYNACONF=\"PRODUCTION\" And will include the .secrets.toml in the .gitignore # Ignore dynaconf secret files .secrets.* For sensitive data in production is recommended using Vault Server Usage: dynaconf init [OPTIONS] Inits a dynaconf project By default it creates a settings.toml and a .secrets.toml for [default|development|staging|testing|production|global] envs. The format of the files can be changed passing --format=yaml|json|ini|py. This command must run on the project's root folder or you must pass --path=/myproject/root/folder. If you want to have a .env created with the ENV defined there e.g: `ENV_FOR_DYNACONF=production` just pass --env=production and then .env will also be created and the env defined to production. Options: -f, --format [ini|toml|yaml|json|py|env] -p, --path TEXT defaults to current directory -e, --env TEXT Sets the working env in `.env` file -v, --vars TEXT extra values to write to settings file file e.g: `dynaconf init -v NAME=foo -v X=2 -s, --secrets TEXT secret key values to be written in .secrets e.g: `dynaconf init -s TOKEN=kdslmflds --wg / --no-wg -y --django TEXT --help Show this message and exit.","title":"dynaconf init"},{"location":"guides/cli/#dynaconf-list","text":"List all defined parameters and optionally export to a json file. Usage: dynaconf list [OPTIONS] Lists all user defined config values and if `--all` is passed it also shows dynaconf internal variables. Options: -e, --env TEXT Filters the env to get the values -k, --key TEXT Filters a single key -m, --more Pagination more|less style -l, --loader TEXT a loader identifier to filter e.g: toml|yaml -a, --all show dynaconf internal settings? -o, --output FILE Filepath to write the listed values as json --output-flat Output file is flat (do not include [env] name) --help Show this message and exit.","title":"dynaconf list"},{"location":"guides/cli/#exporting-current-environment-as-a-file","text":"dynaconf list -o path/to/file.yaml The above command will export all the items showed by dynaconf list to the desired format which is inferred by the -o file extension, supported formats yaml, toml, ini, json, py When using py you may want a flat output (without being nested inside the env key) dynaconf list -o path/to/file.py --output-flat","title":"Exporting current environment as a file"},{"location":"guides/cli/#dynaconf-write","text":"Usage: dynaconf write [OPTIONS] TO Writes data to specific source Options: -v, --vars TEXT key values to be written e.g: `dynaconf write toml -e NAME=foo -e X=2 -s, --secrets TEXT secret key values to be written in .secrets e.g: `dynaconf write toml -s TOKEN=kdslmflds -s X=2 -p, --path TEXT defaults to current directory/settings.{ext} -e, --env TEXT env to write to defaults to DEVELOPMENT for files for external sources like Redis and Vault it will be DYNACONF or the value set in $ENVVAR_PREFIX_FOR_DYNACONF -y --help Show this message and exit.","title":"dynaconf write"},{"location":"guides/cli/#dynaconf-validate","text":"NEW in 1.0.1 Starting on version 1.0.1 it is possible to define validators in TOML file called dynaconf_validators.toml placed in the same fodler as your settings files. dynaconf_validators.toml equivalent to program above [default] version = {must_exist=true} name = {must_exist=true} password = {must_exist=false} [default.age] must_exist = true lte = 30 gte = 10 [production] project = {eq=\"hello_world\"} Then to fire the validation use: $ dynaconf validate If validates it returns status 0 (success) and this command can be called in your CI/CD/Deploy jobs.","title":"dynaconf validate"},{"location":"guides/cli/#dynaconf-version","text":"returns dynaconf version $ dynaconf --version 1.0.0","title":"dynaconf --version"},{"location":"guides/cli/#dynaconf-docs","text":"Opens Dynaconf documentation in browser","title":"dynaconf --docs"},{"location":"guides/cli/#dynaconf-banner","text":"Prints this awesome ascii made banner in the console :) $ dynaconf --banner \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u255a\u2588\u2588\u2557 \u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2551 \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551 \u255a\u2588\u2588\u2554\u255d \u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2551 \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551\u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d Learn more at: http://github.com/rochacbruno/dynaconf","title":"dynaconf --banner"},{"location":"guides/configuration/","text":"Configuring Dynaconf Dynaconf can be configured through variables suffixed with _FOR_DYNACONF those settings can be used to change various dynaconf defaults and behaviors. Each config variable here can be exported to environment variables or wrote to .env file, example: export DEBUG_LEVEL_FOR_DYNACONF=DEBUG export ENV_FOR_DYNACONF=production Or when using your own Dynaconf instance you can pass as parameters directly: from dynaconf import LazySettings settings = LazySettings( DEBUG_LEVEL_FOR_DYNACONF='DEBUG', ENVVAR_PREFIX_FOR_DYNACONF='MYPROGRAM', ENVVAR_FOR_DYNACONF='MYPROGRAM_SETTINGS', ) It can also be passed as parameters to extensions like FlaskDynaconf or set in the DjangoDynaconf on settings.py file. Configuration options NOTE: Append _FOR_DYNACONF when exporting these variables. .. csv-table:: :header: \"Variable\", \"Type\", \"Usage\", \"default\", \"example\" :widths: 15, 15, 50, 30, 50 :delim: | AUTO_CAST | bool | *@casting* like *@int* is parsed. | true | AUTO_CAST_FOR_DYNACONF=false COMMENTJSON_ENABLED | bool | Enable comments in json files. | false (req:*pip install commentjson*) | COMMENTJSON_ENABLED_FOR_DYNACONF=true CORE_LOADERS | list | A list of enabled core loaders. | [\u2018YAML\u2019, \u2018TOML\u2019, \u2018INI\u2019, \u2018JSON\u2019, \u2018PY\u2019] | CORE_LOADERS_FOR_DYNACONF=\u2019[\u201cYAML\u201d, \u201cJSON\u201d]\u2019 or \u2018[]\u2019 DEBUG_LEVEL | str | Upper case logging level. | NOTSET | DEBUG_LEVEL_FOR_DYNACONF=DEBUG DOTENV_OVERRIDE | bool | *.env* should override the exported envvars. | false | DOTENV_OVERRIDE_FOR_DYNACONF=true DOTENV_PATH | str | Defines where to look for *.env* file. | PROJECT_ROOT | DOTENV_PATH_FOR_DYNACONF=\u201d/tmp/.env\u201d ENCODING | str | Encoding to read settings files. | utf-8 | ENCODING_FOR_DYNACONF=\u201dcp1252\u201d ENV | str | Working environment. | \u201cdevelopment\u201d | ENV_FOR_DYNACONF=production *FORCE_ENV | str | Force the working environment | None | FORCE_ENV_FOR_DYNACONF=other ENV_SWITCHER | str | Variable used to change working env. | ENV_FOR_DYNACONF | ENV_SWITCHER_FOR_DYNACONF=MYPROGRAM_ENV ENVVAR | str | The envvar which holds the list of settings files. | \u2018SETTINGS_FILE_FOR_DYNACONF\u2019 | ENVVAR_FOR_DYNACONF=MYPROGRAM_SETTINGS ENVVAR_PREFIX | str | Prefix for exporting parameters as env vars. Example: If your program is called *MYPROGRAM* you may want users to use *MYPROGRAM_FOO=bar* instead of *DYNACONF_FOO=bar* on envvars. | \u201cDYNACONF\u201d | ENVVAR_PREFIX_FOR_DYNACONF=MYPROGRAM (loads MYPROGRAM_VAR) ENVVAR_PREFIX_FOR_DYNACONF=\u2019\u2019 (loads _VAR) ENVVAR_PREFIX_FOR_DYNACONF=false (loads VAR) FRESH_VARS | list | A list of vars to be re-loaded on every access. | [] | FRESH_VARS_FOR_DYNACONF=[\u201cHOST\u201d, \u201cPORT\u201d] INCLUDES | list | A list of paths or a glob to load can be a toml-like list, or sep by , or ; | [] | INCLUDES_FOR_DYNACONF=\u201d[\u2018path1.ext\u2019, \u2018folder/*\u2019]\u201d INCLUDES_FOR_DYNACONF=\u201dpath1.toml;path2.toml\u201d INCLUDES_FOR_DYNACONF=\u201dpath1.toml,path2.toml\u201d INCLUDES_FOR_DYNACONF=\u201dsingle_path.toml\u201d INCLUDES_FOR_DYNACONF=\u201dsingle_path/glob/.toml\u201d INSTANCE **used only by** *$dynaconf** *cli*. | str | Custom instance of LazySettings Must be an importable Python module. | None | INSTANCE_FOR_DYNACONF=myapp.settings LOADERS | list | A list of enabled external loaders. | [\u2018dynaconf.loaders.env_loader\u2019] | LOADERS_FOR_DYNACONF=\u2019[\u2018module.mycustomloader\u2019, \u2026]\u2019 MERGE_ENABLED | bool | A bool to activate the global merge feature | False | MERGE_ENABLED_FOR_DYNACONF=1 NESTED_SEPARATOR | str | Separator for nested assignment like `export DYNACONF_DATABASES__NAME='foo'` | `__` double underline | NESTED_SEPARATOR_FOR_DYNACONF='___' PRELOAD | list | A list of paths or glob to be pre-loaded before main settings file. | [] | PRELOAD_FOR_DYNACONF=\"['path1.ext', 'folder/*']\" REDIS_DB | int | Redis DB. | 0 | REDIS_DB_FOR_DYNACONF=1 REDIS_ENABLED | bool | Redis loader is enabled. | false | REDIS_ENABLED_FOR_DYNACONF=true REDIS_HOST | str | Redis server address. | localhost | REDIS_HOST_FOR_DYNACONF=\u201dlocalhost\u201d REDIS_PORT | int | Redis port. | 6379 | REDIS_PORT_FOR_DYNACONF=8899 ROOT_PATH | str | Directory to look for settings files. This path is the base to search for files defined in *SETTINGS_FILE*. Dynaconf will also search for files in a relative *config/* subfolder if exists. | *None*. If set Dynaconf will look this path first before it starts to search for file in the other locations. see: `<usage.md#the-settings-files>`_ | ROOT_PATH_FOR_DYNACONF=\u201d/my/custom/absolute/path/\u201d SECRETS | str | Path to aditional secrets file to be loaded. | None | SECRETS_FOR_DYNACONF=/var/jenkins/settings_ci.toml SETTINGS_FILE | list, str | List of files to load. | List of all supportes files: *settings.{py,toml,yaml,ini,conf,json} .secrets.{py,toml,yaml,ini,conf,json}*. This var name can be replaced by: *ENVVAR_FOR_DYNACONF=MYPROGRAM_SETTINGS* | SETTINGS_FILE_FOR_DYNACONF=\u201dmyconfig.toml\u201d SETTINGS_FILE_FOR_DYNACONF=\u201d[\u2018conf.toml\u2019,\u2019settings.yaml\u2019]\u201d SETTINGS_FILE_FOR_DYNACONF=\u201dconf.toml,settings.yaml\u201d SETTINGS_FILE_FOR_DYNACONF=\u201dconf.toml;settings.yaml\u201d MYPROGRAM_SETTINGS=\u201dconf.toml,settings.yaml\u201d SILENT_ERRORS | bool | Loading errors should be silenced. | true | SILENT_ERRORS_FOR_DYNACONF=false SKIP_FILES | list | Files to skip/ignore if found on search tree. | [] | SKIP_FILES_FOR_DYNACONF=\u201d[\u2018/absolute/path/to/file.ext\u2019]\u201d VAULT_ALLOW_REDIRECTS | bool | Vault allow redirects. | None | VAULT_ALLOW_REDIRECTS_FOR_DYNACONF=false VAULT_CERT | str | Vault cert/pem file path. | None | VAULT_CERT_FOR_DYNACONF=\u201d~/.ssh/key.pem\u201d VAULT_ENABLED | bool | Vault server is enabled. | false | VAULT_ENABLED_FOR_DYNACONF=true VAULT_HOST | str | Vault host. | localhost | VAULT_HOST_FOR_DYNACONF=\u201dserver\u201d VAULT_PATH | str | Vault path to the configuration. | None | VAULT_PATH_FOR_DYNACONF=\u201dsecret_data\u201d VAULT_PORT | str | Vault port. | 8200 | VAULT_PORT_FOR_DYNACONF=\u201d2800\u201d VAULT_PROXIES | dict | Vault proxies. | None | VAULT_PROXIES_FOR_DYNACONF={http=\u201dhttp:/localhost:3128/\u201d} VAULT_ROLE_ID | str | Vault Role ID. | None | VAULT_ROLE_ID_FOR_DYNACONF=\u201dsome-role-id\u201d VAULT_SCHEME | str | Vault scheme. | http | VAULT_SCHEME_FOR_DYNACONF=\u201dhttps\u201d VAULT_SECRET_ID | str | Vault Secret ID. | None | VAULT_SECRET_ID_FOR_DYNACONF=\u201dsome-secret-id\u201d VAULT_TIMEOUT | int | Vault timeout in seconds. | None | VAULT_TIMEOUT_FOR_DYNACONF=60 VAULT_TOKEN | str | Vault token. | None | VAULT_TOKEN_FOR_DYNACONF=\u201dmyroot\u201d VAULT_URL | str | Vault URL. | http:// localhost :8200 | VAULT_URL_FOR_DYNACONF=\u201dhttp://server/8200\u201d VAULT_VERIFY | bool | Vault should verify. | None | VAULT_VERIFY_FOR_DYNACONF=true YAML_LOADER | str | yaml method name {safe,full,unsafe}_load. | safe_load | YAML_LOADER_FOR_DYNACONF=unsafe_load Internal use variables FORCE_ENV_FOR_DYNACONF: This variable exists to support the from_env method, the crontib extensions and to use for testing. Deprecated options Some configuration options has been deprecated and replaced with a new name, we try to make it without breaking backwards compatibility with old version, but you may receive a warning if use: PROJECT_ROOT replaced by ROOT_PATH_FOR_DYNACONF PROJECT_ROOT_FOR_DYNACONF replaced by ROOT_PATH_FOR_DYNACONF DYNACONF_NAMESPACE replaced by ENV_FOR_DYNACONF NAMESPACE_FOR_DYNACONF replaced by ENV_FOR_DYNACONF BASE_NAMESPACE_FOR_DYNACONF replaced by DEFAULT_ENV_FOR_DYNACONF DYNACONF_SETTINGS_MODULE replaced by SETTINGS_FILE_FOR_DYNACONF DYNACONF_SETTINGS replaced by SETTINGS_FILE_FOR_DYNACONF SETTINGS_MODULE replaced by SETTINGS_FILE_FOR_DYNACONF DYNACONF_SILENT_ERRORS replaced by SILENT_ERRORS_FOR_DYNACONF DYNACONF_ALWAYS_FRESH_VARS replaced by FRESH_VARS_FOR_DYNACONF GLOBAL_ENV_FOR_DYNACONF replaced by ENVVAR_PREFIX_FOR_DYNACONF SETTINGS_MODULE_FOR_DYNACONF replaced by SETTINGS_FILE_FOR_DYNACONF .. autoclass:: dynaconf.default_settings :show-inheritance:","title":"Configuring Dynacon"},{"location":"guides/configuration/#configuring-dynaconf","text":"Dynaconf can be configured through variables suffixed with _FOR_DYNACONF those settings can be used to change various dynaconf defaults and behaviors. Each config variable here can be exported to environment variables or wrote to .env file, example: export DEBUG_LEVEL_FOR_DYNACONF=DEBUG export ENV_FOR_DYNACONF=production Or when using your own Dynaconf instance you can pass as parameters directly: from dynaconf import LazySettings settings = LazySettings( DEBUG_LEVEL_FOR_DYNACONF='DEBUG', ENVVAR_PREFIX_FOR_DYNACONF='MYPROGRAM', ENVVAR_FOR_DYNACONF='MYPROGRAM_SETTINGS', ) It can also be passed as parameters to extensions like FlaskDynaconf or set in the DjangoDynaconf on settings.py file.","title":"Configuring Dynaconf"},{"location":"guides/configuration/#configuration-options","text":"NOTE: Append _FOR_DYNACONF when exporting these variables. .. csv-table:: :header: \"Variable\", \"Type\", \"Usage\", \"default\", \"example\" :widths: 15, 15, 50, 30, 50 :delim: | AUTO_CAST | bool | *@casting* like *@int* is parsed. | true | AUTO_CAST_FOR_DYNACONF=false COMMENTJSON_ENABLED | bool | Enable comments in json files. | false (req:*pip install commentjson*) | COMMENTJSON_ENABLED_FOR_DYNACONF=true CORE_LOADERS | list | A list of enabled core loaders. | [\u2018YAML\u2019, \u2018TOML\u2019, \u2018INI\u2019, \u2018JSON\u2019, \u2018PY\u2019] | CORE_LOADERS_FOR_DYNACONF=\u2019[\u201cYAML\u201d, \u201cJSON\u201d]\u2019 or \u2018[]\u2019 DEBUG_LEVEL | str | Upper case logging level. | NOTSET | DEBUG_LEVEL_FOR_DYNACONF=DEBUG DOTENV_OVERRIDE | bool | *.env* should override the exported envvars. | false | DOTENV_OVERRIDE_FOR_DYNACONF=true DOTENV_PATH | str | Defines where to look for *.env* file. | PROJECT_ROOT | DOTENV_PATH_FOR_DYNACONF=\u201d/tmp/.env\u201d ENCODING | str | Encoding to read settings files. | utf-8 | ENCODING_FOR_DYNACONF=\u201dcp1252\u201d ENV | str | Working environment. | \u201cdevelopment\u201d | ENV_FOR_DYNACONF=production *FORCE_ENV | str | Force the working environment | None | FORCE_ENV_FOR_DYNACONF=other ENV_SWITCHER | str | Variable used to change working env. | ENV_FOR_DYNACONF | ENV_SWITCHER_FOR_DYNACONF=MYPROGRAM_ENV ENVVAR | str | The envvar which holds the list of settings files. | \u2018SETTINGS_FILE_FOR_DYNACONF\u2019 | ENVVAR_FOR_DYNACONF=MYPROGRAM_SETTINGS ENVVAR_PREFIX | str | Prefix for exporting parameters as env vars. Example: If your program is called *MYPROGRAM* you may want users to use *MYPROGRAM_FOO=bar* instead of *DYNACONF_FOO=bar* on envvars. | \u201cDYNACONF\u201d | ENVVAR_PREFIX_FOR_DYNACONF=MYPROGRAM (loads MYPROGRAM_VAR) ENVVAR_PREFIX_FOR_DYNACONF=\u2019\u2019 (loads _VAR) ENVVAR_PREFIX_FOR_DYNACONF=false (loads VAR) FRESH_VARS | list | A list of vars to be re-loaded on every access. | [] | FRESH_VARS_FOR_DYNACONF=[\u201cHOST\u201d, \u201cPORT\u201d] INCLUDES | list | A list of paths or a glob to load can be a toml-like list, or sep by , or ; | [] | INCLUDES_FOR_DYNACONF=\u201d[\u2018path1.ext\u2019, \u2018folder/*\u2019]\u201d INCLUDES_FOR_DYNACONF=\u201dpath1.toml;path2.toml\u201d INCLUDES_FOR_DYNACONF=\u201dpath1.toml,path2.toml\u201d INCLUDES_FOR_DYNACONF=\u201dsingle_path.toml\u201d INCLUDES_FOR_DYNACONF=\u201dsingle_path/glob/.toml\u201d INSTANCE **used only by** *$dynaconf** *cli*. | str | Custom instance of LazySettings Must be an importable Python module. | None | INSTANCE_FOR_DYNACONF=myapp.settings LOADERS | list | A list of enabled external loaders. | [\u2018dynaconf.loaders.env_loader\u2019] | LOADERS_FOR_DYNACONF=\u2019[\u2018module.mycustomloader\u2019, \u2026]\u2019 MERGE_ENABLED | bool | A bool to activate the global merge feature | False | MERGE_ENABLED_FOR_DYNACONF=1 NESTED_SEPARATOR | str | Separator for nested assignment like `export DYNACONF_DATABASES__NAME='foo'` | `__` double underline | NESTED_SEPARATOR_FOR_DYNACONF='___' PRELOAD | list | A list of paths or glob to be pre-loaded before main settings file. | [] | PRELOAD_FOR_DYNACONF=\"['path1.ext', 'folder/*']\" REDIS_DB | int | Redis DB. | 0 | REDIS_DB_FOR_DYNACONF=1 REDIS_ENABLED | bool | Redis loader is enabled. | false | REDIS_ENABLED_FOR_DYNACONF=true REDIS_HOST | str | Redis server address. | localhost | REDIS_HOST_FOR_DYNACONF=\u201dlocalhost\u201d REDIS_PORT | int | Redis port. | 6379 | REDIS_PORT_FOR_DYNACONF=8899 ROOT_PATH | str | Directory to look for settings files. This path is the base to search for files defined in *SETTINGS_FILE*. Dynaconf will also search for files in a relative *config/* subfolder if exists. | *None*. If set Dynaconf will look this path first before it starts to search for file in the other locations. see: `<usage.md#the-settings-files>`_ | ROOT_PATH_FOR_DYNACONF=\u201d/my/custom/absolute/path/\u201d SECRETS | str | Path to aditional secrets file to be loaded. | None | SECRETS_FOR_DYNACONF=/var/jenkins/settings_ci.toml SETTINGS_FILE | list, str | List of files to load. | List of all supportes files: *settings.{py,toml,yaml,ini,conf,json} .secrets.{py,toml,yaml,ini,conf,json}*. This var name can be replaced by: *ENVVAR_FOR_DYNACONF=MYPROGRAM_SETTINGS* | SETTINGS_FILE_FOR_DYNACONF=\u201dmyconfig.toml\u201d SETTINGS_FILE_FOR_DYNACONF=\u201d[\u2018conf.toml\u2019,\u2019settings.yaml\u2019]\u201d SETTINGS_FILE_FOR_DYNACONF=\u201dconf.toml,settings.yaml\u201d SETTINGS_FILE_FOR_DYNACONF=\u201dconf.toml;settings.yaml\u201d MYPROGRAM_SETTINGS=\u201dconf.toml,settings.yaml\u201d SILENT_ERRORS | bool | Loading errors should be silenced. | true | SILENT_ERRORS_FOR_DYNACONF=false SKIP_FILES | list | Files to skip/ignore if found on search tree. | [] | SKIP_FILES_FOR_DYNACONF=\u201d[\u2018/absolute/path/to/file.ext\u2019]\u201d VAULT_ALLOW_REDIRECTS | bool | Vault allow redirects. | None | VAULT_ALLOW_REDIRECTS_FOR_DYNACONF=false VAULT_CERT | str | Vault cert/pem file path. | None | VAULT_CERT_FOR_DYNACONF=\u201d~/.ssh/key.pem\u201d VAULT_ENABLED | bool | Vault server is enabled. | false | VAULT_ENABLED_FOR_DYNACONF=true VAULT_HOST | str | Vault host. | localhost | VAULT_HOST_FOR_DYNACONF=\u201dserver\u201d VAULT_PATH | str | Vault path to the configuration. | None | VAULT_PATH_FOR_DYNACONF=\u201dsecret_data\u201d VAULT_PORT | str | Vault port. | 8200 | VAULT_PORT_FOR_DYNACONF=\u201d2800\u201d VAULT_PROXIES | dict | Vault proxies. | None | VAULT_PROXIES_FOR_DYNACONF={http=\u201dhttp:/localhost:3128/\u201d} VAULT_ROLE_ID | str | Vault Role ID. | None | VAULT_ROLE_ID_FOR_DYNACONF=\u201dsome-role-id\u201d VAULT_SCHEME | str | Vault scheme. | http | VAULT_SCHEME_FOR_DYNACONF=\u201dhttps\u201d VAULT_SECRET_ID | str | Vault Secret ID. | None | VAULT_SECRET_ID_FOR_DYNACONF=\u201dsome-secret-id\u201d VAULT_TIMEOUT | int | Vault timeout in seconds. | None | VAULT_TIMEOUT_FOR_DYNACONF=60 VAULT_TOKEN | str | Vault token. | None | VAULT_TOKEN_FOR_DYNACONF=\u201dmyroot\u201d VAULT_URL | str | Vault URL. | http:// localhost :8200 | VAULT_URL_FOR_DYNACONF=\u201dhttp://server/8200\u201d VAULT_VERIFY | bool | Vault should verify. | None | VAULT_VERIFY_FOR_DYNACONF=true YAML_LOADER | str | yaml method name {safe,full,unsafe}_load. | safe_load | YAML_LOADER_FOR_DYNACONF=unsafe_load","title":"Configuration options"},{"location":"guides/configuration/#internal-use-variables","text":"FORCE_ENV_FOR_DYNACONF: This variable exists to support the from_env method, the crontib extensions and to use for testing.","title":"Internal use variables"},{"location":"guides/configuration/#deprecated-options","text":"Some configuration options has been deprecated and replaced with a new name, we try to make it without breaking backwards compatibility with old version, but you may receive a warning if use: PROJECT_ROOT replaced by ROOT_PATH_FOR_DYNACONF PROJECT_ROOT_FOR_DYNACONF replaced by ROOT_PATH_FOR_DYNACONF DYNACONF_NAMESPACE replaced by ENV_FOR_DYNACONF NAMESPACE_FOR_DYNACONF replaced by ENV_FOR_DYNACONF BASE_NAMESPACE_FOR_DYNACONF replaced by DEFAULT_ENV_FOR_DYNACONF DYNACONF_SETTINGS_MODULE replaced by SETTINGS_FILE_FOR_DYNACONF DYNACONF_SETTINGS replaced by SETTINGS_FILE_FOR_DYNACONF SETTINGS_MODULE replaced by SETTINGS_FILE_FOR_DYNACONF DYNACONF_SILENT_ERRORS replaced by SILENT_ERRORS_FOR_DYNACONF DYNACONF_ALWAYS_FRESH_VARS replaced by FRESH_VARS_FOR_DYNACONF GLOBAL_ENV_FOR_DYNACONF replaced by ENVVAR_PREFIX_FOR_DYNACONF SETTINGS_MODULE_FOR_DYNACONF replaced by SETTINGS_FILE_FOR_DYNACONF .. autoclass:: dynaconf.default_settings :show-inheritance:","title":"Deprecated options"},{"location":"guides/contribute/","text":"How to contribute In github repository issues and Pull Request are welcomed! New implementations Bug Fixes Bug reports More examples of use in /example folder Documentation Feedback as issues and comments or joining #dynaconf on freenode Donation to rochacbruno [at] gmail.com in PayPal New implementations - Steps Create and use a new virtualenv and install the requirements of the file requirements_dev.txt. Install the pre-commit pre-commit install --install-hooks During and after development run tests ! py.test -v --cov-config .coveragerc --cov=dynaconf -l tests/ --junitxml=junit/test-results.xml","title":"How to contribute"},{"location":"guides/contribute/#how-to-contribute","text":"In github repository issues and Pull Request are welcomed! New implementations Bug Fixes Bug reports More examples of use in /example folder Documentation Feedback as issues and comments or joining #dynaconf on freenode Donation to rochacbruno [at] gmail.com in PayPal","title":"How to contribute"},{"location":"guides/contribute/#new-implementations-steps","text":"Create and use a new virtualenv and install the requirements of the file requirements_dev.txt. Install the pre-commit pre-commit install --install-hooks During and after development run tests ! py.test -v --cov-config .coveragerc --cov=dynaconf -l tests/ --junitxml=junit/test-results.xml","title":"New implementations - Steps"},{"location":"guides/credits/","text":"Credits Dynaconf is inspired by flask.config and django.conf.settings Some ideas also taken from Rust config crate Environments definitions ideas taken from Rust rocket framework","title":"Credits"},{"location":"guides/credits/#credits","text":"Dynaconf is inspired by flask.config and django.conf.settings Some ideas also taken from Rust config crate Environments definitions ideas taken from Rust rocket framework","title":"Credits"},{"location":"guides/django/","text":"Django Extension New in 2.0.0 Dynaconf extensions for Django works by patching the settings.py file with dynaconf loading hooks, the change is done on a single file and then in your whole project every time you call django.conf.settings you will have access to dynaconf attributes and methods. Ensure dynaconf is installed on your env pip install dynaconf[yaml] Initialize the extension You can manually append at the bottom of your django project's settings.py the following code: # HERE STARTS DYNACONF EXTENSION LOAD (Keep at the very bottom of settings.py) # Read more at https://dynaconf.readthedocs.io/en/latest/guides/django.md import dynaconf # noqa settings = dynaconf.DjangoDynaconf(__name__) # noqa # HERE ENDS DYNACONF EXTENSION LOAD (No more code below this line) Or optionally you can, on the same directory where your manage.py is located run: export DJANGO_SETTINGS_MODULE=yourapp.settings $ dynaconf init # or passing the location of the settings file $ dynaconf init --django yourapp/settings.py Dynaconf will append its extension loading code to the bottom of your yourapp/settings.py file and will create settings.toml and .secrets.toml in the current folder (the same where manage.py is located). TIP Take a look at example/django_example Using DJANGO_ environment variables Then django.conf.settings will work as a dynaconf.settings instance and DJANGO_ will be the global prefix to export environment variables. Example: export DJANGO_DEBUG=true # django.conf.settings.DEBUG export DJANGO_INTVALUE=1 # django.conf.settings['INTVALUE'] export DJANGO_HELLO=\"Hello\" # django.conf.settings.get('HELLO') TIP : If you dont want to use DJANGO_ as prefix for envvars you can customize by passing a new name e.g: dynaconf.DjangoDynaconf(__name__, ENVVAR_PREFIX_FOR_DYNACONF=\"FOO\") then export FOO_DEBUG=true You can also set nested dictionary values, for example lets say you have a configuration like this: settings.py ... DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'module.foo.engine', 'ARGS': {'timeout': 30} } } ... And now you want to change the values of ENGINE to other.module , via environment variables you can use the format ${ENVVAR_PREFIX}_${VARIABLE}__${NESTED_ITEM}__${NESTED_ITEM} Each __ (dunder, a.k.a double underline ) denotes access to nested elements in a dictionary. So: export DYNACONF_DATABASES__default__ENGINE=other.module will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'timeout': 30} } } Read more on environment variables Settings files You can also have settings files for your Django app, in the root directory (the same where manage.py is located) put your settings.{yaml, toml, ini, json, py} and .secrets.{yaml, toml, ini, json, py} files and then define your environments [default] , [development] and [production] . NOTE: .yaml is the recommended format for Django applications because it allows complex data structures in easy way, but feel free to choose any format you are familiar with. To switch the working environment the DJANGO_ENV variable can be used, so DJANGO_ENV=development to work in development mode or DJANGO_ENV=production to switch to production. IMPORTANT : To use $ dynaconf CLI the DJANGO_SETTINGS_MODULE environment variable must be defined. IF you don't want to manually create your config files take a look at the CLI Customizations It is possible to customize how your django project will load settings, example: You want your users to customize a settings file defined in export PROJECTNAME_SETTINGS=/path/to/settings.toml and you want environment variables to be loaded from PROJECTNAME_VARNAME Edit django settings.py and modify the dynaconf extension part: from: # HERE STARTS DYNACONF EXTENSION LOAD ... settings = dynaconf.DjangoDynaconf(__name__) # HERE ENDS DYNACONF EXTENSION LOAD to: # HERE STARTS DYNACONF EXTENSION LOAD ... settings = dynaconf.DjangoDynaconf( __name__, ENVVAR_PREFIX_FOR_DYNACONF='PROJECTNAME', ENV_SWITCHER_FOR_DYNACONF='PROJECTNAME_ENV', SETTINGS_FILE_FOR_DYNACONF='/etc/projectname/settings.toml', ENVVAR_FOR_DYNACONF='PROJECTNAME_SETTINGS', INCLUDES_FOR_DYNACONF=['/etc/projectname/plugins/*'], ) # HERE ENDS DYNACONF EXTENSION LOAD Variables on environment can be set/override using PROJECTNAME_ prefix e.g: export PROJECTNAME_DEBUG=true . Working environment can now be switched using export PROJECTNAME_ENV=production it defaults to development . Your settings are now read from /etc/projectname/settings.toml (dynaconf will not perform search for all the settings formats). This settings location can be changed via envvar using export PROJECTNAME_SETTINGS=/other/path/to/settings.py{yaml,toml,json,ini} You can have additional settings read from /etc/projectname/plugins/* any supoprted file from this folder will be loaded. You can set more options, take a look on configuration Reading Settings on Standalone Scripts NOTE : The recommended way to create standalone scripts is by creating management commands inside your Django applications or pugins. IMPORTANT If you need that script to be out of your Django Application Scope, it is also possible and if needed you can use settings.DYNACONF.configure() instead of the common settings.configure() provided by Django. Examples: Examples below assumes you have DJANGO_SETTINGS_MODULE environment variable set, either by exporting it to your env or by explicitly adding it to os.environ dictionary. IMPORTANT : If you call settings.configure() directly dynaconf will be disabled. As you have DJANGO_SETTINGS_MODULE exported you don't need to call it, but if you need please use: settings.DYNACONF.configure() . Common case /etc/my_script.py from django.conf import settings print(settings.DATABASES) Explicitly adding the setting module /etc/my_script.py import os os.environ['DJANGO_SETTINGS_MODULE'] = 'foo.settings' from django.conf import settings print(settings.DATABASES) When you need the configure Calling DYNACONF.configure() is needed when you want to access dynaconf special methods like using_env , get , get_fresh etc... /etc/my_script.py from django.conf import settings settings.DYNACONF.configure() print(settings.get('DATABASES')) Importing settings directly (recommended for the above case) /etc/my_script.py from foo.settings import settings print(settings.get('DATABASES')) Importing settings via importlib /etc/my_script.py import os import importlib settings = importlib.import_module(os.environ['DJANGO_SETTINGS_MODULE']) print(settings.get('DATABASES')) Testing on Django Django testing must work out of the box! But in some cases when you mock stuff and need to add environment variables to os.environ on demand for test cases it may be needed to reload the dynaconf . To do that write up on your test case setup part: import os import importlib from myapp import settings # NOTE: this uses your app module not django.conf class TestCase(...): def setUp(self): os.environ['DJANGO_FOO'] = 'BAR' # dynaconf should read it and set `settings.FOO` importlib.reload(settings) def test_foo(self): self.assertEqual(settings.FOO, 'BAR') Explicit mode Some users have the preference to explicitly load each setting variable inside the settings.py and then let django manage it in the common way, it is possible. NOTE Doing this way misses the ability to use dynaconf methods like using_env , get etc on your django applications code, you can use it only inside settings.py Dynaconf will be available only on settings.py scope, on the rest of your application settings is managed by Django normally. settings.py import sys from dynaconf import LazySettings settings = LazySettings(**YOUR_OPTIONS_HERE) DEBUG = settings.get('DEBUG', False) DATABASES = settings.get('DATABASES', { 'default': { 'ENGINE': '...', 'NAME': '... } }) ... # At the end of your settings.py settings.populate_obj(sys.modules[__name__], ignore=locals()) NOTE : Starting in 2.1.1 the ignore argument will tell Dynaconf to not override variables that already exists in the current settings file, remove it if you want all the existing local variables to be overwritten by dynaconf. You can still change env with export DJANGO_ENV=production and also can export variables lile export DJANGO_DEBUG=true Knowm Caveats If settings.configure() is called directly it disables Dynaconf, use settings.DYNACONF.configure() Deprecation note On old dynaconf releases the solution was to add dynaconf.contrib.django_dynaconf to INSTALLED_APPS as the first item, this still works but has some limitations so it is not recommended anymore.","title":"Django"},{"location":"guides/django/#django-extension","text":"New in 2.0.0 Dynaconf extensions for Django works by patching the settings.py file with dynaconf loading hooks, the change is done on a single file and then in your whole project every time you call django.conf.settings you will have access to dynaconf attributes and methods. Ensure dynaconf is installed on your env pip install dynaconf[yaml]","title":"Django Extension"},{"location":"guides/django/#initialize-the-extension","text":"You can manually append at the bottom of your django project's settings.py the following code: # HERE STARTS DYNACONF EXTENSION LOAD (Keep at the very bottom of settings.py) # Read more at https://dynaconf.readthedocs.io/en/latest/guides/django.md import dynaconf # noqa settings = dynaconf.DjangoDynaconf(__name__) # noqa # HERE ENDS DYNACONF EXTENSION LOAD (No more code below this line) Or optionally you can, on the same directory where your manage.py is located run: export DJANGO_SETTINGS_MODULE=yourapp.settings $ dynaconf init # or passing the location of the settings file $ dynaconf init --django yourapp/settings.py Dynaconf will append its extension loading code to the bottom of your yourapp/settings.py file and will create settings.toml and .secrets.toml in the current folder (the same where manage.py is located). TIP Take a look at example/django_example","title":"Initialize the extension"},{"location":"guides/django/#using-django_-environment-variables","text":"Then django.conf.settings will work as a dynaconf.settings instance and DJANGO_ will be the global prefix to export environment variables. Example: export DJANGO_DEBUG=true # django.conf.settings.DEBUG export DJANGO_INTVALUE=1 # django.conf.settings['INTVALUE'] export DJANGO_HELLO=\"Hello\" # django.conf.settings.get('HELLO') TIP : If you dont want to use DJANGO_ as prefix for envvars you can customize by passing a new name e.g: dynaconf.DjangoDynaconf(__name__, ENVVAR_PREFIX_FOR_DYNACONF=\"FOO\") then export FOO_DEBUG=true You can also set nested dictionary values, for example lets say you have a configuration like this: settings.py ... DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'module.foo.engine', 'ARGS': {'timeout': 30} } } ... And now you want to change the values of ENGINE to other.module , via environment variables you can use the format ${ENVVAR_PREFIX}_${VARIABLE}__${NESTED_ITEM}__${NESTED_ITEM} Each __ (dunder, a.k.a double underline ) denotes access to nested elements in a dictionary. So: export DYNACONF_DATABASES__default__ENGINE=other.module will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'timeout': 30} } } Read more on environment variables","title":"Using DJANGO_ environment variables"},{"location":"guides/django/#settings-files","text":"You can also have settings files for your Django app, in the root directory (the same where manage.py is located) put your settings.{yaml, toml, ini, json, py} and .secrets.{yaml, toml, ini, json, py} files and then define your environments [default] , [development] and [production] . NOTE: .yaml is the recommended format for Django applications because it allows complex data structures in easy way, but feel free to choose any format you are familiar with. To switch the working environment the DJANGO_ENV variable can be used, so DJANGO_ENV=development to work in development mode or DJANGO_ENV=production to switch to production. IMPORTANT : To use $ dynaconf CLI the DJANGO_SETTINGS_MODULE environment variable must be defined. IF you don't want to manually create your config files take a look at the CLI","title":"Settings files"},{"location":"guides/django/#customizations","text":"It is possible to customize how your django project will load settings, example: You want your users to customize a settings file defined in export PROJECTNAME_SETTINGS=/path/to/settings.toml and you want environment variables to be loaded from PROJECTNAME_VARNAME Edit django settings.py and modify the dynaconf extension part: from: # HERE STARTS DYNACONF EXTENSION LOAD ... settings = dynaconf.DjangoDynaconf(__name__) # HERE ENDS DYNACONF EXTENSION LOAD to: # HERE STARTS DYNACONF EXTENSION LOAD ... settings = dynaconf.DjangoDynaconf( __name__, ENVVAR_PREFIX_FOR_DYNACONF='PROJECTNAME', ENV_SWITCHER_FOR_DYNACONF='PROJECTNAME_ENV', SETTINGS_FILE_FOR_DYNACONF='/etc/projectname/settings.toml', ENVVAR_FOR_DYNACONF='PROJECTNAME_SETTINGS', INCLUDES_FOR_DYNACONF=['/etc/projectname/plugins/*'], ) # HERE ENDS DYNACONF EXTENSION LOAD Variables on environment can be set/override using PROJECTNAME_ prefix e.g: export PROJECTNAME_DEBUG=true . Working environment can now be switched using export PROJECTNAME_ENV=production it defaults to development . Your settings are now read from /etc/projectname/settings.toml (dynaconf will not perform search for all the settings formats). This settings location can be changed via envvar using export PROJECTNAME_SETTINGS=/other/path/to/settings.py{yaml,toml,json,ini} You can have additional settings read from /etc/projectname/plugins/* any supoprted file from this folder will be loaded. You can set more options, take a look on configuration","title":"Customizations"},{"location":"guides/django/#reading-settings-on-standalone-scripts","text":"NOTE : The recommended way to create standalone scripts is by creating management commands inside your Django applications or pugins. IMPORTANT If you need that script to be out of your Django Application Scope, it is also possible and if needed you can use settings.DYNACONF.configure() instead of the common settings.configure() provided by Django.","title":"Reading Settings on Standalone Scripts"},{"location":"guides/django/#examples","text":"Examples below assumes you have DJANGO_SETTINGS_MODULE environment variable set, either by exporting it to your env or by explicitly adding it to os.environ dictionary. IMPORTANT : If you call settings.configure() directly dynaconf will be disabled. As you have DJANGO_SETTINGS_MODULE exported you don't need to call it, but if you need please use: settings.DYNACONF.configure() .","title":"Examples:"},{"location":"guides/django/#common-case","text":"/etc/my_script.py from django.conf import settings print(settings.DATABASES)","title":"Common case"},{"location":"guides/django/#explicitly-adding-the-setting-module","text":"/etc/my_script.py import os os.environ['DJANGO_SETTINGS_MODULE'] = 'foo.settings' from django.conf import settings print(settings.DATABASES)","title":"Explicitly adding the setting module"},{"location":"guides/django/#when-you-need-the-configure","text":"Calling DYNACONF.configure() is needed when you want to access dynaconf special methods like using_env , get , get_fresh etc... /etc/my_script.py from django.conf import settings settings.DYNACONF.configure() print(settings.get('DATABASES'))","title":"When you need the configure"},{"location":"guides/django/#importing-settings-directly-recommended-for-the-above-case","text":"/etc/my_script.py from foo.settings import settings print(settings.get('DATABASES'))","title":"Importing settings directly (recommended for the above case)"},{"location":"guides/django/#importing-settings-via-importlib","text":"/etc/my_script.py import os import importlib settings = importlib.import_module(os.environ['DJANGO_SETTINGS_MODULE']) print(settings.get('DATABASES'))","title":"Importing settings via importlib"},{"location":"guides/django/#testing-on-django","text":"Django testing must work out of the box! But in some cases when you mock stuff and need to add environment variables to os.environ on demand for test cases it may be needed to reload the dynaconf . To do that write up on your test case setup part: import os import importlib from myapp import settings # NOTE: this uses your app module not django.conf class TestCase(...): def setUp(self): os.environ['DJANGO_FOO'] = 'BAR' # dynaconf should read it and set `settings.FOO` importlib.reload(settings) def test_foo(self): self.assertEqual(settings.FOO, 'BAR')","title":"Testing on Django"},{"location":"guides/django/#explicit-mode","text":"Some users have the preference to explicitly load each setting variable inside the settings.py and then let django manage it in the common way, it is possible. NOTE Doing this way misses the ability to use dynaconf methods like using_env , get etc on your django applications code, you can use it only inside settings.py Dynaconf will be available only on settings.py scope, on the rest of your application settings is managed by Django normally. settings.py import sys from dynaconf import LazySettings settings = LazySettings(**YOUR_OPTIONS_HERE) DEBUG = settings.get('DEBUG', False) DATABASES = settings.get('DATABASES', { 'default': { 'ENGINE': '...', 'NAME': '... } }) ... # At the end of your settings.py settings.populate_obj(sys.modules[__name__], ignore=locals()) NOTE : Starting in 2.1.1 the ignore argument will tell Dynaconf to not override variables that already exists in the current settings file, remove it if you want all the existing local variables to be overwritten by dynaconf. You can still change env with export DJANGO_ENV=production and also can export variables lile export DJANGO_DEBUG=true","title":"Explicit mode"},{"location":"guides/django/#knowm-caveats","text":"If settings.configure() is called directly it disables Dynaconf, use settings.DYNACONF.configure()","title":"Knowm Caveats"},{"location":"guides/django/#deprecation-note","text":"On old dynaconf releases the solution was to add dynaconf.contrib.django_dynaconf to INSTALLED_APPS as the first item, this still works but has some limitations so it is not recommended anymore.","title":"Deprecation note"},{"location":"guides/environment_variables/","text":"Environment variables overloading parameters via env vars All configuration parameters, including custom environments and dynaconf configuration , can be overridden through environment variables. To override the configuration parameter {param} , use an environment variable named DYNACONF_{PARAM} . For instance, to override the \"HOST\" configuration parameter, you can run your application with: DYNACONF_HOST='otherhost.com' python yourapp.py '.env' files If you don't want to declare the variables on every program call you can run export DYNACONF_{PARAM} in your shell or put the values in a .env file located in the same directory as your settings files (the root directory of your application or the same folder where your program script is located), variables in .env does not overrride existing environment variables. IMPORTANT : Dynaconf will search for a .env on the order explained here . So to avoid conflicts with existing .env in parent directories it is recommended to have a .env inside your project even if it is empty. Precedence and type casting Environment variables take precedence over all other configuration sources: if the variable is set, it will be used as the value for the parameter even if parameter exists in settings files or in .env . Variable values are parsed as if they were TOML syntax. As illustration, consider the following examples: # Numbers DYNACONF_INTEGER=42 DYNACONF_FLOAT=3.14 # Text DYNACONF_STRING=Hello DYNACONF_STRING=\"Hello\" # Booleans DYNACONF_BOOL=true DYNACONF_BOOL=false # Use extra quotes to force a string from other type DYNACONF_STRING=\"'42'\" DYNACONF_STRING=\"'true'\" # Arrays must be homogenous in toml syntax DYNACONF_ARRAY=[1, 2, 3] DYNACONF_ARRAY=[1.1, 2.2, 3.3] DYNACONF_ARRAY=['a', 'b', 'c'] # Dictionaries DYNACONF_DICT={key=\"abc\",val=123} # toml syntax does not allow `None/null` values so use @none DYNACONF_NONE='@none None' # toml syntax does not allow mixed type arrays so use @json DYNACONF_ARRAY='@json [42, 3.14, \"hello\", true, [\"otherarray\"], {\"foo\": \"bar\"}]' # Lazily formatted string can access env vars and settings variables. # using str.format DYNACONF_DATABASE_PATH=\"@format '{env[HOME]}/.config/databases/{this.DB_NAME}\" # using jinja2 DYNACONF_DATABASE_PATH=\"@jinja {{env.HOME}}/.config/databases/{{this.DB_NAME}}\" NOTE : Older versions of Dynaconf used the @casting prefixes for env vars like export DYNACONF_INTEGER='@int 123' still works but this casting is deprecated in favor of using TOML syntax described above. To disable the @casting do export AUTO_CAST_FOR_DYNACONF=false Merging new data to existing variables Nested keys in dictionaries via environment variables. New in 2.1.0 This is useful for Django settings. Lets say you have a configuration like this: settings.py DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'module.foo.engine', 'ARGS': {'timeout': 30} } } And now you want to change the values of ENGINE to other.module , via environment variables you can use the format ${ENVVAR_PREFIX}_${VARIABLE}__${NESTED_ITEM}__${NESTED_ITEM} Each __ (dunder, a.k.a double underline ) denotes access to nested elements in a dictionary. So DATABASES['default']['ENGINE'] = 'other.module' Can be expressed as environment variables as: export DYNACONF_DATABASES__default__ENGINE=other.module NOTE : if you are using Django extension then the prefix will be DJANGO_ instead of DYNACONF_ and the same if you are using FLASK_ or a custom prefix if you have customized the ENVVAR_PREFIX . This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'timeout': 30} } } IMPORTANT lower case keys are respected only on *nix systems, unfortunately Windows environment variables are case insensitive and Python reads it as all upper cases, that means that if you are running on Windows the dictionary can have only upper case keys. Now if you want to add a new item to ARGS key: export DYNACONF_DATABASES__default__ARGS__retries=10 This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'timeout': 30, 'retries': 10} } } and you can also pass a toml like dictionary to be merged with existing ARGS key using @merge token. new in 3.0.0 # as a toml (recommended) export DYNACONF_DATABASES__default__ARGS='@merge {timeout=50, size=1}' # OR as a json export DYNACONF_DATABASES__default__ARGS='@merge {\"timeout\": 50, \"size\": 1}' # OR as plain key pair export DYNACONF_DATABASES__default__ARGS='@merge timeout=50,size=1' will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'retries': 10, 'timeout': 50, 'size': 1} } } Now if you want to clean an existing nested attribute you can just assign the new value. # As a TOML empty dictionary `\"{}\"` export DYNACONF_DATABASES__default__ARGS='{}' This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {} } } # As a TOML dictionary (recommended) export DYNACONF_DATABASES__default__ARGS='{timeout=90}' This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'timeout': 90} } } And if in any case you need to completely remove that key from the dictionary: export DYNACONF_DATABASES__default__ARGS='@del' This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module' } } Using the dynaconf_merge mark on configuration files. New in 2.0.0 To merge exported variables there is the dynaconf_merge tokens, example: Your main settings file (e.g settings.toml ) has an existing DATABASE dict setting on [default] env. Now you want to contribute to the same DATABASE key by adding new keys, so you can use dynaconf_merge at the end of your dict: In specific [envs] [default] database = {host=\"server.com\", user=\"default\"} [development] database = {user=\"dev_user\", dynaconf_merge=true} or New in 2.2.0 [default] database = {host=\"server.com\", user=\"default\"} [development.database] dynaconf_merge = {user=\"dev_user\"} In an environment variable use @merge token: New in 2.2.0 # Toml formatted envvar export DYNACONF_DATABASE='@merge {password=1234}' or dunder (recommended) # Toml formatted envvar export DYNACONF_DATABASE__PASSWORD=1234 The end result will be on [development] env: settings.DATABASE == {'host': 'server.com', 'user': 'dev_user', 'password': 1234} Read more in Getting Started Guide The global prefix The DYNACONF_{param} prefix is set by ENVVAR_PREFIX_FOR_DYNACONF and serves only to be used in environment variables to override config values. This prefix itself can be changed to something more significant for your application, however we recommend keeping DYNACONF_{param} as your global env prefix. Setting ENVVAR_PREFIX_FOR_DYNACONF to false will disable the prefix entirely and cause Dynaconf to load all environment variables. When providing ENVVAR_PREFIX_FOR_DYNACONF as parameter to LazySettings or settings.configure , make sure to give it a Python-native False : from dynaconf import LazySettings settings = LazySettings(ENVVAR_PREFIX_FOR_DYNACONF=False) NOTE : See the Configuring dynaconf section in documentation to learn more on how to use .env variables to configure dynaconf behavior.","title":"Environment variables"},{"location":"guides/environment_variables/#environment-variables","text":"","title":"Environment variables"},{"location":"guides/environment_variables/#overloading-parameters-via-env-vars","text":"All configuration parameters, including custom environments and dynaconf configuration , can be overridden through environment variables. To override the configuration parameter {param} , use an environment variable named DYNACONF_{PARAM} . For instance, to override the \"HOST\" configuration parameter, you can run your application with: DYNACONF_HOST='otherhost.com' python yourapp.py","title":"overloading parameters via env vars"},{"location":"guides/environment_variables/#env-files","text":"If you don't want to declare the variables on every program call you can run export DYNACONF_{PARAM} in your shell or put the values in a .env file located in the same directory as your settings files (the root directory of your application or the same folder where your program script is located), variables in .env does not overrride existing environment variables. IMPORTANT : Dynaconf will search for a .env on the order explained here . So to avoid conflicts with existing .env in parent directories it is recommended to have a .env inside your project even if it is empty.","title":"'.env' files"},{"location":"guides/environment_variables/#precedence-and-type-casting","text":"Environment variables take precedence over all other configuration sources: if the variable is set, it will be used as the value for the parameter even if parameter exists in settings files or in .env . Variable values are parsed as if they were TOML syntax. As illustration, consider the following examples: # Numbers DYNACONF_INTEGER=42 DYNACONF_FLOAT=3.14 # Text DYNACONF_STRING=Hello DYNACONF_STRING=\"Hello\" # Booleans DYNACONF_BOOL=true DYNACONF_BOOL=false # Use extra quotes to force a string from other type DYNACONF_STRING=\"'42'\" DYNACONF_STRING=\"'true'\" # Arrays must be homogenous in toml syntax DYNACONF_ARRAY=[1, 2, 3] DYNACONF_ARRAY=[1.1, 2.2, 3.3] DYNACONF_ARRAY=['a', 'b', 'c'] # Dictionaries DYNACONF_DICT={key=\"abc\",val=123} # toml syntax does not allow `None/null` values so use @none DYNACONF_NONE='@none None' # toml syntax does not allow mixed type arrays so use @json DYNACONF_ARRAY='@json [42, 3.14, \"hello\", true, [\"otherarray\"], {\"foo\": \"bar\"}]' # Lazily formatted string can access env vars and settings variables. # using str.format DYNACONF_DATABASE_PATH=\"@format '{env[HOME]}/.config/databases/{this.DB_NAME}\" # using jinja2 DYNACONF_DATABASE_PATH=\"@jinja {{env.HOME}}/.config/databases/{{this.DB_NAME}}\" NOTE : Older versions of Dynaconf used the @casting prefixes for env vars like export DYNACONF_INTEGER='@int 123' still works but this casting is deprecated in favor of using TOML syntax described above. To disable the @casting do export AUTO_CAST_FOR_DYNACONF=false","title":"Precedence and type casting"},{"location":"guides/environment_variables/#merging-new-data-to-existing-variables","text":"","title":"Merging new data to existing variables"},{"location":"guides/environment_variables/#nested-keys-in-dictionaries-via-environment-variables","text":"New in 2.1.0 This is useful for Django settings. Lets say you have a configuration like this: settings.py DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'module.foo.engine', 'ARGS': {'timeout': 30} } } And now you want to change the values of ENGINE to other.module , via environment variables you can use the format ${ENVVAR_PREFIX}_${VARIABLE}__${NESTED_ITEM}__${NESTED_ITEM} Each __ (dunder, a.k.a double underline ) denotes access to nested elements in a dictionary. So DATABASES['default']['ENGINE'] = 'other.module' Can be expressed as environment variables as: export DYNACONF_DATABASES__default__ENGINE=other.module NOTE : if you are using Django extension then the prefix will be DJANGO_ instead of DYNACONF_ and the same if you are using FLASK_ or a custom prefix if you have customized the ENVVAR_PREFIX . This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'timeout': 30} } } IMPORTANT lower case keys are respected only on *nix systems, unfortunately Windows environment variables are case insensitive and Python reads it as all upper cases, that means that if you are running on Windows the dictionary can have only upper case keys. Now if you want to add a new item to ARGS key: export DYNACONF_DATABASES__default__ARGS__retries=10 This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'timeout': 30, 'retries': 10} } } and you can also pass a toml like dictionary to be merged with existing ARGS key using @merge token. new in 3.0.0 # as a toml (recommended) export DYNACONF_DATABASES__default__ARGS='@merge {timeout=50, size=1}' # OR as a json export DYNACONF_DATABASES__default__ARGS='@merge {\"timeout\": 50, \"size\": 1}' # OR as plain key pair export DYNACONF_DATABASES__default__ARGS='@merge timeout=50,size=1' will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'retries': 10, 'timeout': 50, 'size': 1} } } Now if you want to clean an existing nested attribute you can just assign the new value. # As a TOML empty dictionary `\"{}\"` export DYNACONF_DATABASES__default__ARGS='{}' This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {} } } # As a TOML dictionary (recommended) export DYNACONF_DATABASES__default__ARGS='{timeout=90}' This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module', 'ARGS': {'timeout': 90} } } And if in any case you need to completely remove that key from the dictionary: export DYNACONF_DATABASES__default__ARGS='@del' This will result in DATABASES = { 'default': { 'NAME': 'db', 'ENGINE': 'other.module' } }","title":"Nested keys in dictionaries via environment variables."},{"location":"guides/environment_variables/#using-the-dynaconf_merge-mark-on-configuration-files","text":"New in 2.0.0 To merge exported variables there is the dynaconf_merge tokens, example: Your main settings file (e.g settings.toml ) has an existing DATABASE dict setting on [default] env. Now you want to contribute to the same DATABASE key by adding new keys, so you can use dynaconf_merge at the end of your dict: In specific [envs] [default] database = {host=\"server.com\", user=\"default\"} [development] database = {user=\"dev_user\", dynaconf_merge=true} or New in 2.2.0 [default] database = {host=\"server.com\", user=\"default\"} [development.database] dynaconf_merge = {user=\"dev_user\"} In an environment variable use @merge token: New in 2.2.0 # Toml formatted envvar export DYNACONF_DATABASE='@merge {password=1234}' or dunder (recommended) # Toml formatted envvar export DYNACONF_DATABASE__PASSWORD=1234 The end result will be on [development] env: settings.DATABASE == {'host': 'server.com', 'user': 'dev_user', 'password': 1234} Read more in Getting Started Guide","title":"Using the dynaconf_merge mark on configuration files."},{"location":"guides/environment_variables/#the-global-prefix","text":"The DYNACONF_{param} prefix is set by ENVVAR_PREFIX_FOR_DYNACONF and serves only to be used in environment variables to override config values. This prefix itself can be changed to something more significant for your application, however we recommend keeping DYNACONF_{param} as your global env prefix. Setting ENVVAR_PREFIX_FOR_DYNACONF to false will disable the prefix entirely and cause Dynaconf to load all environment variables. When providing ENVVAR_PREFIX_FOR_DYNACONF as parameter to LazySettings or settings.configure , make sure to give it a Python-native False : from dynaconf import LazySettings settings = LazySettings(ENVVAR_PREFIX_FOR_DYNACONF=False) NOTE : See the Configuring dynaconf section in documentation to learn more on how to use .env variables to configure dynaconf behavior.","title":"The global prefix"},{"location":"guides/examples/","text":"Examples Supported file formats TOML [default] DEBUG = true SERVER = \"flaskdynaconf.com\" PORT = 6666 MESSAGE = \"Dynaconf works like a charm with Flask and TOML\" TEST_RULE = '/flask_with_toml' [development] DEBUG = true SERVER = \"dev.flaskdynaconf.com\" [production] DEBUG = false SERVER = \"prod.flaskdynaconf.com\" YAML default: DEBUG: true SERVER: flaskdynaconf.com PORT: 6666 MESSAGE: Dynaconf works like a charm with Flask and YAML TEST_RULE: /flask_with_yaml development: DEBUG: true SERVER: dev.flaskdynaconf.com production: DEBUG: false SERVER: prod.flaskdynaconf.com INI [default] DEBUG = true SERVER = \"flaskdynaconf.com\" PORT = 6666 MESSAGE = \"Dynaconf works like a charm with Flask and INI\" TEST_RULE = '/flask_with_ini' [development] DEBUG = true SERVER = \"dev.flaskdynaconf.com\" [production] DEBUG = false SERVER = \"prod.flaskdynaconf.com\" JSON { \"default\": { \"DEBUG\": true, \"SERVER\": \"flaskdynaconf.com\", \"PORT\": 6666, \"MESSAGE\": \"Dynaconf works like a charm with Flask and JSON\", \"TEST_RULE\": \"/flask_with_json\" }, \"development\": { \"DEBUG\": true, \"SERVER\": \"dev.flaskdynaconf.com\" }, \"production\": { \"DEBUG\": false, \"SERVER\": \"prod.flaskdynaconf.com\" } } PY In python fils the environment is set by prefixing the file names settings.py DEBUG = True SERVER = \"flaskdynaconf.com\" PORT = 6666 MESSAGE = \"Dynaconf works like a charm with Flask and .py\" TEST_RULE = '/flask_with_ini' development_settings.py DEBUG = True SERVER = \"dev.flaskdynaconf.com\" production_settings.py DEBUG = False SERVER = \"prod.flaskdynaconf.com\" .env .env allows only the global environment (overrides everything) DEBUG=true SERVER=\"flaskdynaconf.com\" PORT=6666 MESSAGE=\"Dynaconf works like a charm with Flask and .env\" TEST_RULE='/flask_with_ini' Using a default main config file plus variable settings file On the .env export SETTINGS_FILE_FOR_DYNACONF=\"default.toml\" The default file [default] variable1 = 'value1' Now having specific settings per environment Use cases: plugin based apps user specific settings dev specific settings On the user1 environment export INCLUDES_FOR_DYNACONF='/path/to/user1_specific_settings.toml' On the user2 environment export INCLUDES_FOR_DYNACONF='/path/to/user2_specific_settings.toml' It can be a glob export INCLUDES_FOR_DYNACONF='/path/to/config/*.toml' And also supports having a ; or , separated list of paths or globs. More examples Take a look at example/ for more examples.","title":"Examples"},{"location":"guides/examples/#examples","text":"","title":"Examples"},{"location":"guides/examples/#supported-file-formats","text":"","title":"Supported file formats"},{"location":"guides/examples/#toml","text":"[default] DEBUG = true SERVER = \"flaskdynaconf.com\" PORT = 6666 MESSAGE = \"Dynaconf works like a charm with Flask and TOML\" TEST_RULE = '/flask_with_toml' [development] DEBUG = true SERVER = \"dev.flaskdynaconf.com\" [production] DEBUG = false SERVER = \"prod.flaskdynaconf.com\"","title":"TOML"},{"location":"guides/examples/#yaml","text":"default: DEBUG: true SERVER: flaskdynaconf.com PORT: 6666 MESSAGE: Dynaconf works like a charm with Flask and YAML TEST_RULE: /flask_with_yaml development: DEBUG: true SERVER: dev.flaskdynaconf.com production: DEBUG: false SERVER: prod.flaskdynaconf.com","title":"YAML"},{"location":"guides/examples/#ini","text":"[default] DEBUG = true SERVER = \"flaskdynaconf.com\" PORT = 6666 MESSAGE = \"Dynaconf works like a charm with Flask and INI\" TEST_RULE = '/flask_with_ini' [development] DEBUG = true SERVER = \"dev.flaskdynaconf.com\" [production] DEBUG = false SERVER = \"prod.flaskdynaconf.com\"","title":"INI"},{"location":"guides/examples/#json","text":"{ \"default\": { \"DEBUG\": true, \"SERVER\": \"flaskdynaconf.com\", \"PORT\": 6666, \"MESSAGE\": \"Dynaconf works like a charm with Flask and JSON\", \"TEST_RULE\": \"/flask_with_json\" }, \"development\": { \"DEBUG\": true, \"SERVER\": \"dev.flaskdynaconf.com\" }, \"production\": { \"DEBUG\": false, \"SERVER\": \"prod.flaskdynaconf.com\" } }","title":"JSON"},{"location":"guides/examples/#py","text":"In python fils the environment is set by prefixing the file names settings.py DEBUG = True SERVER = \"flaskdynaconf.com\" PORT = 6666 MESSAGE = \"Dynaconf works like a charm with Flask and .py\" TEST_RULE = '/flask_with_ini' development_settings.py DEBUG = True SERVER = \"dev.flaskdynaconf.com\" production_settings.py DEBUG = False SERVER = \"prod.flaskdynaconf.com\"","title":"PY"},{"location":"guides/examples/#env","text":".env allows only the global environment (overrides everything) DEBUG=true SERVER=\"flaskdynaconf.com\" PORT=6666 MESSAGE=\"Dynaconf works like a charm with Flask and .env\" TEST_RULE='/flask_with_ini'","title":".env"},{"location":"guides/examples/#using-a-default-main-config-file-plus-variable-settings-file","text":"On the .env export SETTINGS_FILE_FOR_DYNACONF=\"default.toml\" The default file [default] variable1 = 'value1' Now having specific settings per environment Use cases: plugin based apps user specific settings dev specific settings On the user1 environment export INCLUDES_FOR_DYNACONF='/path/to/user1_specific_settings.toml' On the user2 environment export INCLUDES_FOR_DYNACONF='/path/to/user2_specific_settings.toml' It can be a glob export INCLUDES_FOR_DYNACONF='/path/to/config/*.toml' And also supports having a ; or , separated list of paths or globs.","title":"Using a default main config file plus variable settings file"},{"location":"guides/examples/#more-examples","text":"Take a look at example/ for more examples.","title":"More examples"},{"location":"guides/extend/","text":"Extending Creating new loaders In your project i.e called myprogram create your custom loader. myprogram/my_custom_loader.py def load(obj, env=None, silent=True, key=None, filename=None): \"\"\" Reads and loads in to \"obj\" a single key or all keys from source :param obj: the settings instance :param env: settings current env (upper case) default='DEVELOPMENT' :param silent: if errors should raise :param key: if defined load a single key, else load all from `env` :param filename: Custom filename to load (useful for tests) :return: None \"\"\" # Load data from your custom data source (file, database, memory etc) # use `obj.set(key, value)` or `obj.update(dict)` to load data # use `obj.logger.debug` to log your loader activities # use `obj.find_file('filename.ext')` to find the file in search tree # Return nothing In the .env file or exporting the envvar define: LOADERS_FOR_DYNACONF=['myprogram.my_custom_loader', 'dynaconf.loaders.env_loader'] Dynaconf will import your myprogram.my_custom_loader.load and call it. IMPORTANT : the 'dynaconf.loaders.env_loader' must be the last in the loaders list if you want to keep the behavior of having envvars to override parameters. In case you need to disable all external loaders and rely only the settings.* file loaders define: LOADERS_FOR_DYNACONF=false In case you need to disable all core loaders and rely only on external loaders: CORE_LOADERS_FOR_DYNACONF='[]' # a toml empty list See example/custom_loader","title":"Extending"},{"location":"guides/extend/#extending","text":"","title":"Extending"},{"location":"guides/extend/#creating-new-loaders","text":"In your project i.e called myprogram create your custom loader. myprogram/my_custom_loader.py def load(obj, env=None, silent=True, key=None, filename=None): \"\"\" Reads and loads in to \"obj\" a single key or all keys from source :param obj: the settings instance :param env: settings current env (upper case) default='DEVELOPMENT' :param silent: if errors should raise :param key: if defined load a single key, else load all from `env` :param filename: Custom filename to load (useful for tests) :return: None \"\"\" # Load data from your custom data source (file, database, memory etc) # use `obj.set(key, value)` or `obj.update(dict)` to load data # use `obj.logger.debug` to log your loader activities # use `obj.find_file('filename.ext')` to find the file in search tree # Return nothing In the .env file or exporting the envvar define: LOADERS_FOR_DYNACONF=['myprogram.my_custom_loader', 'dynaconf.loaders.env_loader'] Dynaconf will import your myprogram.my_custom_loader.load and call it. IMPORTANT : the 'dynaconf.loaders.env_loader' must be the last in the loaders list if you want to keep the behavior of having envvars to override parameters. In case you need to disable all external loaders and rely only the settings.* file loaders define: LOADERS_FOR_DYNACONF=false In case you need to disable all core loaders and rely only on external loaders: CORE_LOADERS_FOR_DYNACONF='[]' # a toml empty list See example/custom_loader","title":"Creating new loaders"},{"location":"guides/external_storages/","text":"External storages An external storage is needed in some programs for scenarios like: 1) Having a single storage for settings and distribute across multiple instances 2) The need to change settings on the fly without redeploying or restarting the app (see Feature Flags ) 3) Storing sensitive values in a safe sealed Vault Using REDIS Run a Redis server installed or via docker: $ docker run -d -p 6379:6379 redis Install support for redis in dynaconf $ pip install dynaconf[redis] In your .env file or in exported environment variables define: REDIS_ENABLED_FOR_DYNACONF=true REDIS_HOST_FOR_DYNACONF=localhost REDIS_PORT_FOR_DYNACONF=6379 You can now write variables direct in to a redis hash named DYNACONF_< env > for example: DYNACONF_DEFAULT : default values DYNACONF_DEVELOPMENT : loaded only when ENV_FOR_DYNACONF=development (default) DYNACONF_PRODUCTION : loaded only when ENV_FOR_DYNACONF=production DYNACONF_CUSTOM : loaded only when ENV_FOR_DYNACONF=custom You can also use the redis writer $ dynaconf write redis -v name=Bruno -v database=localhost -v port=1234 The above data will be recorded in redis as a hash: DYNACONF_DEFAULT { NAME='Bruno' DATABASE='localhost' PORT='@int 1234' } If you want to write to specific env pass the -e option. $ dynaconf write redis -v name=Bruno -v database=localhost -v port=1234 -e production The above data will be recorded in redis as a hash: DYNACONF_PRODUCTION { NAME='Bruno' DATABASE='localhost' PORT='@int 1234' } Then to access that values you can set export ENV_FOR_DYNACONF=production or directly via settings.from_env('production').NAME if you want to skip type casting, write as string intead of PORT=1234 use PORT=\"'1234'\". Data is read from redis and another loaders only once when dynaconf.settings is first accessed or when from_env , .setenv() or using_env() are invoked. You can access the fresh value using settings.get_fresh(key) There is also the fresh context manager from dynaconf import settings print(settings.FOO) # this data was loaded once on import with settings.fresh(): print(settings.FOO) # this data is being freshly reloaded from source print(settings.get('FOO', fresh=True)) # this data is being freshly reloaded from source And you can also force some variables to be fresh setting in your setting file FRESH_VARS_FOR_DYNACONF = ['MYSQL_HOST'] or using env vars export FRESH_VARS_FOR_DYNACONF='[\"MYSQL_HOST\", \"OTHERVAR\"]' Then from dynaconf import settings print(settings.FOO) # This data was loaded once on import print(settings.MYSQL_HOST) # This data is being read from redis imediatelly! Using Hashicorp Vault to store secrets Read more in Using Vault Server section Custom Storages Do you want to store settings in other databases like NoSQL, Relational Databases or other services? Please see how to extend dynaconf to add your custom loaders.","title":"External storages"},{"location":"guides/external_storages/#external-storages","text":"An external storage is needed in some programs for scenarios like: 1) Having a single storage for settings and distribute across multiple instances 2) The need to change settings on the fly without redeploying or restarting the app (see Feature Flags ) 3) Storing sensitive values in a safe sealed Vault","title":"External storages"},{"location":"guides/external_storages/#using-redis","text":"Run a Redis server installed or via docker: $ docker run -d -p 6379:6379 redis Install support for redis in dynaconf $ pip install dynaconf[redis] In your .env file or in exported environment variables define: REDIS_ENABLED_FOR_DYNACONF=true REDIS_HOST_FOR_DYNACONF=localhost REDIS_PORT_FOR_DYNACONF=6379 You can now write variables direct in to a redis hash named DYNACONF_< env > for example: DYNACONF_DEFAULT : default values DYNACONF_DEVELOPMENT : loaded only when ENV_FOR_DYNACONF=development (default) DYNACONF_PRODUCTION : loaded only when ENV_FOR_DYNACONF=production DYNACONF_CUSTOM : loaded only when ENV_FOR_DYNACONF=custom You can also use the redis writer $ dynaconf write redis -v name=Bruno -v database=localhost -v port=1234 The above data will be recorded in redis as a hash: DYNACONF_DEFAULT { NAME='Bruno' DATABASE='localhost' PORT='@int 1234' } If you want to write to specific env pass the -e option. $ dynaconf write redis -v name=Bruno -v database=localhost -v port=1234 -e production The above data will be recorded in redis as a hash: DYNACONF_PRODUCTION { NAME='Bruno' DATABASE='localhost' PORT='@int 1234' } Then to access that values you can set export ENV_FOR_DYNACONF=production or directly via settings.from_env('production').NAME if you want to skip type casting, write as string intead of PORT=1234 use PORT=\"'1234'\". Data is read from redis and another loaders only once when dynaconf.settings is first accessed or when from_env , .setenv() or using_env() are invoked. You can access the fresh value using settings.get_fresh(key) There is also the fresh context manager from dynaconf import settings print(settings.FOO) # this data was loaded once on import with settings.fresh(): print(settings.FOO) # this data is being freshly reloaded from source print(settings.get('FOO', fresh=True)) # this data is being freshly reloaded from source And you can also force some variables to be fresh setting in your setting file FRESH_VARS_FOR_DYNACONF = ['MYSQL_HOST'] or using env vars export FRESH_VARS_FOR_DYNACONF='[\"MYSQL_HOST\", \"OTHERVAR\"]' Then from dynaconf import settings print(settings.FOO) # This data was loaded once on import print(settings.MYSQL_HOST) # This data is being read from redis imediatelly!","title":"Using REDIS"},{"location":"guides/external_storages/#using-hashicorp-vault-to-store-secrets","text":"Read more in Using Vault Server section","title":"Using Hashicorp Vault to store secrets"},{"location":"guides/external_storages/#custom-storages","text":"Do you want to store settings in other databases like NoSQL, Relational Databases or other services? Please see how to extend dynaconf to add your custom loaders.","title":"Custom Storages"},{"location":"guides/feature_flag/","text":"Feature flag system feature toggles Feature flagging is a system to dynamically toggle features in your application based in some settings value. The advantage of using it is to perform changes on the fly without the need to redeploy ou restart the application. Learn more on how to design your program using Feature Flags: http://martinfowler.com/articles/feature-toggles.md Example: Lets say you have 2 versions of your app dashboard and you want to serve the new version only for premium users. write flags to redis $ dynaconf write redis -s NEWDASHBOARD=true -e premiumuser In your program do: usertype = 'premiumuser' # assume you loaded it as part of your auth # user has access to new dashboard? if settings.flag('newdashboard', usertype): activate_new_dashboard() else: # User will have old dashboard if not a premiumuser activate_old_dashboard() The value is ensured to be loaded fresh from redis server so features can be enabled or disabled at any time without the need to redeploy. It also works with file settings but the recommended is redis as the data can be loaded once it is updated.","title":"Feature flag system"},{"location":"guides/feature_flag/#feature-flag-system","text":"","title":"Feature flag system"},{"location":"guides/feature_flag/#feature-toggles","text":"Feature flagging is a system to dynamically toggle features in your application based in some settings value. The advantage of using it is to perform changes on the fly without the need to redeploy ou restart the application. Learn more on how to design your program using Feature Flags: http://martinfowler.com/articles/feature-toggles.md Example: Lets say you have 2 versions of your app dashboard and you want to serve the new version only for premium users. write flags to redis $ dynaconf write redis -s NEWDASHBOARD=true -e premiumuser In your program do: usertype = 'premiumuser' # assume you loaded it as part of your auth # user has access to new dashboard? if settings.flag('newdashboard', usertype): activate_new_dashboard() else: # User will have old dashboard if not a premiumuser activate_old_dashboard() The value is ensured to be loaded fresh from redis server so features can be enabled or disabled at any time without the need to redeploy. It also works with file settings but the recommended is redis as the data can be loaded once it is updated.","title":"feature toggles"},{"location":"guides/flask/","text":"Flask Extension Dynaconf provides a drop in replacement for app.config . As Flask encourages the composition by overriding the config_class attribute this extension follows the patterns of Flask and turns your Flask's app.config in to a dynaconf instance. Initialize the extension Initialize the FlaskDynaconf extension in your app from flask import Flask from dynaconf import FlaskDynaconf app = Flask(__name__) FlaskDynaconf(app) You can optionally use init_app as well. Use FLASK_ environment variables Then the app.config will work as a dynaconf.settings instance and FLASK_ will be the global prefix for exporting environment variables. Example: export FLASK_DEBUG=true # app.config.DEBUG export FLASK_INTVALUE=1 # app.config['INTVALUE'] export FLASK_MAIL_SERVER='host.com' # app.config.get('MAIL_SERVER') Settings files You can also have settings files for your Flask app, in the root directory (the same where you execute flask run ) put your settings.toml and .secrets.toml files and then define your environments [default] , [development] and [production] . To switch the working environment the FLASK_ENV variable can be used, so FLASK_ENV=development to work in development mode or FLASK_ENV=production to switch to production. IMPORTANT : To use $ dynaconf CLI the FLASK_APP must be defined. IF you don't want to manually create your config files take a look at the CLI Customizations It is possible to customize how your Flask project will load settings, example: You want your users to customize a settings file defined in export PROJECTNAME_SETTINGS=/path/to/settings.toml and you want environment variables to be loaded from PROJECTNAME_VARNAME your flask app.py (or wherever you setup dynaconf) ENVVAR_PREFIX_FOR_DYNACONF = \"PROJECTNAME\" \"\"\"This defines which environment variable global prefix dynaconf will load That means that `export PROJECTNAME_FOO=1` will be loaded to `app.config.FOO On command line it is possible to check it with `dynaconf list -k foo`\"\"\" ENVVAR_FOR_DYNACONF = \"PROJECTNAME_SETTINGS\" \"\"\"This defines which path dynaconf will look to load config files example: export PROJECTNAME_SETTINGS=/path/to/settings.toml and the format can be .ini, .json, .yaml or .toml e.g:: export PROJECTNAME_SETTINGS=settings.toml [default] FOO = 1 [development] FOO = 2 [production] FOO = 3 OR:: export PROJECTNAME_SETTINGS=settings.yaml default: foo: 1 development: foo: 2 production: foo: 3 It is also possible to pass a list of files:: export PROJECTNAME_SETTINGS=settings.toml,other_settings.yaml,another.json The variables will be cascaded in the defined order (last wins the precedence) The environment variables wins precedence over all! \"\"\" # load dynaconf app = Flask(__name__) FlaskDynaconf( app, ENVVAR_PREFIX_FOR_DYNACONF=ENVVAR_PREFIX_FOR_DYNACONF, ENVVAR_FOR_DYNACONF=ENVVAR_FOR_DYNACONF ) Then the working environment can now be switched using export PROJECTNAME_ENV=production Loading Flask Extensions Dynamically You can tell Dynaconf to load your Flask Extensions dynamically as long as the extensions follows the Pattens of Flask extensions. The only requirement is that the extension must be a callable that accepts app as first argument. e.g: flask_admin:Admin or custom_extension.module:init_app and of course the extension must be in Python namespace to be imported. For extensions initialized just use the class or function path like: \"flask_admin:Admin\" or \"extension.module:init_app\" having a settings.toml [default] EXTENSIONS = [ \"flask_admin:Admin\", \"flask_bootstrap:Bootstrap\", \"custom_extension.module:init_app\" ] Considering an app.py like: from flask import Flask from dynaconf import FlaskDynaconf app = Flask(__name__) flask_dynaconf = FlaskDynaconf(app) app.config.load_extensions() Optionally you can pass load_extensions(key=\"OTHER_NAME\") pointing to your list of extensions. It is also possible to use environment variables to set the extensions to be loaded. # .env export FLASK_EXTENSIONS=\"['flask_admin:Admin']\" The extensions will be loaded in order. Develoment extensions It is also possible to have extensions that loads only in development environment. [default] EXTENSIONS = [ \"flask_admin:Admin\", \"flask_bootstrap:Bootstrap\", \"custom_extension.module:init_app\" ] [development] EXTENSIONS = [ \"dynaconf_merge\", \"flask_debugtoolbar:DebugToolbar\" ]","title":"Flask"},{"location":"guides/flask/#flask-extension","text":"Dynaconf provides a drop in replacement for app.config . As Flask encourages the composition by overriding the config_class attribute this extension follows the patterns of Flask and turns your Flask's app.config in to a dynaconf instance.","title":"Flask Extension"},{"location":"guides/flask/#initialize-the-extension","text":"Initialize the FlaskDynaconf extension in your app from flask import Flask from dynaconf import FlaskDynaconf app = Flask(__name__) FlaskDynaconf(app) You can optionally use init_app as well.","title":"Initialize the extension"},{"location":"guides/flask/#use-flask_-environment-variables","text":"Then the app.config will work as a dynaconf.settings instance and FLASK_ will be the global prefix for exporting environment variables. Example: export FLASK_DEBUG=true # app.config.DEBUG export FLASK_INTVALUE=1 # app.config['INTVALUE'] export FLASK_MAIL_SERVER='host.com' # app.config.get('MAIL_SERVER')","title":"Use FLASK_ environment variables"},{"location":"guides/flask/#settings-files","text":"You can also have settings files for your Flask app, in the root directory (the same where you execute flask run ) put your settings.toml and .secrets.toml files and then define your environments [default] , [development] and [production] . To switch the working environment the FLASK_ENV variable can be used, so FLASK_ENV=development to work in development mode or FLASK_ENV=production to switch to production. IMPORTANT : To use $ dynaconf CLI the FLASK_APP must be defined. IF you don't want to manually create your config files take a look at the CLI","title":"Settings files"},{"location":"guides/flask/#customizations","text":"It is possible to customize how your Flask project will load settings, example: You want your users to customize a settings file defined in export PROJECTNAME_SETTINGS=/path/to/settings.toml and you want environment variables to be loaded from PROJECTNAME_VARNAME your flask app.py (or wherever you setup dynaconf) ENVVAR_PREFIX_FOR_DYNACONF = \"PROJECTNAME\" \"\"\"This defines which environment variable global prefix dynaconf will load That means that `export PROJECTNAME_FOO=1` will be loaded to `app.config.FOO On command line it is possible to check it with `dynaconf list -k foo`\"\"\" ENVVAR_FOR_DYNACONF = \"PROJECTNAME_SETTINGS\" \"\"\"This defines which path dynaconf will look to load config files example: export PROJECTNAME_SETTINGS=/path/to/settings.toml and the format can be .ini, .json, .yaml or .toml e.g:: export PROJECTNAME_SETTINGS=settings.toml [default] FOO = 1 [development] FOO = 2 [production] FOO = 3 OR:: export PROJECTNAME_SETTINGS=settings.yaml default: foo: 1 development: foo: 2 production: foo: 3 It is also possible to pass a list of files:: export PROJECTNAME_SETTINGS=settings.toml,other_settings.yaml,another.json The variables will be cascaded in the defined order (last wins the precedence) The environment variables wins precedence over all! \"\"\" # load dynaconf app = Flask(__name__) FlaskDynaconf( app, ENVVAR_PREFIX_FOR_DYNACONF=ENVVAR_PREFIX_FOR_DYNACONF, ENVVAR_FOR_DYNACONF=ENVVAR_FOR_DYNACONF ) Then the working environment can now be switched using export PROJECTNAME_ENV=production","title":"Customizations"},{"location":"guides/flask/#loading-flask-extensions-dynamically","text":"You can tell Dynaconf to load your Flask Extensions dynamically as long as the extensions follows the Pattens of Flask extensions. The only requirement is that the extension must be a callable that accepts app as first argument. e.g: flask_admin:Admin or custom_extension.module:init_app and of course the extension must be in Python namespace to be imported. For extensions initialized just use the class or function path like: \"flask_admin:Admin\" or \"extension.module:init_app\" having a settings.toml [default] EXTENSIONS = [ \"flask_admin:Admin\", \"flask_bootstrap:Bootstrap\", \"custom_extension.module:init_app\" ] Considering an app.py like: from flask import Flask from dynaconf import FlaskDynaconf app = Flask(__name__) flask_dynaconf = FlaskDynaconf(app) app.config.load_extensions() Optionally you can pass load_extensions(key=\"OTHER_NAME\") pointing to your list of extensions. It is also possible to use environment variables to set the extensions to be loaded. # .env export FLASK_EXTENSIONS=\"['flask_admin:Admin']\" The extensions will be loaded in order.","title":"Loading Flask Extensions Dynamically"},{"location":"guides/flask/#develoment-extensions","text":"It is also possible to have extensions that loads only in development environment. [default] EXTENSIONS = [ \"flask_admin:Admin\", \"flask_bootstrap:Bootstrap\", \"custom_extension.module:init_app\" ] [development] EXTENSIONS = [ \"dynaconf_merge\", \"flask_debugtoolbar:DebugToolbar\" ]","title":"Develoment extensions"},{"location":"guides/sensitive_secrets/","text":"Sensitive secrets Using .secrets files To safely store sensitive data Dynaconf also searches for a .secrets.{toml|py|json|ini|yaml} file to look for data like tokens and passwords. example .secrets.toml : [default] password = \"sek@987342$\" The secrets file supports all the environment definitions supported in the settings file. IMPORTANT : The reason to use a .secrets.* file is the ability to omit this file when committing to the repository so a recommended .gitignore should include .secrets.* line. Using Vault server The vaultproject.io/ is a key:value store for secrets and Dynaconf can load variables from a Vault secret. Run a vault server Run a Vault server installed or via docker: $ docker run -d -e 'VAULT_DEV_ROOT_TOKEN_ID=myroot' -p 8200:8200 vault Install support for vault in dynaconf $ pip install dynaconf[vault] In your .env file or in exported environment variables define: VAULT_ENABLED_FOR_DYNACONF=true VAULT_URL_FOR_DYNACONF=\"http://localhost:8200\" VAULT_TOKEN_FOR_DYNACONF=\"myroot\" Now you can have keys like PASSWORD and TOKEN defined in the vault and dynaconf will read it. To write a new secret you can use http://localhost:8200 web admin and write keys under the /secret/dynaconf/< env > secret database. You can also use the Dynaconf writer via console: # writes {'password': 123456} to secret/dynaconf/default $ dynaconf write vault -s password=123456 # writes {'password': 123456, 'username': 'admin'} to secret/dynaconf/default $ dynaconf write vault -s password=123456 -s username=admin # writes {'password': 555555} to secret/dynaconf/development $ dynaconf write vault -s password=555555 -e development # writes {'password': 777777, 'username': 'admin'} to secret/dynaconf/production $ dynaconf write vault -s password=777777 -s username=produser -e production then you can access values normally in your program from dynaconf import settings settings.PASSWORD == 555555 # if ENV_FOR_DYNACONF is the default `development` settings.USERNAME == 'admin' # if ENV_FOR_DYNACONF is the default `development` settings.PASSWORD == 777777 # if ENV_FOR_DYNACONF is `production` settings.USERNAME == 'produser' # if ENV_FOR_DYNACONF is `production` You can also ask settings to be loaded from specific env with from_env method: settings.from_env('production').PASSWORD == 777777 settings.from_env('production').USERNAME == 'produser' Additional secrets file (for CI, jenkins etc.) It is common to have an extra secrets file that is available only when running on specific CI environment like Jenkins , usually there will be an environment variable pointing to the file. On Jenkins it is done on job settings by exporting the secrets information. Dynaconf can handle this via SECRETS_FOR_DYNACONF environment variable. ex: export SECRETS_FOR_DYNACONF=/path/to/secrets.toml{json|py|ini|yaml} If that variable exists in your environment then Dynaconf will also load it.","title":"Sensitive secrets"},{"location":"guides/sensitive_secrets/#sensitive-secrets","text":"","title":"Sensitive secrets"},{"location":"guides/sensitive_secrets/#using-secrets-files","text":"To safely store sensitive data Dynaconf also searches for a .secrets.{toml|py|json|ini|yaml} file to look for data like tokens and passwords. example .secrets.toml : [default] password = \"sek@987342$\" The secrets file supports all the environment definitions supported in the settings file. IMPORTANT : The reason to use a .secrets.* file is the ability to omit this file when committing to the repository so a recommended .gitignore should include .secrets.* line.","title":"Using .secrets files"},{"location":"guides/sensitive_secrets/#using-vault-server","text":"The vaultproject.io/ is a key:value store for secrets and Dynaconf can load variables from a Vault secret. Run a vault server Run a Vault server installed or via docker: $ docker run -d -e 'VAULT_DEV_ROOT_TOKEN_ID=myroot' -p 8200:8200 vault Install support for vault in dynaconf $ pip install dynaconf[vault] In your .env file or in exported environment variables define: VAULT_ENABLED_FOR_DYNACONF=true VAULT_URL_FOR_DYNACONF=\"http://localhost:8200\" VAULT_TOKEN_FOR_DYNACONF=\"myroot\" Now you can have keys like PASSWORD and TOKEN defined in the vault and dynaconf will read it. To write a new secret you can use http://localhost:8200 web admin and write keys under the /secret/dynaconf/< env > secret database. You can also use the Dynaconf writer via console: # writes {'password': 123456} to secret/dynaconf/default $ dynaconf write vault -s password=123456 # writes {'password': 123456, 'username': 'admin'} to secret/dynaconf/default $ dynaconf write vault -s password=123456 -s username=admin # writes {'password': 555555} to secret/dynaconf/development $ dynaconf write vault -s password=555555 -e development # writes {'password': 777777, 'username': 'admin'} to secret/dynaconf/production $ dynaconf write vault -s password=777777 -s username=produser -e production then you can access values normally in your program from dynaconf import settings settings.PASSWORD == 555555 # if ENV_FOR_DYNACONF is the default `development` settings.USERNAME == 'admin' # if ENV_FOR_DYNACONF is the default `development` settings.PASSWORD == 777777 # if ENV_FOR_DYNACONF is `production` settings.USERNAME == 'produser' # if ENV_FOR_DYNACONF is `production` You can also ask settings to be loaded from specific env with from_env method: settings.from_env('production').PASSWORD == 777777 settings.from_env('production').USERNAME == 'produser'","title":"Using Vault server"},{"location":"guides/sensitive_secrets/#additional-secrets-file-for-ci-jenkins-etc","text":"It is common to have an extra secrets file that is available only when running on specific CI environment like Jenkins , usually there will be an environment variable pointing to the file. On Jenkins it is done on job settings by exporting the secrets information. Dynaconf can handle this via SECRETS_FOR_DYNACONF environment variable. ex: export SECRETS_FOR_DYNACONF=/path/to/secrets.toml{json|py|ini|yaml} If that variable exists in your environment then Dynaconf will also load it.","title":"Additional secrets file (for CI, jenkins etc.)"},{"location":"guides/testing/","text":"Testing For testing it is recommended to just switch to testing environment and read the same config files. settings.toml [default] value = \"On Default\" [testing] value = \"On Testing\" program.py from dynaconf import settings print(settings.VALUE) ENV_FOR_DYNACONF=testing python program.py Then your program.py will print \"On Testing\" red from [testing] environment. Pytest For pytest it is common to create fixtures to provide pre-configured settings object or to configure the settings before all the tests are collected. Examples available on https://github.com/rochacbruno/dynaconf/tree/master/example/pytest_example With pytest fixtures it is recommended to use the FORCE_ENV_FOR_DYNACONF isntead of just ENV_FOR_DYNACONF because it has precedence. A python program settings.toml with the [testing] environment. [default] VALUE = \"On Default\" [testing] VALUE = \"On Testing\" app.py that reads that value from current environment. from dynaconf import settings def return_a_value(): return settings.VALUE tests/conftest.py with a fixture to force settings to run pointing to [testing] environment. import pytest from dynaconf import settings @pytest.fixture(scope=\"session\", autouse=True) def set_test_settings(): settings.configure(FORCE_ENV_FOR_DYNACONF=\"testing\") tests/test_dynaconf.py to assert that the correct environment is loaded from app import return_a_value def test_dynaconf_is_in_testing_env(): assert return_a_value() == \"On Testing\" A Flask program settings.toml with the [testing] environment. [default] VALUE = \"On Default\" [testing] VALUE = \"On Testing\" src.py that has a Flask application factory from flask import Flask from dynaconf.contrib import FlaskDynaconf def create_app(**config): app = Flask(__name__) FlaskDynaconf(app, **config) return app tests/conftest.py with a fixture to provide app dependency injection to all the tests, And force this app to point to [testing] config environment. import pytest from src import create_app @pytest.fixture(scope=\"session\") def app(): app = create_app(FORCE_ENV_FOR_DYNACONF=\"testing\") return app tests/test_flask_dynaconf.py to assert that the correct environment is loaded def test_dynaconf_is_on_testing_env(app): assert app.config[\"VALUE\"] == \"On Testing\" assert app.config.current_env == \"testing\" Mocking But it is common in unit tests to mock some objects and you may need in rare cases to mock the dynaconf.settings when running your tests. from dynaconf.utils import DynaconfDict mocked_settings = DynaconfDict({'FOO': 'BAR'}) DynaconfDict is a dict like obj that can be populated from a file: from dynaconf.loaders import toml_loader toml_loader.load(mocked_settings, filename='my_file.toml', env='testing')","title":"Testing"},{"location":"guides/testing/#testing","text":"For testing it is recommended to just switch to testing environment and read the same config files. settings.toml [default] value = \"On Default\" [testing] value = \"On Testing\" program.py from dynaconf import settings print(settings.VALUE) ENV_FOR_DYNACONF=testing python program.py Then your program.py will print \"On Testing\" red from [testing] environment.","title":"Testing"},{"location":"guides/testing/#pytest","text":"For pytest it is common to create fixtures to provide pre-configured settings object or to configure the settings before all the tests are collected. Examples available on https://github.com/rochacbruno/dynaconf/tree/master/example/pytest_example With pytest fixtures it is recommended to use the FORCE_ENV_FOR_DYNACONF isntead of just ENV_FOR_DYNACONF because it has precedence.","title":"Pytest"},{"location":"guides/testing/#a-python-program","text":"settings.toml with the [testing] environment. [default] VALUE = \"On Default\" [testing] VALUE = \"On Testing\" app.py that reads that value from current environment. from dynaconf import settings def return_a_value(): return settings.VALUE tests/conftest.py with a fixture to force settings to run pointing to [testing] environment. import pytest from dynaconf import settings @pytest.fixture(scope=\"session\", autouse=True) def set_test_settings(): settings.configure(FORCE_ENV_FOR_DYNACONF=\"testing\") tests/test_dynaconf.py to assert that the correct environment is loaded from app import return_a_value def test_dynaconf_is_in_testing_env(): assert return_a_value() == \"On Testing\"","title":"A python program"},{"location":"guides/testing/#a-flask-program","text":"settings.toml with the [testing] environment. [default] VALUE = \"On Default\" [testing] VALUE = \"On Testing\" src.py that has a Flask application factory from flask import Flask from dynaconf.contrib import FlaskDynaconf def create_app(**config): app = Flask(__name__) FlaskDynaconf(app, **config) return app tests/conftest.py with a fixture to provide app dependency injection to all the tests, And force this app to point to [testing] config environment. import pytest from src import create_app @pytest.fixture(scope=\"session\") def app(): app = create_app(FORCE_ENV_FOR_DYNACONF=\"testing\") return app tests/test_flask_dynaconf.py to assert that the correct environment is loaded def test_dynaconf_is_on_testing_env(app): assert app.config[\"VALUE\"] == \"On Testing\" assert app.config.current_env == \"testing\"","title":"A Flask program"},{"location":"guides/testing/#mocking","text":"But it is common in unit tests to mock some objects and you may need in rare cases to mock the dynaconf.settings when running your tests. from dynaconf.utils import DynaconfDict mocked_settings = DynaconfDict({'FOO': 'BAR'}) DynaconfDict is a dict like obj that can be populated from a file: from dynaconf.loaders import toml_loader toml_loader.load(mocked_settings, filename='my_file.toml', env='testing')","title":"Mocking"},{"location":"guides/usage/","text":"Getting Started Installation Python 3.x is required $ pip install dynaconf Default installation supports .toml, .py and .json file formats and also environment variables (.env supported) - to support YAML add pip install dynaconf[yaml] or pip install dynaconf[all] Usage Accessing config variables in your Python application In your Python program wherever you need to access a settings variable you use the canonical object from dynaconf import settings : Example of program to connect to some database from some.db import Client from dynaconf import settings conn = Client( username=settings.USERNAME, # attribute style access password=settings.get('PASSWORD'), # dict get style access port=settings['PORT'], # dict item style access timeout=settings.as_int('TIMEOUT'), # Forcing casting if needed host=settings.get('HOST', 'localhost') # Providing defaults ) Understanding the settings Dynaconf aims to have a flexible and usable configuration system. Your applications can be configured via a configuration files , through environment variables , or both. Configurations can be separated into environments: [default], [development], [staging], [testing] and [production] . The working environment is switched via an environment variable. But this is all optional you can of course follow strictly the 12 factor app guide, have your configuration coming only from environment variables and provide files only to store [default] values. (take also a look on how to add a dynaconf validation file to your project). Sensitive data like tokens, secret keys and password can be stored in .secrets.* files and/or external storages like Redis or vault secrets server. Besides the built-in optional support to Redis as settings storage dynaconf allows you to create Custom Loaders and store the data wherever you want e.g: databases, memory storages, other file formats, nosql databases etc. Working environments At any point in time, your application is operating in a given configuration environment. By default there are four such environments: [development] (selected by default) [staging] [testing] [production] [{custom}] <-- You can create named environments that you need There is also the pseudo-envs [default] to provide comprehensive default values and [global] to provide global values to override in any other environment. Without any action, your applications by default run in the [development] environment. The environment can be changed via the ENV_FOR_DYNACONF environment variable. For example, to launch an application in the [staging] environment, we can run: export ENV_FOR_DYNACONF=staging or ENV_FOR_DYNACONF=staging python yourapp.py NOTE: When using Flask Extension the environment can be changed via FLASK_ENV variable and for Django Extension you can use DJANGO_ENV . The settings files NOTE: The settings files are optional. If it is not present, only the values from environment variables and enabled external loaders are used ( .env file is also supported). Dynaconf will search for the settings files defined in SETTINGS_FILE_FOR_DYNACONF which by default is a list containing combinations of settings.{py|toml|json|ini|yaml} and .secrets.{py|toml|json|ini|yaml} and dynaconf will try to find each one of those combinations, optionally it is possible to configure it to a different set of files e.g: export SETTINGS_FILE_FOR_DYNACONF='[\"myfilename.toml\", \"another.json\"]' , this value contains a list of relative or absolute paths, can be a toml-like list or a comma/semicolon separated string and can be exported to envvars , write to .env file or passed directly to Dynaconf instance. IMPORTANT: Dynaconf by default reads settings files using utf-8 encoding, if you have settings files written in other encoding please set ENCODING_FOR_DYNACONF environment variable. See more details in configuration Settings files location To find the files defined in SETTINGS_FILE_FOR_DYNACONF the search will start at the path defined in ROOT_PATH_FOR_DYNACONF (if defined), then will recursively walk to its root and then will try the folder where the called program is located and then it will recursively try its parent directories until the root parent is reached which can be File System / or the current working dir then finally will try the current working directory as the last option. NOTE : If by any reason you need Dynaconf to first look at the current working dir you can customize the ROOT_PATH_FOR_DYNACONF via environment variable or by creating a custom settings object Some people prefer to put settings in a sub-folder so for each of the paths it will also search in a relative folder called config/ . And for each file dynaconf will also try to load a .local. file, for example, if you have a settings.toml after loading it Dynaconf will also try to find a settings.local.toml if exists. Dynaconf will stop searching on the first match for each file and if no file is found it will fail silently unless SILENT_ERRORS_FOR_DYNACONF=false is exported. Illustrative Example New in 2.0.0 If your program has the following structure: |_ myprogram/ |_ src/ |_ app.py # from dynaconf import settings # print(settings.NAME) # print(settings.PASSWORD) # print(settings.FOO) |_ config |_ settings.toml # [default] # name = \"Jon Doe\" |_ settings.local.toml # [default] # name = \"Oscar Wilde\" |_ .env # DYNACONF_FOO='BAR' |_ .secrets.toml # [default] # password = \"Utopi@\" And you call it from myprogram working dir. cd myprogram python src/app.py What happens is: NOTE: The behavior explained here is valid only for the above file structure, other arrangements are possible and depending on how folders are organized dynaconf can behave differently. app.py:1 does from dynaconf import settings Only the .env file will be searched, other settings are lazy evaluated. .env will be searched starting on myprogram/src/.env if not found then myprogram/src/config/.env if not found then myprogram/.env actually found here so stops searching if not found then myprogram/config/.env It will load all values from .env to the environment variables and create the instance of settings app.py:2 does the first access to a settings on print(settings.NAME) Dynaconf will execute the loaders defined in CORE_LOADERS and LOADERS , it will initialize the settings object and start the file search. settings.{py|toml|json|ini|yaml} will be searched on myprogram/src/ if not found then myprogram/src/config if not found then myprogram/ if not found then myprogram/config settings.toml actually found here so stops searching for toml It will load all the values defined in the settings.toml It will continue to look all the other files e.g: settings.json, settings.ini, settings.yaml etc. Then It will search for .secrets.{py|toml|json|ini|yaml} on myprogram/src/ if not found then myprogram/src/config if not found then myprogram/ .secrets.toml actually found here so stops searching for toml if not found then myprogram/config It will load all the values defined in .secrets.toml (if filename is *.secret.* values are hidden on logs) It will continue to look all the other files e.g: .secrets.json, .secrets.ini, .secrets.yaml etc. Then It will iterate the list of loaded files containing [settings.toml, .secrets.toml] and for each of them it will also try to find a settings.local.toml ( found in myprogram/settings.local.toml ) and a .secrets.local.toml using the same search tree until it is found or it will skip if not found. Then It will execute external loaders like Redis and Vault if enabled. It will execute custom loaders if configured. Then finally It will read all environment variables prefixed with DYNACONF_ and load its values, in our example it loads FOO='BAR' from .env file. app.py:3 does second access to a settings on print(settings.PASSWORD) All the loaders, loaded files, config options and vars are now cached no loading has been executed. Only if settings.get_fresh('PASSWORD') is used, dynaconf will force a re-load of everything to ensure the fresh value. Also if settings.using_env|from_env or ENV_FOR_DYNACONF switched, e.g: from [development] to [staging] , then re-load happens. It is also possible to explicitly force a load or reload . Complete program output is: Oscar Wilde Utopi@ BAR TIP: If you add DEBUG_LEVEL_FOR_DYNACONF=DEBUG on .env or export this variable then you can follow the dynaconf loading process. Loading order Dynaconf loads file in a overriding cascade loading order using the predefined order: First the environment variables (and .env file) to read for configuration options Then the paths provided in PRELOAD_FOR_DYNACONF using all enabled loaders. Then the files defined in SETTINGS_FILE_FOR_DYNACONF using all enabled loaders. Files containing .local. in its name will be loaded at the end. e.g: settings.local.yaml Then contents of SECRETS_FOR_DYNACONF envvar filename if defined (useful for jenkins and other CI) Then the loaders defined in LOADERS_FOR_DYNACONF Redis if enabled by REDIS_FOR_DYNACONF=1 Vault if enabled by Vault_FOR_DYNACONF=1 Custom loaders if any added Environment variables loader will be the last always If there is any DYNACONF_INCLUDE key found or INCLUDES_FOR_DYNACONF env vars this will be loaded. The order can be changed by overriding the SETTINGS_FILE_FOR_DYNACONF the CORE_LOADERS_FOR_DYNACONF and LOADERS_FOR_DYNACONF variables. NOTE : Dynaconf works in an layered override mode based on the above order, so if you have multiple file formats with conflicting keys defined, the precedence will be based on the loading order. If you dont want to have values like lists and dicts overwritten take a look on how to merge existing values Local configuration files and merging to existing data New in 2.2.0 This feature is useful for maintaining a shared set of config files for a team, while still allowing for local configuration. Any file matched by the glob *.local.* will be read at the end of file loading order. So it is possible to have local settings files that are for example not committed to the version controlled repository. (e:g add **/*.local* to your .gitignore ) So if you have settings.toml Dynaconf will load it and after all will also try to load a file named settings.local.toml if it does exist. And the same applies to all the other supported extensions settings.local.{py,json,yaml,toml,ini,cfg} Example: # settings.toml # <-- 1st loaded [default] colors = [\"green\", \"blue\"] parameters = {enabled=true, number=42} # .secrets.toml # <-- 2nd loaded (overrides previous existing vars) [default] password = 1234 # settings.local.toml # <-- 3rd loaded (overrides previous existing vars) [default] colors = [\"pink\"] parameters = {enabled=false} password = 9999 So with above the values will be: settings.COLORS == [\"pink\"] settings.PARAMETERS == {\"enabled\": False} settings.PASSWORD == 9999 For each loaded file dynaconf will override previous existing keys so if you want to append new values to existing variables you can use 3 strategies. Mark the local file to be entirely merged New in 2.2.0 # settings.local.toml dynaconf_merge = true [default] colors = [\"pink\"] parameters = {enabled=false} By adding dynaconf_merge to the top root of the file mark entire file to be merged. And then the values will be updated in to existing data structures. settings.COLORS == [\"pink\", \"green\", \"blue\"] settings.PARAMETERS == {\"enabled\": False, \"number\": 42} settings.PASSWORD == 9999 You can also mark a single env like [development] to be merged. # settings.local.toml [development] dynaconf_merge = true colors = [\"pink\"] parameters = {enabled=false} dynaconf merge token # settings.local.toml [default] colors = [\"pink\", \"dynaconf_merge\"] parameters = {enabled=false, dynaconf_merge=true} By adding dynaconf_merge to a list or dict marks it as a merge candidate. And then the values will be updated in to existing data structures. settings.COLORS == [\"pink\", \"green\", \"blue\"] settings.PARAMETERS == {\"enabled\": False, \"number\": 42} settings.PASSWORD == 9999 New in 2.2.0 And it also works having dynaconf_merge as dict keys holding the value to be merged. # settings.local.toml [default.colors] dynaconf_merge = [\"pink\"] # <-- value [\"pink\"] will be merged in to existing colors [default.parameters] dynaconf_merge = {enabled=false} Dunder merging for nested structures For nested structures the recommendation is to use dunder merging because it it easier to read and also it has no limitations in terms of nesting levels. # settings.local.yaml [default] parameters__enabled = false The use of __ to denote nested level will ensure the key is merged with existing values read more in merging existing values . Global merge export MERGE_ENABLED_FOR_DYNACONF=true or put it in your .env file then Dynaconf will automatically merge all existing variables. BEWARE : Using MERGE_ENABLED_FOR_DYNACONF can lead to unexpected results because you do not have granular control of what is being merged or overwritten so the recommendation is to use other options. Settings File Formats The recommended file format is TOML but you can choose to use any of .{py|toml|json|ini|yaml} . The file must be a series of sections, at least one for [default] , optionally one for each [environment] , and an optional [global] section. Each section contains key-value pairs corresponding to configuration parameters for that [environment] . If a configuration parameter is missing, the value from [default] is used. The following is a complete settings.toml file, where every standard configuration parameter is specified within the [default] section: NOTE : if the file format choosen is .py as it does not support sections you can create multiple files like settings.py for [default], development_settings.py , production_settings.py and global_settings.py . ATTENTION : using .py is not recommended for configuration - prefer to use static files like TOML ! [default] username = \"admin\" port = 5000 host = \"localhost\" message = \"default message\" value = \"default value\" [development] username = \"devuser\" [staging] host = \"staging.server.com\" [testing] host = \"testing.server.com\" [production] host = \"server.com\" [awesomeenv] value = \"this value is set for custom [awesomeenv]\" [global] message = \"This value overrides message of default and other envs\" The [global] pseudo-environment can be used to set and/or override configuration parameters globally. A parameter defined in a [global] section sets, or overrides if already present, that parameter in every environment. IMPORTANT: the environments and pseudo envs such as [global], ['default'] affects only the current file, it means that a value in [global] will override values defined only on that file or previous loaded files, if in another file the value is reloaded then the global values is overwritten. Dynaconf supports multiple file formats but the recommendation is not to mix them, choose a format and stick with it. For example, given the following settings.toml file, the value of address will be \"1.2.3.4\" in every environment: [global] address = \"1.2.3.4\" [development] address = \"localhost\" [production] address = \"0.0.0.0\" NOTE : The [env] name and first level variables are case insensitive as internally dynaconf will always use upper case, that means [development] and [DEVELOPMENT] are equivalent and address and ADDRESS are also equivalent. But the recommendation is to always use lower case in files and always use upper case in env vars and .py files (This rule does not apply for inner data structures as dictionaries and arrays). Supported file formats By default toml is the recommended format to store your configuration, however you can switch to a different supported format. # If you wish to include support for more sources pip3 install dynaconf[yaml|ini|redis|vault] # for a complete installation pip3 install dynaconf[all] Once the support is installed no extra configuration is needed to load data from those files. If you need a different file format take a look on how to extend dynaconf writing a custom loader Additional secrets file (for CI, jenkins etc.) It is common to have an extra secrets file that is available only when running on specific CI environment like Jenkins , usually there will be an environment variable pointing to the file. On Jenkins it is done on job settings by exporting the secrets information. Dynaconf can handle this via SECRETS_FOR_DYNACONF environment variable. ex: export SECRETS_FOR_DYNACONF=/path/to/settings.toml{json|py|ini|yaml} If that variable exists in your environment then Dynaconf will also load it. Including files inside files Sometimes you have multiple fragments of settings in different files, dynaconf allow easy merging of those files via dynaconf_include . Example: plugin1.toml [development] plugin_specific_variable = 'value for development' and even mixing different formats: plugin2.yaml production: plugin_specific_variable: 'value for production' Then it can be merged on main settings.toml file via dynaconf_include settings.toml [default] dynaconf_include = [\"plugin1.toml\", \"plugin2.yaml\"] DEBUG = false SERVER = \"base.example.com\" PORT = 6666 A settings file can include a dynaconf_include stanza, whose exact syntax will depend on the type of settings file (json, yaml, toml, etc) being used: cfg [default] dynaconf_include = [\"/absolute/path/to/plugin1.toml\", \"relative/path/to/plugin2.toml\"] DEBUG = false SERVER = \"www.example.com\" When loaded, the files located at the (relative or absolute) paths in the dynaconf_include key will be parsed, in order, and override any base settings that may exist in your current configuration. The paths can be relative to the base settings.(toml|yaml|json|ini|py) file, or can be absolute paths. The idea here is that plugins or extensions for whatever framework or architecture you are using can provide their own configuration values when necessary. It is also possible to specify glob-based patterns: cfg [default] dynaconf_include = [\"configurations/*.toml\"] DEBUG = false SERVER = \"www.example.com\" Currently, only a single level of includes is permitted to keep things simple and straightforward. Including via environment variable It is also possible to setup includes using environment variable. # A glob pattern export INCLUDES_FOR_DYNACONF='/etc/myprogram/conf.d/*.toml' # a single path export INCLUDES_FOR_DYNACONF='/path/to/file.yaml' # multiple files export INCLUDES_FOR_DYNACONF='/path/to/file.yaml;/other/path/to/file.toml' Programmatically loading a settings file from dynaconf import settings settings.load_file(path=\"/path/to/file.toml\") # list or `;/,` separated allowed NOTE : programmatically loaded file is not persisted, once env is changed via setenv|ugin_env , or a reload or configure is invoked it will be cleaned, to persist it needs to go to INCLUDES_FOR_DYNACONF variable or you need to load it programmatically again. Template substitutions Dynaconf has 2 tokens to enable string substitutions @format and @jinja . @format token Dynaconf allows template substitutions for strings values, by using the @format token prefix and including placeholders accepted by Python's str.format method Dynaconf will call it lazily upon access time. The call will be like: \"<YOURVALUE>\".format(env=os.environ, this=dynaconf.settings) So in your string you can refer to environment variables via env object, and also to variables defined int the settings object itself via this reference. It is lazily evaluated on access it will use the final value for a settings regardless the order of load. Example: export PROGRAM_NAME=calculator settings.toml [default] DB_NAME = \"mydb.db\" [development] DB_PATH = \"@format {env[HOME]}/{this.current_env}/{env[PROGRAM_NAME]}/{this.DB_NAME}\" {env[HOME]} is the same as os.environ[\"HOME\"] or $HOME in the shell. {this.current_env} is the same as settings.current_env {env[PROGRAM_NAME]} is the same as os.environ[\"PROGRAM_NAME\"] or $PROGRAM_NAME in the shell. {this.DB_NAME} is the same as settins.DB_NAME or settings[\"DB_NAME\"] so in your program from dynaconf import settings settings.DB_PATH == '~/DEVELOPMENT/calculator/mydb.db' @jinja token If jinja2 package is installed then dynaconf will also allow the use jinja to render string values. Example: export PROGRAM_NAME=calculator settings.toml [default] DB_NAME = \"mydb.db\" [development] DB_NAME = \"@jinja {{env.HOME}}/{{this.current_env | lower}}/{{env[\"PROGRAM_NAME\"]}}/{{this.DB_NAME}}\" so in your program from dynaconf import settings settings.DB_PATH == '~/development/calculator/mydb.db' The main difference is that Jinja allows some Python expressions to be avaluated such as {% for, if, while %} and also supports calling methods and has lots of filters like | lower . Jinja supports its built-in filters listed in Builtin Filters Page and Dynaconf includes aditional filters for os.path module: abspath . realpath , relpath , basename and dirname and usage is like: VALUE = \"@jinja {{this.FOO | abspath}}\" Merging existing data structures If your settings has existing variables of types list ot dict and you want to merge instead of override then the dynaconf_merge and dynaconf_merge_unique stanzas can mark that variable as a candidate for merging. For dict value: Your main settings file (e.g settings.toml ) has an existing DATABASE dict setting on [default] env. Now you want to contribute to the same DATABASE key by adding new keys, so you can use dynaconf_merge at the end of your dict: In specific [envs] [default] database = {host=\"server.com\", user=\"default\"} [development] database = {user=\"dev_user\", dynaconf_merge=true} [production] database = {user=\"prod_user\", dynaconf_merge=true} also allowed the alternative short format [default] database = {host=\"server.com\", user=\"default\"} [development.database] dynaconf_merge = {user=\"dev_user\"} [production.database] dynaconf_merge = {user=\"prod_user\"} In an environment variable: Using @merge mark # Toml formatted envvar export DYNACONF_DATABASE='@merge {password=1234}' or @merge mark short format # Toml formatted envvar export DYNACONF_DATABASE='@merge password=1234' It is also possible to use nested dunder traversal like: export DYNACONF_DATABASE__password=1234 export DYNACONF_DATABASE__user=admin export DYNACONF_DATABASE__ARGS__timeout=30 export DYNACONF_DATABASE__ARGS__retries=5 Each __ is parsed as a level traversing thought dict keys. read more in environment variables So the above will result in DATABASE = {'password': 1234, 'user': 'admin', 'ARGS': {'timeout': 30, 'retries': 5}} IMPORTANT lower case keys are respected only on *nix systems, unfortunately Windows environment variables are case insensitive and Python reads it as all upper cases, that means that if you are running on Windows the dictionary can have only upper case keys. You can also export a toml dictionary. # Toml formatted envvar export DYNACONF_DATABASE='{password=1234, dynaconf_merge=true}' Or in an additional file (e.g settings.yaml, .secrets.yaml, etc ) by using dynaconf_merge token: default: database: password: 1234 dynaconf_merge: true or default: database: dynaconf_merge: password: 1234 The dynaconf_merge token will mark that object to be merged with existing values (of course dynaconf_merge key will not be added to the final settings it is just a mark) The end result will be on [development] env: settings.DATABASE == {'host': 'server.com', 'user': 'dev_user', 'password': 1234} The same can be applied to lists : settings.toml [default] plugins = [\"core\"] [development] plugins = [\"debug_toolbar\", \"dynaconf_merge\"] or [default] plugins = [\"core\"] [development.plugins] dynaconf_merge = [\"debug_toolbar\"] And in environment variable using @merge token export DYNACONF_PLUGINS='@merge [\"ci_plugin\"]' or short version export DYNACONF_PLUGINS='@merge ci_plugin' comma separated values also supported: export DYNACONF_PLUGINS='@merge ci_plugin,other_plugin' or explicitly export DYNACONF_PLUGINS='[\"ci_plugin\", \"dynaconf_merge\"]' Then the end result on [development] is: settings.PLUGINS == [\"ci_plugin\", \"debug_toolbar\", \"core\"] If your value is a dictionary: export DYNACONF_DATA=\"@merge {foo='bar'}\" # or the short export DYNACONF_DATA=\"@merge foo=bar\" Avoiding duplications on lists The dynaconf_merge_unique is the token for when you want to avoid duplications in a list. Example: [default] scripts = ['install.sh', 'deploy.sh'] [development] scripts = ['dev.sh', 'test.sh', 'deploy.sh', 'dynaconf_merge_unique'] export DYNACONF_SCRIPTS='[\"deploy.sh\", \"run.sh\", \"dynaconf_merge_unique\"]' The end result for [development] will be: settings.SCRIPTS == ['install.sh', 'dev.sh', 'test.sh', 'deploy.sh', 'run.sh'] Note that deploy.sh is set 3 times but it is not repeated in the final settings. Known caveats The dynaconf_merge and @merge functionalities works only for the first level keys, it will not merge subdicts or nested lists (yet). For deeper nested objects use dunder merge . Global merge export MERGE_ENABLED_FOR_DYNACONF=true or put it in your .env file then Dynaconf will automatically merge all existing variables. BEWARE : Using MERGE_ENABLED_FOR_DYNACONF can lead to unexpected results because you do not have granular control of what is being merged or overwritten so the recommendation is to use other options. More examples Take a look at the example folder to see some examples of use with different file formats and features.","title":"Getting started"},{"location":"guides/usage/#getting-started","text":"","title":"Getting Started"},{"location":"guides/usage/#installation","text":"Python 3.x is required $ pip install dynaconf Default installation supports .toml, .py and .json file formats and also environment variables (.env supported) - to support YAML add pip install dynaconf[yaml] or pip install dynaconf[all]","title":"Installation"},{"location":"guides/usage/#usage","text":"","title":"Usage"},{"location":"guides/usage/#accessing-config-variables-in-your-python-application","text":"In your Python program wherever you need to access a settings variable you use the canonical object from dynaconf import settings :","title":"Accessing config variables in your Python application"},{"location":"guides/usage/#example-of-program-to-connect-to-some-database","text":"from some.db import Client from dynaconf import settings conn = Client( username=settings.USERNAME, # attribute style access password=settings.get('PASSWORD'), # dict get style access port=settings['PORT'], # dict item style access timeout=settings.as_int('TIMEOUT'), # Forcing casting if needed host=settings.get('HOST', 'localhost') # Providing defaults )","title":"Example of program to connect to some database"},{"location":"guides/usage/#understanding-the-settings","text":"Dynaconf aims to have a flexible and usable configuration system. Your applications can be configured via a configuration files , through environment variables , or both. Configurations can be separated into environments: [default], [development], [staging], [testing] and [production] . The working environment is switched via an environment variable. But this is all optional you can of course follow strictly the 12 factor app guide, have your configuration coming only from environment variables and provide files only to store [default] values. (take also a look on how to add a dynaconf validation file to your project). Sensitive data like tokens, secret keys and password can be stored in .secrets.* files and/or external storages like Redis or vault secrets server. Besides the built-in optional support to Redis as settings storage dynaconf allows you to create Custom Loaders and store the data wherever you want e.g: databases, memory storages, other file formats, nosql databases etc.","title":"Understanding the settings"},{"location":"guides/usage/#working-environments","text":"At any point in time, your application is operating in a given configuration environment. By default there are four such environments: [development] (selected by default) [staging] [testing] [production] [{custom}] <-- You can create named environments that you need There is also the pseudo-envs [default] to provide comprehensive default values and [global] to provide global values to override in any other environment. Without any action, your applications by default run in the [development] environment. The environment can be changed via the ENV_FOR_DYNACONF environment variable. For example, to launch an application in the [staging] environment, we can run: export ENV_FOR_DYNACONF=staging or ENV_FOR_DYNACONF=staging python yourapp.py NOTE: When using Flask Extension the environment can be changed via FLASK_ENV variable and for Django Extension you can use DJANGO_ENV .","title":"Working environments"},{"location":"guides/usage/#the-settings-files","text":"NOTE: The settings files are optional. If it is not present, only the values from environment variables and enabled external loaders are used ( .env file is also supported). Dynaconf will search for the settings files defined in SETTINGS_FILE_FOR_DYNACONF which by default is a list containing combinations of settings.{py|toml|json|ini|yaml} and .secrets.{py|toml|json|ini|yaml} and dynaconf will try to find each one of those combinations, optionally it is possible to configure it to a different set of files e.g: export SETTINGS_FILE_FOR_DYNACONF='[\"myfilename.toml\", \"another.json\"]' , this value contains a list of relative or absolute paths, can be a toml-like list or a comma/semicolon separated string and can be exported to envvars , write to .env file or passed directly to Dynaconf instance. IMPORTANT: Dynaconf by default reads settings files using utf-8 encoding, if you have settings files written in other encoding please set ENCODING_FOR_DYNACONF environment variable. See more details in configuration","title":"The settings files"},{"location":"guides/usage/#settings-files-location","text":"To find the files defined in SETTINGS_FILE_FOR_DYNACONF the search will start at the path defined in ROOT_PATH_FOR_DYNACONF (if defined), then will recursively walk to its root and then will try the folder where the called program is located and then it will recursively try its parent directories until the root parent is reached which can be File System / or the current working dir then finally will try the current working directory as the last option. NOTE : If by any reason you need Dynaconf to first look at the current working dir you can customize the ROOT_PATH_FOR_DYNACONF via environment variable or by creating a custom settings object Some people prefer to put settings in a sub-folder so for each of the paths it will also search in a relative folder called config/ . And for each file dynaconf will also try to load a .local. file, for example, if you have a settings.toml after loading it Dynaconf will also try to find a settings.local.toml if exists. Dynaconf will stop searching on the first match for each file and if no file is found it will fail silently unless SILENT_ERRORS_FOR_DYNACONF=false is exported.","title":"Settings files location"},{"location":"guides/usage/#illustrative-example","text":"New in 2.0.0 If your program has the following structure: |_ myprogram/ |_ src/ |_ app.py # from dynaconf import settings # print(settings.NAME) # print(settings.PASSWORD) # print(settings.FOO) |_ config |_ settings.toml # [default] # name = \"Jon Doe\" |_ settings.local.toml # [default] # name = \"Oscar Wilde\" |_ .env # DYNACONF_FOO='BAR' |_ .secrets.toml # [default] # password = \"Utopi@\" And you call it from myprogram working dir. cd myprogram python src/app.py What happens is: NOTE: The behavior explained here is valid only for the above file structure, other arrangements are possible and depending on how folders are organized dynaconf can behave differently. app.py:1 does from dynaconf import settings Only the .env file will be searched, other settings are lazy evaluated. .env will be searched starting on myprogram/src/.env if not found then myprogram/src/config/.env if not found then myprogram/.env actually found here so stops searching if not found then myprogram/config/.env It will load all values from .env to the environment variables and create the instance of settings app.py:2 does the first access to a settings on print(settings.NAME) Dynaconf will execute the loaders defined in CORE_LOADERS and LOADERS , it will initialize the settings object and start the file search. settings.{py|toml|json|ini|yaml} will be searched on myprogram/src/ if not found then myprogram/src/config if not found then myprogram/ if not found then myprogram/config settings.toml actually found here so stops searching for toml It will load all the values defined in the settings.toml It will continue to look all the other files e.g: settings.json, settings.ini, settings.yaml etc. Then It will search for .secrets.{py|toml|json|ini|yaml} on myprogram/src/ if not found then myprogram/src/config if not found then myprogram/ .secrets.toml actually found here so stops searching for toml if not found then myprogram/config It will load all the values defined in .secrets.toml (if filename is *.secret.* values are hidden on logs) It will continue to look all the other files e.g: .secrets.json, .secrets.ini, .secrets.yaml etc. Then It will iterate the list of loaded files containing [settings.toml, .secrets.toml] and for each of them it will also try to find a settings.local.toml ( found in myprogram/settings.local.toml ) and a .secrets.local.toml using the same search tree until it is found or it will skip if not found. Then It will execute external loaders like Redis and Vault if enabled. It will execute custom loaders if configured. Then finally It will read all environment variables prefixed with DYNACONF_ and load its values, in our example it loads FOO='BAR' from .env file. app.py:3 does second access to a settings on print(settings.PASSWORD) All the loaders, loaded files, config options and vars are now cached no loading has been executed. Only if settings.get_fresh('PASSWORD') is used, dynaconf will force a re-load of everything to ensure the fresh value. Also if settings.using_env|from_env or ENV_FOR_DYNACONF switched, e.g: from [development] to [staging] , then re-load happens. It is also possible to explicitly force a load or reload . Complete program output is: Oscar Wilde Utopi@ BAR TIP: If you add DEBUG_LEVEL_FOR_DYNACONF=DEBUG on .env or export this variable then you can follow the dynaconf loading process.","title":"Illustrative Example"},{"location":"guides/usage/#loading-order","text":"Dynaconf loads file in a overriding cascade loading order using the predefined order: First the environment variables (and .env file) to read for configuration options Then the paths provided in PRELOAD_FOR_DYNACONF using all enabled loaders. Then the files defined in SETTINGS_FILE_FOR_DYNACONF using all enabled loaders. Files containing .local. in its name will be loaded at the end. e.g: settings.local.yaml Then contents of SECRETS_FOR_DYNACONF envvar filename if defined (useful for jenkins and other CI) Then the loaders defined in LOADERS_FOR_DYNACONF Redis if enabled by REDIS_FOR_DYNACONF=1 Vault if enabled by Vault_FOR_DYNACONF=1 Custom loaders if any added Environment variables loader will be the last always If there is any DYNACONF_INCLUDE key found or INCLUDES_FOR_DYNACONF env vars this will be loaded. The order can be changed by overriding the SETTINGS_FILE_FOR_DYNACONF the CORE_LOADERS_FOR_DYNACONF and LOADERS_FOR_DYNACONF variables. NOTE : Dynaconf works in an layered override mode based on the above order, so if you have multiple file formats with conflicting keys defined, the precedence will be based on the loading order. If you dont want to have values like lists and dicts overwritten take a look on how to merge existing values","title":"Loading order"},{"location":"guides/usage/#local-configuration-files-and-merging-to-existing-data","text":"New in 2.2.0 This feature is useful for maintaining a shared set of config files for a team, while still allowing for local configuration. Any file matched by the glob *.local.* will be read at the end of file loading order. So it is possible to have local settings files that are for example not committed to the version controlled repository. (e:g add **/*.local* to your .gitignore ) So if you have settings.toml Dynaconf will load it and after all will also try to load a file named settings.local.toml if it does exist. And the same applies to all the other supported extensions settings.local.{py,json,yaml,toml,ini,cfg} Example: # settings.toml # <-- 1st loaded [default] colors = [\"green\", \"blue\"] parameters = {enabled=true, number=42} # .secrets.toml # <-- 2nd loaded (overrides previous existing vars) [default] password = 1234 # settings.local.toml # <-- 3rd loaded (overrides previous existing vars) [default] colors = [\"pink\"] parameters = {enabled=false} password = 9999 So with above the values will be: settings.COLORS == [\"pink\"] settings.PARAMETERS == {\"enabled\": False} settings.PASSWORD == 9999 For each loaded file dynaconf will override previous existing keys so if you want to append new values to existing variables you can use 3 strategies.","title":"Local configuration files and merging to existing data"},{"location":"guides/usage/#mark-the-local-file-to-be-entirely-merged","text":"New in 2.2.0 # settings.local.toml dynaconf_merge = true [default] colors = [\"pink\"] parameters = {enabled=false} By adding dynaconf_merge to the top root of the file mark entire file to be merged. And then the values will be updated in to existing data structures. settings.COLORS == [\"pink\", \"green\", \"blue\"] settings.PARAMETERS == {\"enabled\": False, \"number\": 42} settings.PASSWORD == 9999 You can also mark a single env like [development] to be merged. # settings.local.toml [development] dynaconf_merge = true colors = [\"pink\"] parameters = {enabled=false}","title":"Mark the local file to be entirely merged"},{"location":"guides/usage/#dynaconf-merge-token","text":"# settings.local.toml [default] colors = [\"pink\", \"dynaconf_merge\"] parameters = {enabled=false, dynaconf_merge=true} By adding dynaconf_merge to a list or dict marks it as a merge candidate. And then the values will be updated in to existing data structures. settings.COLORS == [\"pink\", \"green\", \"blue\"] settings.PARAMETERS == {\"enabled\": False, \"number\": 42} settings.PASSWORD == 9999 New in 2.2.0 And it also works having dynaconf_merge as dict keys holding the value to be merged. # settings.local.toml [default.colors] dynaconf_merge = [\"pink\"] # <-- value [\"pink\"] will be merged in to existing colors [default.parameters] dynaconf_merge = {enabled=false}","title":"dynaconf merge token"},{"location":"guides/usage/#dunder-merging-for-nested-structures","text":"For nested structures the recommendation is to use dunder merging because it it easier to read and also it has no limitations in terms of nesting levels. # settings.local.yaml [default] parameters__enabled = false The use of __ to denote nested level will ensure the key is merged with existing values read more in merging existing values .","title":"Dunder merging for nested structures"},{"location":"guides/usage/#global-merge","text":"export MERGE_ENABLED_FOR_DYNACONF=true or put it in your .env file then Dynaconf will automatically merge all existing variables. BEWARE : Using MERGE_ENABLED_FOR_DYNACONF can lead to unexpected results because you do not have granular control of what is being merged or overwritten so the recommendation is to use other options.","title":"Global merge"},{"location":"guides/usage/#settings-file-formats","text":"The recommended file format is TOML but you can choose to use any of .{py|toml|json|ini|yaml} . The file must be a series of sections, at least one for [default] , optionally one for each [environment] , and an optional [global] section. Each section contains key-value pairs corresponding to configuration parameters for that [environment] . If a configuration parameter is missing, the value from [default] is used. The following is a complete settings.toml file, where every standard configuration parameter is specified within the [default] section: NOTE : if the file format choosen is .py as it does not support sections you can create multiple files like settings.py for [default], development_settings.py , production_settings.py and global_settings.py . ATTENTION : using .py is not recommended for configuration - prefer to use static files like TOML ! [default] username = \"admin\" port = 5000 host = \"localhost\" message = \"default message\" value = \"default value\" [development] username = \"devuser\" [staging] host = \"staging.server.com\" [testing] host = \"testing.server.com\" [production] host = \"server.com\" [awesomeenv] value = \"this value is set for custom [awesomeenv]\" [global] message = \"This value overrides message of default and other envs\" The [global] pseudo-environment can be used to set and/or override configuration parameters globally. A parameter defined in a [global] section sets, or overrides if already present, that parameter in every environment. IMPORTANT: the environments and pseudo envs such as [global], ['default'] affects only the current file, it means that a value in [global] will override values defined only on that file or previous loaded files, if in another file the value is reloaded then the global values is overwritten. Dynaconf supports multiple file formats but the recommendation is not to mix them, choose a format and stick with it. For example, given the following settings.toml file, the value of address will be \"1.2.3.4\" in every environment: [global] address = \"1.2.3.4\" [development] address = \"localhost\" [production] address = \"0.0.0.0\" NOTE : The [env] name and first level variables are case insensitive as internally dynaconf will always use upper case, that means [development] and [DEVELOPMENT] are equivalent and address and ADDRESS are also equivalent. But the recommendation is to always use lower case in files and always use upper case in env vars and .py files (This rule does not apply for inner data structures as dictionaries and arrays).","title":"Settings File Formats"},{"location":"guides/usage/#supported-file-formats","text":"By default toml is the recommended format to store your configuration, however you can switch to a different supported format. # If you wish to include support for more sources pip3 install dynaconf[yaml|ini|redis|vault] # for a complete installation pip3 install dynaconf[all] Once the support is installed no extra configuration is needed to load data from those files. If you need a different file format take a look on how to extend dynaconf writing a custom loader","title":"Supported file formats"},{"location":"guides/usage/#additional-secrets-file-for-ci-jenkins-etc","text":"It is common to have an extra secrets file that is available only when running on specific CI environment like Jenkins , usually there will be an environment variable pointing to the file. On Jenkins it is done on job settings by exporting the secrets information. Dynaconf can handle this via SECRETS_FOR_DYNACONF environment variable. ex: export SECRETS_FOR_DYNACONF=/path/to/settings.toml{json|py|ini|yaml} If that variable exists in your environment then Dynaconf will also load it.","title":"Additional secrets file (for CI, jenkins etc.)"},{"location":"guides/usage/#including-files-inside-files","text":"Sometimes you have multiple fragments of settings in different files, dynaconf allow easy merging of those files via dynaconf_include . Example: plugin1.toml [development] plugin_specific_variable = 'value for development' and even mixing different formats: plugin2.yaml production: plugin_specific_variable: 'value for production' Then it can be merged on main settings.toml file via dynaconf_include settings.toml [default] dynaconf_include = [\"plugin1.toml\", \"plugin2.yaml\"] DEBUG = false SERVER = \"base.example.com\" PORT = 6666 A settings file can include a dynaconf_include stanza, whose exact syntax will depend on the type of settings file (json, yaml, toml, etc) being used: cfg [default] dynaconf_include = [\"/absolute/path/to/plugin1.toml\", \"relative/path/to/plugin2.toml\"] DEBUG = false SERVER = \"www.example.com\" When loaded, the files located at the (relative or absolute) paths in the dynaconf_include key will be parsed, in order, and override any base settings that may exist in your current configuration. The paths can be relative to the base settings.(toml|yaml|json|ini|py) file, or can be absolute paths. The idea here is that plugins or extensions for whatever framework or architecture you are using can provide their own configuration values when necessary. It is also possible to specify glob-based patterns: cfg [default] dynaconf_include = [\"configurations/*.toml\"] DEBUG = false SERVER = \"www.example.com\" Currently, only a single level of includes is permitted to keep things simple and straightforward.","title":"Including files inside files"},{"location":"guides/usage/#including-via-environment-variable","text":"It is also possible to setup includes using environment variable. # A glob pattern export INCLUDES_FOR_DYNACONF='/etc/myprogram/conf.d/*.toml' # a single path export INCLUDES_FOR_DYNACONF='/path/to/file.yaml' # multiple files export INCLUDES_FOR_DYNACONF='/path/to/file.yaml;/other/path/to/file.toml'","title":"Including via environment variable"},{"location":"guides/usage/#programmatically-loading-a-settings-file","text":"from dynaconf import settings settings.load_file(path=\"/path/to/file.toml\") # list or `;/,` separated allowed NOTE : programmatically loaded file is not persisted, once env is changed via setenv|ugin_env , or a reload or configure is invoked it will be cleaned, to persist it needs to go to INCLUDES_FOR_DYNACONF variable or you need to load it programmatically again.","title":"Programmatically loading a settings file"},{"location":"guides/usage/#template-substitutions","text":"Dynaconf has 2 tokens to enable string substitutions @format and @jinja .","title":"Template substitutions"},{"location":"guides/usage/#format-token","text":"Dynaconf allows template substitutions for strings values, by using the @format token prefix and including placeholders accepted by Python's str.format method Dynaconf will call it lazily upon access time. The call will be like: \"<YOURVALUE>\".format(env=os.environ, this=dynaconf.settings) So in your string you can refer to environment variables via env object, and also to variables defined int the settings object itself via this reference. It is lazily evaluated on access it will use the final value for a settings regardless the order of load. Example: export PROGRAM_NAME=calculator settings.toml [default] DB_NAME = \"mydb.db\" [development] DB_PATH = \"@format {env[HOME]}/{this.current_env}/{env[PROGRAM_NAME]}/{this.DB_NAME}\" {env[HOME]} is the same as os.environ[\"HOME\"] or $HOME in the shell. {this.current_env} is the same as settings.current_env {env[PROGRAM_NAME]} is the same as os.environ[\"PROGRAM_NAME\"] or $PROGRAM_NAME in the shell. {this.DB_NAME} is the same as settins.DB_NAME or settings[\"DB_NAME\"] so in your program from dynaconf import settings settings.DB_PATH == '~/DEVELOPMENT/calculator/mydb.db'","title":"@format token"},{"location":"guides/usage/#jinja-token","text":"If jinja2 package is installed then dynaconf will also allow the use jinja to render string values. Example: export PROGRAM_NAME=calculator settings.toml [default] DB_NAME = \"mydb.db\" [development] DB_NAME = \"@jinja {{env.HOME}}/{{this.current_env | lower}}/{{env[\"PROGRAM_NAME\"]}}/{{this.DB_NAME}}\" so in your program from dynaconf import settings settings.DB_PATH == '~/development/calculator/mydb.db' The main difference is that Jinja allows some Python expressions to be avaluated such as {% for, if, while %} and also supports calling methods and has lots of filters like | lower . Jinja supports its built-in filters listed in Builtin Filters Page and Dynaconf includes aditional filters for os.path module: abspath . realpath , relpath , basename and dirname and usage is like: VALUE = \"@jinja {{this.FOO | abspath}}\"","title":"@jinja token"},{"location":"guides/usage/#merging-existing-data-structures","text":"If your settings has existing variables of types list ot dict and you want to merge instead of override then the dynaconf_merge and dynaconf_merge_unique stanzas can mark that variable as a candidate for merging. For dict value: Your main settings file (e.g settings.toml ) has an existing DATABASE dict setting on [default] env. Now you want to contribute to the same DATABASE key by adding new keys, so you can use dynaconf_merge at the end of your dict: In specific [envs] [default] database = {host=\"server.com\", user=\"default\"} [development] database = {user=\"dev_user\", dynaconf_merge=true} [production] database = {user=\"prod_user\", dynaconf_merge=true} also allowed the alternative short format [default] database = {host=\"server.com\", user=\"default\"} [development.database] dynaconf_merge = {user=\"dev_user\"} [production.database] dynaconf_merge = {user=\"prod_user\"} In an environment variable: Using @merge mark # Toml formatted envvar export DYNACONF_DATABASE='@merge {password=1234}' or @merge mark short format # Toml formatted envvar export DYNACONF_DATABASE='@merge password=1234' It is also possible to use nested dunder traversal like: export DYNACONF_DATABASE__password=1234 export DYNACONF_DATABASE__user=admin export DYNACONF_DATABASE__ARGS__timeout=30 export DYNACONF_DATABASE__ARGS__retries=5 Each __ is parsed as a level traversing thought dict keys. read more in environment variables So the above will result in DATABASE = {'password': 1234, 'user': 'admin', 'ARGS': {'timeout': 30, 'retries': 5}} IMPORTANT lower case keys are respected only on *nix systems, unfortunately Windows environment variables are case insensitive and Python reads it as all upper cases, that means that if you are running on Windows the dictionary can have only upper case keys. You can also export a toml dictionary. # Toml formatted envvar export DYNACONF_DATABASE='{password=1234, dynaconf_merge=true}' Or in an additional file (e.g settings.yaml, .secrets.yaml, etc ) by using dynaconf_merge token: default: database: password: 1234 dynaconf_merge: true or default: database: dynaconf_merge: password: 1234 The dynaconf_merge token will mark that object to be merged with existing values (of course dynaconf_merge key will not be added to the final settings it is just a mark) The end result will be on [development] env: settings.DATABASE == {'host': 'server.com', 'user': 'dev_user', 'password': 1234} The same can be applied to lists : settings.toml [default] plugins = [\"core\"] [development] plugins = [\"debug_toolbar\", \"dynaconf_merge\"] or [default] plugins = [\"core\"] [development.plugins] dynaconf_merge = [\"debug_toolbar\"] And in environment variable using @merge token export DYNACONF_PLUGINS='@merge [\"ci_plugin\"]' or short version export DYNACONF_PLUGINS='@merge ci_plugin' comma separated values also supported: export DYNACONF_PLUGINS='@merge ci_plugin,other_plugin' or explicitly export DYNACONF_PLUGINS='[\"ci_plugin\", \"dynaconf_merge\"]' Then the end result on [development] is: settings.PLUGINS == [\"ci_plugin\", \"debug_toolbar\", \"core\"] If your value is a dictionary: export DYNACONF_DATA=\"@merge {foo='bar'}\" # or the short export DYNACONF_DATA=\"@merge foo=bar\"","title":"Merging existing data structures"},{"location":"guides/usage/#avoiding-duplications-on-lists","text":"The dynaconf_merge_unique is the token for when you want to avoid duplications in a list. Example: [default] scripts = ['install.sh', 'deploy.sh'] [development] scripts = ['dev.sh', 'test.sh', 'deploy.sh', 'dynaconf_merge_unique'] export DYNACONF_SCRIPTS='[\"deploy.sh\", \"run.sh\", \"dynaconf_merge_unique\"]' The end result for [development] will be: settings.SCRIPTS == ['install.sh', 'dev.sh', 'test.sh', 'deploy.sh', 'run.sh'] Note that deploy.sh is set 3 times but it is not repeated in the final settings.","title":"Avoiding duplications on lists"},{"location":"guides/usage/#known-caveats","text":"The dynaconf_merge and @merge functionalities works only for the first level keys, it will not merge subdicts or nested lists (yet). For deeper nested objects use dunder merge .","title":"Known caveats"},{"location":"guides/usage/#global-merge_1","text":"export MERGE_ENABLED_FOR_DYNACONF=true or put it in your .env file then Dynaconf will automatically merge all existing variables. BEWARE : Using MERGE_ENABLED_FOR_DYNACONF can lead to unexpected results because you do not have granular control of what is being merged or overwritten so the recommendation is to use other options.","title":"Global merge"},{"location":"guides/usage/#more-examples","text":"Take a look at the example folder to see some examples of use with different file formats and features.","title":"More examples"},{"location":"guides/validation/","text":"Validation Dynaconf allows the validation of settings parameters, in some cases you may want to validate the settings before starting the program. Lets say you have settings.toml [default] version = \"1.0.0\" age = 35 name = \"Bruno\" DEV_SERVERS = ['127.0.0.1', 'localhost', 'development.com'] PORT = 8001 [production] PROJECT = \"This is not hello_world\" Validating in Python programatically At any point of your program you can do: from dynaconf import settings, Validator # Register validators settings.validators.register( # Ensure some parameters exists (are required) Validator('VERSION', 'AGE', 'NAME', must_exist=True), # Ensure some password cannot exist Validator('PASSWORD', must_exist=False), # Ensure some parameter mets a condition # conditions: (eq, ne, lt, gt, lte, gte, identity, is_type_of, is_in, is_not_in) Validator('AGE', lte=30, gte=10), # validate a value is eq in specific env Validator('PROJECT', eq='hello_world', env='production'), # Ensure some parameter (string) meets a condition # conditions: (len_eq, len_ne, len_min, len_max, cont) # Determines the minimum and maximum length for the value Validator(\"NAME\", len_min=3, len_max=125), # Signifies the presence of the value in a set, text or word Validator(\"DEV_SERVERS\", cont='localhost'), # Checks whether the length is the same as defined. Validator(\"PORT\", len_eq=4), ) # Fire the validator settings.validators.validate() The above will raise dynaconf.validators.ValidationError(\"AGE must be lte=30 but it is 35 in env DEVELOPMENT\") and dynaconf.validators.ValidationError(\"PROJECT must be eq='hello_world' but it is 'This is not hello_world' in env PRODUCTION\") You can also use dot-delimited paths for registering validators on nested structures: from dynaconf import settings, Validator # Register validators settings.validators.register( # Ensure the database.host field exists. Validator('DATABASE.HOST', must_exist=True), # Make the database.password field optional. This is a default behavior. Validator('DATABASE.PASSWORD', must_exist=None), ) # Fire the validator settings.validators.validate() CLI and dynaconf_validators.toml NEW in 1.0.1 Starting on version 1.0.1 it is possible to define validators in TOML file called dynaconf_validators.toml placed in the same fodler as your settings files. dynaconf_validators.toml equivalent to program above [default] version = {must_exist=true} name = {must_exist=true} password = {must_exist=false} # dot notation is also supported 'a_big_dict.nested_1.nested_2.nested_3.nested_4' = {must_exist=true, eq=1} [default.age] must_exist = true lte = 30 gte = 10 [production] project = {eq=\"hello_world\"} Then to fire the validation use: $ dynaconf validate This returns code 0 (success) if validation is ok.","title":"Validation"},{"location":"guides/validation/#validation","text":"Dynaconf allows the validation of settings parameters, in some cases you may want to validate the settings before starting the program. Lets say you have settings.toml [default] version = \"1.0.0\" age = 35 name = \"Bruno\" DEV_SERVERS = ['127.0.0.1', 'localhost', 'development.com'] PORT = 8001 [production] PROJECT = \"This is not hello_world\"","title":"Validation"},{"location":"guides/validation/#validating-in-python-programatically","text":"At any point of your program you can do: from dynaconf import settings, Validator # Register validators settings.validators.register( # Ensure some parameters exists (are required) Validator('VERSION', 'AGE', 'NAME', must_exist=True), # Ensure some password cannot exist Validator('PASSWORD', must_exist=False), # Ensure some parameter mets a condition # conditions: (eq, ne, lt, gt, lte, gte, identity, is_type_of, is_in, is_not_in) Validator('AGE', lte=30, gte=10), # validate a value is eq in specific env Validator('PROJECT', eq='hello_world', env='production'), # Ensure some parameter (string) meets a condition # conditions: (len_eq, len_ne, len_min, len_max, cont) # Determines the minimum and maximum length for the value Validator(\"NAME\", len_min=3, len_max=125), # Signifies the presence of the value in a set, text or word Validator(\"DEV_SERVERS\", cont='localhost'), # Checks whether the length is the same as defined. Validator(\"PORT\", len_eq=4), ) # Fire the validator settings.validators.validate() The above will raise dynaconf.validators.ValidationError(\"AGE must be lte=30 but it is 35 in env DEVELOPMENT\") and dynaconf.validators.ValidationError(\"PROJECT must be eq='hello_world' but it is 'This is not hello_world' in env PRODUCTION\") You can also use dot-delimited paths for registering validators on nested structures: from dynaconf import settings, Validator # Register validators settings.validators.register( # Ensure the database.host field exists. Validator('DATABASE.HOST', must_exist=True), # Make the database.password field optional. This is a default behavior. Validator('DATABASE.PASSWORD', must_exist=None), ) # Fire the validator settings.validators.validate()","title":"Validating in Python programatically"},{"location":"guides/validation/#cli-and-dynaconf_validatorstoml","text":"NEW in 1.0.1 Starting on version 1.0.1 it is possible to define validators in TOML file called dynaconf_validators.toml placed in the same fodler as your settings files. dynaconf_validators.toml equivalent to program above [default] version = {must_exist=true} name = {must_exist=true} password = {must_exist=false} # dot notation is also supported 'a_big_dict.nested_1.nested_2.nested_3.nested_4' = {must_exist=true, eq=1} [default.age] must_exist = true lte = 30 gte = 10 [production] project = {eq=\"hello_world\"} Then to fire the validation use: $ dynaconf validate This returns code 0 (success) if validation is ok.","title":"CLI and dynaconf_validators.toml"},{"location":"modules/base/","text":"LazySettings When you do:: >>> from dynaconf import settings a LazySettings is imported and is initialized with only default_settings. Then when you first access a value, this will be set up and loaders will be executes looking for default config files or the file defined in SETTINGS_FILE_FOR_DYNACONF variable:: >>> settings.SETTINGS_FILE_FOR_DYNACONF Or when you call:: >>> settings.configure(settings_module='/tmp/settings.py') You can define in your settings module a list of loaders to get values from different stores. By default it will try environment variables starting with ENVVAR_PREFIX_FOR_DYNACONF (by defaulf `DYNACONF_`) You can also import this directly and customize it. in a file `proj/conf.py`:: >>> from dynaconf import LazySettings >>> config = LazySettings(ENV_FOR_DYNACONF='PROJ', ... LOADERS_FOR_DYNACONF=[ ... 'dynaconf.loaders.env_loader', ... 'dynaconf.loaders.redis_loader' ... ]) save common values in a settings file:: $ echo \"SERVER_IP = '10.10.10.10'\" > proj/settings.py or use `.toml|.yaml|.ini|.json` save sensitive values in .secrets.{py|toml|yaml|ini|json} or export as DYNACONF global environment variable:: $ export DYNACONF_SERVER_PASSWD='super_secret' >>> # from proj.conf import config >>> print config.SERVER_IP >>> print config.SERVER_PASSWD and now it reads all variables starting with `DYNACONF_` from envvars and all values in a hash called DYNACONF_PROJ in redis configured property readonly If wrapped is configured __call__ ( self , * args , ** kwargs ) special Allow direct call of settings('val') in place of settings.get('val') Source code in dynaconf\\base.py 114 115 116 117 118 def __call__ ( self , * args , ** kwargs ): \"\"\"Allow direct call of settings('val') in place of settings.get('val') \"\"\" return self . get ( * args , ** kwargs ) __getattr__ ( self , name ) special Allow getting keys from self.store using dot notation Source code in dynaconf\\base.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 @evaluate_lazy_format def __getattr__ ( self , name ): \"\"\"Allow getting keys from self.store using dot notation\"\"\" if self . _wrapped is empty : self . _setup () if name in self . _wrapped . _deleted : # noqa raise AttributeError ( f \"Attribute { name } was deleted, \" \"or belongs to different env\" ) if ( name . isupper () and ( self . _wrapped . _fresh or name in self . _wrapped . FRESH_VARS_FOR_DYNACONF ) and name not in dir ( default_settings ) ): return self . _wrapped . get_fresh ( name ) return getattr ( self . _wrapped , name ) __init__ ( self , ** kwargs ) special handle initialization for the customization cases :param kwargs: values that overrides default_settings Source code in dynaconf\\base.py 84 85 86 87 88 89 90 91 92 def __init__ ( self , ** kwargs ): \"\"\" handle initialization for the customization cases :param kwargs: values that overrides default_settings \"\"\" compat_kwargs ( kwargs ) self . _kwargs = kwargs super ( LazySettings , self ) . __init__ () configure ( self , settings_module = None , ** kwargs ) Allows user to reconfigure settings object passing a new settings module or separated kwargs :param settings_module: defines the setttings file :param kwargs: override default settings Source code in dynaconf\\base.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 def configure ( self , settings_module = None , ** kwargs ): \"\"\" Allows user to reconfigure settings object passing a new settings module or separated kwargs :param settings_module: defines the setttings file :param kwargs: override default settings \"\"\" default_settings . reload () environment_var = self . _kwargs . get ( \"ENVVAR_FOR_DYNACONF\" , default_settings . ENVVAR_FOR_DYNACONF ) settings_module = settings_module or os . environ . get ( environment_var ) compat_kwargs ( kwargs ) kwargs . update ( self . _kwargs ) self . _wrapped = Settings ( settings_module = settings_module , ** kwargs ) self . logger . debug ( \"Lazy Settings configured ...\" ) Settings Common logic for settings whether set by a module or by the user. current_env property readonly Return the current active env current_namespace property readonly Return the current active env loaded_by_loaders property readonly Gets the internal mapping of LOADER -> values loaded_envs property writable Get or create internal loaded envs list loaded_namespaces property readonly Get or create internal loaded envs list loaders property readonly Return available loaders logger property readonly Get or create inner logger settings_file property readonly Gets SETTINGS_MODULE variable settings_module property readonly Gets SETTINGS_MODULE variable store property readonly Gets internal storage validators property readonly Gets or creates validator wrapper __call__ ( self , * args , ** kwargs ) special Allow direct call of settings('val') in place of settings.get('val') Source code in dynaconf\\base.py 194 195 196 197 198 def __call__ ( self , * args , ** kwargs ): \"\"\"Allow direct call of `settings('val')` in place of `settings.get('val')` \"\"\" return self . get ( * args , ** kwargs ) __contains__ ( self , item ) special Respond to item in settings Source code in dynaconf\\base.py 215 216 217 def __contains__ ( self , item ): \"Respond to `item in settings`\" return item in self . store __delattr__ ( self , name ) special stores reference in _deleted for proper error management Source code in dynaconf\\base.py 209 210 211 212 213 def __delattr__ ( self , name ): \"\"\"stores reference in `_deleted` for proper error management\"\"\" self . _deleted . add ( name ) if hasattr ( self , name ): super ( Settings , self ) . __delattr__ ( name ) __getitem__ ( self , item ) special Allow getting variables as dict keys settings['KEY'] Source code in dynaconf\\base.py 219 220 221 222 223 224 def __getitem__ ( self , item ): \"\"\"Allow getting variables as dict keys `settings['KEY']`\"\"\" value = self . get ( item , default = empty ) if value is empty : raise KeyError ( f \" { item } does not exist\" ) return value __init__ ( self , settings_module = None , ** kwargs ) special Execute loaders and custom initialization :param settings_module: defines the setttings file :param kwargs: override default settings Source code in dynaconf\\base.py 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 def __init__ ( self , settings_module = None , ** kwargs ): # pragma: no cover \"\"\"Execute loaders and custom initialization :param settings_module: defines the setttings file :param kwargs: override default settings \"\"\" self . _logger = None self . _fresh = False self . _loaded_envs = [] self . _loaded_files = [] self . _deleted = set () self . _store = DynaBox () self . _env_cache = {} self . _loaded_by_loaders = {} self . _loaders = [] self . _defaults = {} self . environ = os . environ self . SETTINGS_MODULE = None self . _not_installed_warnings = [] self . _memoized = None compat_kwargs ( kwargs ) if settings_module : self . set ( \"SETTINGS_FILE_FOR_DYNACONF\" , settings_module ) for key , value in kwargs . items (): self . set ( key , value ) # execute loaders only after setting defaults got from kwargs self . _defaults = kwargs self . logger . debug ( f \"Initializing Dynaconf ( { self . _store } )\" ) self . execute_loaders () __setattr__ ( self , name , value ) special Allow settings.FOO = 'value' and deal with _deleted Source code in dynaconf\\base.py 200 201 202 203 204 205 206 207 def __setattr__ ( self , name , value ): \"\"\"Allow `settings.FOO = 'value'` and deal with `_deleted`\"\"\" try : self . _deleted . discard ( name ) except AttributeError : pass super ( Settings , self ) . __setattr__ ( name , value ) __setitem__ ( self , key , value ) special Allow settings['KEY'] = 'value' Source code in dynaconf\\base.py 226 227 228 def __setitem__ ( self , key , value ): \"\"\"Allow `settings['KEY'] = 'value'`\"\"\" self . set ( key , value ) as_bool ( self , key ) Partial method for get with bool cast Source code in dynaconf\\base.py 376 377 378 def as_bool ( self , key ): \"\"\"Partial method for get with bool cast\"\"\" return self . get ( key , cast = \"@bool\" ) as_dict ( self , env = None , internal = False ) Returns a dictionary with set key and values. :param env: Str env name, default self.current_env DEVELOPMENT :param internal: bool - should include dynaconf internal vars? Source code in dynaconf\\base.py 243 244 245 246 247 248 249 250 251 252 253 254 255 256 def as_dict ( self , env = None , internal = False ): \"\"\"Returns a dictionary with set key and values. :param env: Str env name, default self.current_env `DEVELOPMENT` :param internal: bool - should include dynaconf internal vars? \"\"\" ctx_mgr = suppress () if env is None else self . using_env ( env ) with ctx_mgr : data = self . store . to_dict () . copy () # if not internal remove internal settings if not internal : for name in dir ( default_settings ): data . pop ( name , None ) return data as_float ( self , key ) Partial method for get with float cast Source code in dynaconf\\base.py 384 385 386 def as_float ( self , key ): \"\"\"Partial method for get with float cast\"\"\" return self . get ( key , cast = \"@float\" ) as_int ( self , key ) Partial method for get with int cast Source code in dynaconf\\base.py 380 381 382 def as_int ( self , key ): \"\"\"Partial method for get with int cast\"\"\" return self . get ( key , cast = \"@int\" ) as_json ( self , key ) Partial method for get with json cast Source code in dynaconf\\base.py 388 389 390 def as_json ( self , key ): \"\"\"Partial method for get with json cast\"\"\" return self . get ( key , cast = \"@json\" ) clean ( self , * args , ** kwargs ) Clean all loaded values to reload when switching envs Source code in dynaconf\\base.py 614 615 616 617 def clean ( self , * args , ** kwargs ): \"\"\"Clean all loaded values to reload when switching envs\"\"\" for key in list ( self . store . keys ()): self . unset ( key ) execute_loaders ( self , env = None , silent = None , key = None , filename = None ) Execute all internal and registered loaders :param env: The environment to load :param silent: If loading erros is silenced :param key: if provided load a single key :param filename: optional custom filename to load Source code in dynaconf\\base.py 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 def execute_loaders ( self , env = None , silent = None , key = None , filename = None ): \"\"\"Execute all internal and registered loaders :param env: The environment to load :param silent: If loading erros is silenced :param key: if provided load a single key :param filename: optional custom filename to load \"\"\" if key is None : default_loader ( self , self . _defaults ) env = ( env or self . current_env ) . upper () silent = silent or self . SILENT_ERRORS_FOR_DYNACONF self . pre_load ( env , silent = silent , key = key ) settings_loader ( self , env = env , silent = silent , key = key , filename = filename ) self . load_extra_yaml ( env , silent , key ) # DEPRECATED enable_external_loaders ( self ) for loader in self . loaders : self . logger . debug ( f \"Dynaconf executing: { loader . __name__ } \" ) loader . load ( self , env , silent = silent , key = key ) self . load_includes ( env , silent = silent , key = key ) self . logger . debug ( f \"Loaded Files: { deduplicate ( self . _loaded_files ) } \" ) exists ( self , key , fresh = False ) Check if key exists :param key: the name of setting variable :param fresh: if key should be taken from source direclty :return: Boolean Source code in dynaconf\\base.py 331 332 333 334 335 336 337 338 339 340 341 def exists ( self , key , fresh = False ): \"\"\"Check if key exists :param key: the name of setting variable :param fresh: if key should be taken from source direclty :return: Boolean \"\"\" key = upperfy ( key ) if key in self . _deleted : return False return self . get ( key , fresh = fresh , default = missing ) is not missing exists_in_environ ( self , key ) Return True if env variable is exported Source code in dynaconf\\base.py 372 373 374 def exists_in_environ ( self , key ): \"\"\"Return True if env variable is exported\"\"\" return upperfy ( key ) in self . environ flag ( self , key , env = None ) Feature flagging system write flags to redis $ dynaconf write redis -s DASHBOARD=1 -e premiumuser meaning: Any premium user has DASHBOARD feature enabled In your program do:: # premium user has access to dashboard? >>> if settings.flag('dashboard', 'premiumuser'): ... activate_dashboard() The value is ensured to be loaded fresh from redis server It also works with file settings but the recommended is redis as the data can be loaded once it is updated. :param key: The flag name :param env: The env to look for Source code in dynaconf\\base.py 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 def flag ( self , key , env = None ): \"\"\"Feature flagging system write flags to redis $ dynaconf write redis -s DASHBOARD=1 -e premiumuser meaning: Any premium user has DASHBOARD feature enabled In your program do:: # premium user has access to dashboard? >>> if settings.flag('dashboard', 'premiumuser'): ... activate_dashboard() The value is ensured to be loaded fresh from redis server It also works with file settings but the recommended is redis as the data can be loaded once it is updated. :param key: The flag name :param env: The env to look for \"\"\" env = env or self . ENVVAR_PREFIX_FOR_DYNACONF or \"DYNACONF\" with self . using_env ( env ): value = self . get_fresh ( key ) return value is True or value in true_values fresh ( self ) this context manager force the load of a key direct from the store:: $ export DYNACONF_VALUE='Original' >>> from dynaconf import settings >>> print settings.VALUE 'Original' $ export DYNACONF_VALUE='Changed Value' >>> print settings.VALUE # will not be reloaded from env vars 'Original >>> with settings.fresh(): # inside this context all is reloaded ... print settings.VALUE 'Changed Value' an alternative is using settings.get_fresh(key) :return: context Source code in dynaconf\\base.py 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 @contextmanager def fresh ( self ): \"\"\" this context manager force the load of a key direct from the store:: $ export DYNACONF_VALUE='Original' >>> from dynaconf import settings >>> print settings.VALUE 'Original' $ export DYNACONF_VALUE='Changed Value' >>> print settings.VALUE # will not be reloaded from env vars 'Original >>> with settings.fresh(): # inside this context all is reloaded ... print settings.VALUE 'Changed Value' an alternative is using `settings.get_fresh(key)` :return: context \"\"\" self . _fresh = True yield self . _fresh = False from_env ( self , env , keep = False , ** kwargs ) Return a new isolated settings object pointing to specified env. Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print(settings.MESSAGE) 'This is in dev' >>> print(settings.from_env('other').MESSAGE) 'This is in other env' # The existing settings object remains the same. >>> print(settings.MESSAGE) 'This is in dev' Arguments:: env {str} -- Env to load (development, production, custom) Keyword Arguments:: keep {bool} -- Keep pre-existing values (default: {False}) kwargs {dict} -- Passed directly to new instance. Source code in dynaconf\\base.py 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 def from_env ( self , env , keep = False , ** kwargs ): \"\"\"Return a new isolated settings object pointing to specified env. Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print(settings.MESSAGE) 'This is in dev' >>> print(settings.from_env('other').MESSAGE) 'This is in other env' # The existing settings object remains the same. >>> print(settings.MESSAGE) 'This is in dev' Arguments:: env {str} -- Env to load (development, production, custom) Keyword Arguments:: keep {bool} -- Keep pre-existing values (default: {False}) kwargs {dict} -- Passed directly to new instance. \"\"\" cache_key = f \" { env } _ { keep } _ { kwargs } \" if cache_key in self . _env_cache : self . logger . debug ( f \"Settings instance in env: { env } from cache\" ) return self . _env_cache [ cache_key ] new_data = { key : self . get ( key ) for key in dir ( default_settings ) if key . isupper () and key not in RENAMED_VARS } if keep : # keep existing values from current env new_data . update ( { key : value for key , value in self . store . to_dict () . copy () . items () if key . isupper () and key not in RENAMED_VARS } ) new_data . update ( kwargs ) new_data [ \"FORCE_ENV_FOR_DYNACONF\" ] = env new_settings = LazySettings ( ** new_data ) self . logger . debug ( f \"New settings instance in env: { env } \" ) self . _env_cache [ cache_key ] = new_settings return new_settings get ( self , key , default = None , cast = None , fresh = False , dotted_lookup = True , parent = None ) Get a value from settings store, this is the prefered way to access:: >>> from dynaconf import settings >>> settings.get('KEY') :param key: The name of the setting value, will always be upper case :param default: In case of not found it will be returned :param cast: Should cast in to @int, @float, @bool or @json ? :param fresh: Should reload from loaders store before access? :param dotted_lookup: Should perform dotted-path lookup? :param parent: Is there a pre-loaded parent in a nested data? :return: The value if found, default or None Source code in dynaconf\\base.py 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 @evaluate_lazy_format def get ( self , key , default = None , cast = None , fresh = False , dotted_lookup = True , parent = None , ): \"\"\" Get a value from settings store, this is the prefered way to access:: >>> from dynaconf import settings >>> settings.get('KEY') :param key: The name of the setting value, will always be upper case :param default: In case of not found it will be returned :param cast: Should cast in to @int, @float, @bool or @json ? :param fresh: Should reload from loaders store before access? :param dotted_lookup: Should perform dotted-path lookup? :param parent: Is there a pre-loaded parent in a nested data? :return: The value if found, default or None \"\"\" if \".\" in key and dotted_lookup : return self . _dotted_get ( dotted_key = key , default = default , cast = cast , fresh = fresh , parent = parent , ) key = upperfy ( key ) if key in self . _deleted : return default if ( fresh or self . _fresh or key in getattr ( self , \"FRESH_VARS_FOR_DYNACONF\" , ()) ) and key not in dir ( default_settings ): self . unset ( key ) self . execute_loaders ( key = key ) data = ( parent or self . store ) . get ( key , default ) if cast : data = converters . get ( cast )( data ) return data get_environ ( self , key , default = None , cast = None ) Get value from environment variable using os.environ.get :param key: The name of the setting value, will always be upper case :param default: In case of not found it will be returned :param cast: Should cast in to @int, @float, @bool or @json ? or cast must be true to use cast inference :return: The value if found, default or None Source code in dynaconf\\base.py 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 def get_environ ( self , key , default = None , cast = None ): \"\"\"Get value from environment variable using os.environ.get :param key: The name of the setting value, will always be upper case :param default: In case of not found it will be returned :param cast: Should cast in to @int, @float, @bool or @json ? or cast must be true to use cast inference :return: The value if found, default or None \"\"\" key = upperfy ( key ) data = self . environ . get ( key , default ) if data : if cast in converters : data = converters . get ( cast )( data ) if cast is True : data = parse_conf_data ( data , tomlfy = True ) return data get_fresh ( self , key , default = None , cast = None ) This is a shortcut to get(key, fresh=True) . always reload from loaders store before getting the var. :param key: The name of the setting value, will always be upper case :param default: In case of not found it will be returned :param cast: Should cast in to @int, @float, @bool or @json ? :return: The value if found, default or None Source code in dynaconf\\base.py 343 344 345 346 347 348 349 350 351 352 def get_fresh ( self , key , default = None , cast = None ): \"\"\"This is a shortcut to `get(key, fresh=True)`. always reload from loaders store before getting the var. :param key: The name of the setting value, will always be upper case :param default: In case of not found it will be returned :param cast: Should cast in to @int, @float, @bool or @json ? :return: The value if found, default or None \"\"\" return self . get ( key , default = default , cast = cast , fresh = True ) keys ( self ) Redirects to store object Source code in dynaconf\\base.py 235 236 237 def keys ( self ): \"\"\"Redirects to store object\"\"\" return self . store . keys () load_extra_yaml ( self , env , silent , key ) This is deprecated, kept for compat .. deprecated:: 1.0.0 Use multiple settings or INCLUDES_FOR_DYNACONF files instead. Source code in dynaconf\\base.py 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 def load_extra_yaml ( self , env , silent , key ): \"\"\"This is deprecated, kept for compat .. deprecated:: 1.0.0 Use multiple settings or INCLUDES_FOR_DYNACONF files instead. \"\"\" if self . get ( \"YAML\" ) is not None : self . logger . warning ( \"The use of YAML var is deprecated, please define multiple \" \"filepaths instead: \" \"e.g: SETTINGS_FILE_FOR_DYNACONF = \" \"'settings.py,settings.yaml,settings.toml' or \" \"INCLUDES_FOR_DYNACONF=['path.toml', 'folder/*']\" ) yaml_loader . load ( self , env = env , filename = self . find_file ( self . get ( \"YAML\" )), silent = silent , key = key , ) load_file ( self , path = None , env = None , silent = True , key = None ) Programmatically load files from path . :param path: A single filename or a file list :param env: Which env to load from file (default current_env) :param silent: Should raise errors? :param key: Load a single key? Source code in dynaconf\\base.py 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 def load_file ( self , path = None , env = None , silent = True , key = None ): \"\"\"Programmatically load files from ``path``. :param path: A single filename or a file list :param env: Which env to load from file (default current_env) :param silent: Should raise errors? :param key: Load a single key? \"\"\" env = ( env or self . current_env ) . upper () files = ensure_a_list ( path ) if files : self . logger . debug ( f \"Got { files } files to process\" ) already_loaded = set () for _filename in files : self . logger . debug ( f \"Processing file { _filename } \" ) if py_loader . try_to_load_from_py_module_name ( obj = self , name = _filename , silent = True ): # if it was possible to load from module name # continue the loop. continue filepath = os . path . join ( self . _root_path or os . getcwd (), _filename ) self . logger . debug ( f \"File path is { filepath } \" ) paths = [ p for p in sorted ( glob . glob ( filepath )) if \".local.\" not in p ] local_paths = [ p for p in sorted ( glob . glob ( filepath )) if \".local.\" in p ] # Handle possible *.globs sorted alphanumeric for path in paths + local_paths : self . logger . debug ( f \"Loading { path } \" ) if path in already_loaded : # pragma: no cover self . logger . debug ( f \"Skipping { path } , already loaded\" ) continue settings_loader ( obj = self , env = env , silent = silent , key = key , filename = path , ) already_loaded . add ( path ) if not already_loaded : self . logger . warning ( f \"Not able to locate the files { files } \" \"to load\" ) load_includes ( self , env , silent , key ) Do we have any nested includes we need to process? Source code in dynaconf\\base.py 905 906 907 908 909 910 911 912 913 914 915 def load_includes ( self , env , silent , key ): \"\"\"Do we have any nested includes we need to process?\"\"\" includes = self . get ( \"DYNACONF_INCLUDE\" , []) includes . extend ( ensure_a_list ( self . get ( \"INCLUDES_FOR_DYNACONF\" ))) if includes : self . logger . debug ( f \"Processing includes { includes } \" ) self . load_file ( path = includes , env = env , silent = silent , key = key ) # ensure env vars are the last thing loaded after all includes last_loader = self . loaders and self . loaders [ - 1 ] if last_loader and last_loader == env_loader : last_loader . load ( self , env , silent , key ) namespace ( self , env = None , clean = True , silent = True , filename = None ) Used to interactively change the env Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print settings.MESSAGE 'This is in dev' >>> with settings.using_env('OTHER'): ... print settings.MESSAGE 'this is in other env' :param env: Upper case name of env without any _ :param clean: If preloaded vars should be cleaned :param silent: Silence errors :param filename: Custom filename to load (optional) :return: context Source code in dynaconf\\base.py 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 def setenv ( self , env = None , clean = True , silent = True , filename = None ): \"\"\"Used to interactively change the env Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print settings.MESSAGE 'This is in dev' >>> with settings.using_env('OTHER'): ... print settings.MESSAGE 'this is in other env' :param env: Upper case name of env without any _ :param clean: If preloaded vars should be cleaned :param silent: Silence errors :param filename: Custom filename to load (optional) :return: context \"\"\" env = env or self . ENV_FOR_DYNACONF if not isinstance ( env , str ): raise AttributeError ( \"env should be a string\" ) self . logger . debug ( f \"env switching to: { env } \" ) env = env . upper () if env != self . ENV_FOR_DYNACONF : self . loaded_envs . append ( env ) else : self . loaded_envs = [] if clean : self . clean ( env = env ) self . execute_loaders ( env = env , silent = silent , filename = filename ) path_for ( self , * args ) Path containing _root_path Source code in dynaconf\\base.py 1003 1004 1005 1006 1007 def path_for ( self , * args ): \"\"\"Path containing _root_path\"\"\" if args and args [ 0 ] . startswith ( os . path . sep ): return os . path . join ( * args ) return os . path . join ( self . _root_path or os . getcwd (), * args ) populate_obj ( self , obj , keys = None , ignore = None ) Given the obj populate it using self.store items. :param obj: An object to be populated, a class instance. :param keys: A list of keys to be included. :param ignore: A list of keys to be excluded. Source code in dynaconf\\base.py 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 def populate_obj ( self , obj , keys = None , ignore = None ): \"\"\"Given the `obj` populate it using self.store items. :param obj: An object to be populated, a class instance. :param keys: A list of keys to be included. :param ignore: A list of keys to be excluded. \"\"\" keys = keys or self . keys () for key in keys : key = upperfy ( key ) if ignore and key in ignore : continue value = self . get ( key , empty ) if value is not empty : setattr ( obj , key , value ) pre_load ( self , env , silent , key ) Do we have any file to pre-load before main settings file? Source code in dynaconf\\base.py 898 899 900 901 902 903 def pre_load ( self , env , silent , key ): \"\"\"Do we have any file to pre-load before main settings file?\"\"\" preloads = self . get ( \"PRELOAD_FOR_DYNACONF\" , []) if preloads : self . logger . debug ( f \"Processing preloads { preloads } \" ) self . load_file ( path = preloads , env = env , silent = silent , key = key ) reload ( self , env = None , silent = None ) Clean end Execute all loaders Source code in dynaconf\\base.py 869 870 871 872 def reload ( self , env = None , silent = None ): # pragma: no cover \"\"\"Clean end Execute all loaders\"\"\" self . clean () self . execute_loaders ( env , silent ) set ( self , key , value , loader_identifier = None , tomlfy = False , dotted_lookup = True , is_secret = False , merge = False ) Set a value storing references for the loader :param key: The key to store :param value: The value to store :param loader_identifier: Optional loader name e.g: toml, yaml etc. :param tomlfy: Bool define if value is parsed by toml (defaults False) :param is_secret: Bool define if secret values is hidden on logs. :param merge: Bool define if existing nested data will be merged. Source code in dynaconf\\base.py 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 def set ( self , key , value , loader_identifier = None , tomlfy = False , dotted_lookup = True , is_secret = False , merge = False , ): \"\"\"Set a value storing references for the loader :param key: The key to store :param value: The value to store :param loader_identifier: Optional loader name e.g: toml, yaml etc. :param tomlfy: Bool define if value is parsed by toml (defaults False) :param is_secret: Bool define if secret values is hidden on logs. :param merge: Bool define if existing nested data will be merged. \"\"\" nested_sep = self . get ( \"NESTED_SEPARATOR_FOR_DYNACONF\" ) if nested_sep and nested_sep in key : # turn FOO__bar__ZAZ in `FOO.bar.ZAZ` key = key . replace ( nested_sep , \".\" ) if \".\" in key and dotted_lookup is True : return self . _dotted_set ( key , value , loader_identifier = loader_identifier , tomlfy = tomlfy ) value = parse_conf_data ( value , tomlfy = tomlfy ) key = upperfy ( key . strip ()) existing = getattr ( self , key , None ) if getattr ( value , \"_dynaconf_del\" , None ): # just in case someone use a `@del` in a first level var. self . unset ( key , force = True ) return if getattr ( value , \"_dynaconf_reset\" , False ): # pragma: no cover # just in case someone use a `@reset` in a first level var. # NOTE: @reset/Reset is deprecated in v3.0.0 value = value . unwrap () if getattr ( value , \"_dynaconf_merge\" , False ): # just in case someone use a `@merge` in a first level var if existing : object_merge ( existing , value . unwrap ()) value = value . unwrap () if existing is not None and existing != value : # `dynaconf_merge` used in file root `merge=True` if merge : object_merge ( existing , value ) else : # `dynaconf_merge` may be used within the key structure value = self . _merge_before_set ( key , existing , value , is_secret ) if isinstance ( value , dict ): value = DynaBox ( value ) setattr ( self , key , value ) self . store [ key ] = value self . _deleted . discard ( key ) # set loader identifiers so cleaners know which keys to clean if loader_identifier and loader_identifier in self . loaded_by_loaders : self . loaded_by_loaders [ loader_identifier ][ key ] = value elif loader_identifier : self . loaded_by_loaders [ loader_identifier ] = { key : value } elif loader_identifier is None : # if .set is called without loader identifier it becomes # a default value and goes away only when explicitly unset self . _defaults [ key ] = value setenv ( self , env = None , clean = True , silent = True , filename = None ) Used to interactively change the env Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print settings.MESSAGE 'This is in dev' >>> with settings.using_env('OTHER'): ... print settings.MESSAGE 'this is in other env' :param env: Upper case name of env without any _ :param clean: If preloaded vars should be cleaned :param silent: Silence errors :param filename: Custom filename to load (optional) :return: context Source code in dynaconf\\base.py 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 def setenv ( self , env = None , clean = True , silent = True , filename = None ): \"\"\"Used to interactively change the env Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print settings.MESSAGE 'This is in dev' >>> with settings.using_env('OTHER'): ... print settings.MESSAGE 'this is in other env' :param env: Upper case name of env without any _ :param clean: If preloaded vars should be cleaned :param silent: Silence errors :param filename: Custom filename to load (optional) :return: context \"\"\" env = env or self . ENV_FOR_DYNACONF if not isinstance ( env , str ): raise AttributeError ( \"env should be a string\" ) self . logger . debug ( f \"env switching to: { env } \" ) env = env . upper () if env != self . ENV_FOR_DYNACONF : self . loaded_envs . append ( env ) else : self . loaded_envs = [] if clean : self . clean ( env = env ) self . execute_loaders ( env = env , silent = silent , filename = filename ) to_dict ( self , env = None , internal = False ) Returns a dictionary with set key and values. :param env: Str env name, default self.current_env DEVELOPMENT :param internal: bool - should include dynaconf internal vars? Source code in dynaconf\\base.py 243 244 245 246 247 248 249 250 251 252 253 254 255 256 def as_dict ( self , env = None , internal = False ): \"\"\"Returns a dictionary with set key and values. :param env: Str env name, default self.current_env `DEVELOPMENT` :param internal: bool - should include dynaconf internal vars? \"\"\" ctx_mgr = suppress () if env is None else self . using_env ( env ) with ctx_mgr : data = self . store . to_dict () . copy () # if not internal remove internal settings if not internal : for name in dir ( default_settings ): data . pop ( name , None ) return data unset ( self , key , force = False ) Unset on all references :param key: The key to be unset :param force: Bypass default checks and force unset Source code in dynaconf\\base.py 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 def unset ( self , key , force = False ): \"\"\"Unset on all references :param key: The key to be unset :param force: Bypass default checks and force unset \"\"\" key = upperfy ( key . strip ()) if ( key not in dir ( default_settings ) and key not in self . _defaults or force ): self . logger . debug ( f \"Unset { key } \" ) delattr ( self , key ) self . store . pop ( key , None ) unset_all ( self , keys , force = False ) Unset based on a list of keys :param keys: a list of keys :param force: Bypass default checks and force unset Source code in dynaconf\\base.py 635 636 637 638 639 640 641 642 def unset_all ( self , keys , force = False ): # pragma: no cover \"\"\"Unset based on a list of keys :param keys: a list of keys :param force: Bypass default checks and force unset \"\"\" for key in keys : self . unset ( key , force = force ) update ( self , data = None , loader_identifier = None , tomlfy = False , is_secret = False , merge = False , ** kwargs ) Update values in the current settings object without saving in stores:: >>> from dynaconf import settings >>> print settings.NAME 'Bruno' >>> settings.update({'NAME': 'John'}, other_value=1) >>> print settings.NAME 'John' >>> print settings.OTHER_VALUE 1 :param data: Data to be updated :param loader_identifier: Only to be used by custom loaders :param tomlfy: Bool define if value is parsed by toml (defaults False) :param merge: Bool define if existing nested data will be merged. :param kwargs: extra values to update :return: None Source code in dynaconf\\base.py 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 def update ( self , data = None , loader_identifier = None , tomlfy = False , is_secret = False , merge = False , ** kwargs , ): \"\"\" Update values in the current settings object without saving in stores:: >>> from dynaconf import settings >>> print settings.NAME 'Bruno' >>> settings.update({'NAME': 'John'}, other_value=1) >>> print settings.NAME 'John' >>> print settings.OTHER_VALUE 1 :param data: Data to be updated :param loader_identifier: Only to be used by custom loaders :param tomlfy: Bool define if value is parsed by toml (defaults False) :param merge: Bool define if existing nested data will be merged. :param kwargs: extra values to update :return: None \"\"\" data = data or {} data . update ( kwargs ) for key , value in data . items (): self . set ( key , value , loader_identifier = loader_identifier , tomlfy = tomlfy , is_secret = is_secret , merge = merge , ) using_env ( self , env , clean = True , silent = True , filename = None ) This context manager allows the contextual use of a different env Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print settings.MESSAGE 'This is in dev' >>> with settings.using_env('OTHER'): ... print settings.MESSAGE 'this is in other env' :param env: Upper case name of env without any _ :param clean: If preloaded vars should be cleaned :param silent: Silence errors :param filename: Custom filename to load (optional) :return: context Source code in dynaconf\\base.py 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 @contextmanager def using_env ( self , env , clean = True , silent = True , filename = None ): \"\"\" This context manager allows the contextual use of a different env Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print settings.MESSAGE 'This is in dev' >>> with settings.using_env('OTHER'): ... print settings.MESSAGE 'this is in other env' :param env: Upper case name of env without any _ :param clean: If preloaded vars should be cleaned :param silent: Silence errors :param filename: Custom filename to load (optional) :return: context \"\"\" try : self . setenv ( env , clean = clean , silent = silent , filename = filename ) self . logger . debug ( f \"In env: { env } \" ) yield finally : if env . lower () != self . ENV_FOR_DYNACONF . lower (): del self . loaded_envs [ - 1 ] self . logger . debug ( f \"Out env: { env } \" ) self . setenv ( self . current_env , clean = clean , filename = filename ) using_namespace ( self , env , clean = True , silent = True , filename = None ) This context manager allows the contextual use of a different env Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print settings.MESSAGE 'This is in dev' >>> with settings.using_env('OTHER'): ... print settings.MESSAGE 'this is in other env' :param env: Upper case name of env without any _ :param clean: If preloaded vars should be cleaned :param silent: Silence errors :param filename: Custom filename to load (optional) :return: context Source code in dynaconf\\base.py 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 @contextmanager def using_env ( self , env , clean = True , silent = True , filename = None ): \"\"\" This context manager allows the contextual use of a different env Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print settings.MESSAGE 'This is in dev' >>> with settings.using_env('OTHER'): ... print settings.MESSAGE 'this is in other env' :param env: Upper case name of env without any _ :param clean: If preloaded vars should be cleaned :param silent: Silence errors :param filename: Custom filename to load (optional) :return: context \"\"\" try : self . setenv ( env , clean = clean , silent = silent , filename = filename ) self . logger . debug ( f \"In env: { env } \" ) yield finally : if env . lower () != self . ENV_FOR_DYNACONF . lower (): del self . loaded_envs [ - 1 ] self . logger . debug ( f \"Out env: { env } \" ) self . setenv ( self . current_env , clean = clean , filename = filename ) values ( self ) Redirects to store object Source code in dynaconf\\base.py 239 240 241 def values ( self ): \"\"\"Redirects to store object\"\"\" return self . store . values ()","title":"Base"},{"location":"modules/base/#dynaconf.base","text":"","title":"dynaconf.base"},{"location":"modules/base/#dynaconf.base.LazySettings","text":"When you do:: >>> from dynaconf import settings a LazySettings is imported and is initialized with only default_settings. Then when you first access a value, this will be set up and loaders will be executes looking for default config files or the file defined in SETTINGS_FILE_FOR_DYNACONF variable:: >>> settings.SETTINGS_FILE_FOR_DYNACONF Or when you call:: >>> settings.configure(settings_module='/tmp/settings.py') You can define in your settings module a list of loaders to get values from different stores. By default it will try environment variables starting with ENVVAR_PREFIX_FOR_DYNACONF (by defaulf `DYNACONF_`) You can also import this directly and customize it. in a file `proj/conf.py`:: >>> from dynaconf import LazySettings >>> config = LazySettings(ENV_FOR_DYNACONF='PROJ', ... LOADERS_FOR_DYNACONF=[ ... 'dynaconf.loaders.env_loader', ... 'dynaconf.loaders.redis_loader' ... ]) save common values in a settings file:: $ echo \"SERVER_IP = '10.10.10.10'\" > proj/settings.py or use `.toml|.yaml|.ini|.json` save sensitive values in .secrets.{py|toml|yaml|ini|json} or export as DYNACONF global environment variable:: $ export DYNACONF_SERVER_PASSWD='super_secret' >>> # from proj.conf import config >>> print config.SERVER_IP >>> print config.SERVER_PASSWD and now it reads all variables starting with `DYNACONF_` from envvars and all values in a hash called DYNACONF_PROJ in redis","title":"LazySettings"},{"location":"modules/base/#dynaconf.base.LazySettings.configured","text":"If wrapped is configured","title":"configured"},{"location":"modules/base/#dynaconf.base.LazySettings.__call__","text":"Allow direct call of settings('val') in place of settings.get('val') Source code in dynaconf\\base.py 114 115 116 117 118 def __call__ ( self , * args , ** kwargs ): \"\"\"Allow direct call of settings('val') in place of settings.get('val') \"\"\" return self . get ( * args , ** kwargs )","title":"__call__()"},{"location":"modules/base/#dynaconf.base.LazySettings.__getattr__","text":"Allow getting keys from self.store using dot notation Source code in dynaconf\\base.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 @evaluate_lazy_format def __getattr__ ( self , name ): \"\"\"Allow getting keys from self.store using dot notation\"\"\" if self . _wrapped is empty : self . _setup () if name in self . _wrapped . _deleted : # noqa raise AttributeError ( f \"Attribute { name } was deleted, \" \"or belongs to different env\" ) if ( name . isupper () and ( self . _wrapped . _fresh or name in self . _wrapped . FRESH_VARS_FOR_DYNACONF ) and name not in dir ( default_settings ) ): return self . _wrapped . get_fresh ( name ) return getattr ( self . _wrapped , name )","title":"__getattr__()"},{"location":"modules/base/#dynaconf.base.LazySettings.__init__","text":"handle initialization for the customization cases :param kwargs: values that overrides default_settings Source code in dynaconf\\base.py 84 85 86 87 88 89 90 91 92 def __init__ ( self , ** kwargs ): \"\"\" handle initialization for the customization cases :param kwargs: values that overrides default_settings \"\"\" compat_kwargs ( kwargs ) self . _kwargs = kwargs super ( LazySettings , self ) . __init__ ()","title":"__init__()"},{"location":"modules/base/#dynaconf.base.LazySettings.configure","text":"Allows user to reconfigure settings object passing a new settings module or separated kwargs :param settings_module: defines the setttings file :param kwargs: override default settings Source code in dynaconf\\base.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 def configure ( self , settings_module = None , ** kwargs ): \"\"\" Allows user to reconfigure settings object passing a new settings module or separated kwargs :param settings_module: defines the setttings file :param kwargs: override default settings \"\"\" default_settings . reload () environment_var = self . _kwargs . get ( \"ENVVAR_FOR_DYNACONF\" , default_settings . ENVVAR_FOR_DYNACONF ) settings_module = settings_module or os . environ . get ( environment_var ) compat_kwargs ( kwargs ) kwargs . update ( self . _kwargs ) self . _wrapped = Settings ( settings_module = settings_module , ** kwargs ) self . logger . debug ( \"Lazy Settings configured ...\" )","title":"configure()"},{"location":"modules/base/#dynaconf.base.Settings","text":"Common logic for settings whether set by a module or by the user.","title":"Settings"},{"location":"modules/base/#dynaconf.base.Settings.current_env","text":"Return the current active env","title":"current_env"},{"location":"modules/base/#dynaconf.base.Settings.current_namespace","text":"Return the current active env","title":"current_namespace"},{"location":"modules/base/#dynaconf.base.Settings.loaded_by_loaders","text":"Gets the internal mapping of LOADER -> values","title":"loaded_by_loaders"},{"location":"modules/base/#dynaconf.base.Settings.loaded_envs","text":"Get or create internal loaded envs list","title":"loaded_envs"},{"location":"modules/base/#dynaconf.base.Settings.loaded_namespaces","text":"Get or create internal loaded envs list","title":"loaded_namespaces"},{"location":"modules/base/#dynaconf.base.Settings.loaders","text":"Return available loaders","title":"loaders"},{"location":"modules/base/#dynaconf.base.Settings.logger","text":"Get or create inner logger","title":"logger"},{"location":"modules/base/#dynaconf.base.Settings.settings_file","text":"Gets SETTINGS_MODULE variable","title":"settings_file"},{"location":"modules/base/#dynaconf.base.Settings.settings_module","text":"Gets SETTINGS_MODULE variable","title":"settings_module"},{"location":"modules/base/#dynaconf.base.Settings.store","text":"Gets internal storage","title":"store"},{"location":"modules/base/#dynaconf.base.Settings.validators","text":"Gets or creates validator wrapper","title":"validators"},{"location":"modules/base/#dynaconf.base.Settings.__call__","text":"Allow direct call of settings('val') in place of settings.get('val') Source code in dynaconf\\base.py 194 195 196 197 198 def __call__ ( self , * args , ** kwargs ): \"\"\"Allow direct call of `settings('val')` in place of `settings.get('val')` \"\"\" return self . get ( * args , ** kwargs )","title":"__call__()"},{"location":"modules/base/#dynaconf.base.Settings.__contains__","text":"Respond to item in settings Source code in dynaconf\\base.py 215 216 217 def __contains__ ( self , item ): \"Respond to `item in settings`\" return item in self . store","title":"__contains__()"},{"location":"modules/base/#dynaconf.base.Settings.__delattr__","text":"stores reference in _deleted for proper error management Source code in dynaconf\\base.py 209 210 211 212 213 def __delattr__ ( self , name ): \"\"\"stores reference in `_deleted` for proper error management\"\"\" self . _deleted . add ( name ) if hasattr ( self , name ): super ( Settings , self ) . __delattr__ ( name )","title":"__delattr__()"},{"location":"modules/base/#dynaconf.base.Settings.__getitem__","text":"Allow getting variables as dict keys settings['KEY'] Source code in dynaconf\\base.py 219 220 221 222 223 224 def __getitem__ ( self , item ): \"\"\"Allow getting variables as dict keys `settings['KEY']`\"\"\" value = self . get ( item , default = empty ) if value is empty : raise KeyError ( f \" { item } does not exist\" ) return value","title":"__getitem__()"},{"location":"modules/base/#dynaconf.base.Settings.__init__","text":"Execute loaders and custom initialization :param settings_module: defines the setttings file :param kwargs: override default settings Source code in dynaconf\\base.py 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 def __init__ ( self , settings_module = None , ** kwargs ): # pragma: no cover \"\"\"Execute loaders and custom initialization :param settings_module: defines the setttings file :param kwargs: override default settings \"\"\" self . _logger = None self . _fresh = False self . _loaded_envs = [] self . _loaded_files = [] self . _deleted = set () self . _store = DynaBox () self . _env_cache = {} self . _loaded_by_loaders = {} self . _loaders = [] self . _defaults = {} self . environ = os . environ self . SETTINGS_MODULE = None self . _not_installed_warnings = [] self . _memoized = None compat_kwargs ( kwargs ) if settings_module : self . set ( \"SETTINGS_FILE_FOR_DYNACONF\" , settings_module ) for key , value in kwargs . items (): self . set ( key , value ) # execute loaders only after setting defaults got from kwargs self . _defaults = kwargs self . logger . debug ( f \"Initializing Dynaconf ( { self . _store } )\" ) self . execute_loaders ()","title":"__init__()"},{"location":"modules/base/#dynaconf.base.Settings.__setattr__","text":"Allow settings.FOO = 'value' and deal with _deleted Source code in dynaconf\\base.py 200 201 202 203 204 205 206 207 def __setattr__ ( self , name , value ): \"\"\"Allow `settings.FOO = 'value'` and deal with `_deleted`\"\"\" try : self . _deleted . discard ( name ) except AttributeError : pass super ( Settings , self ) . __setattr__ ( name , value )","title":"__setattr__()"},{"location":"modules/base/#dynaconf.base.Settings.__setitem__","text":"Allow settings['KEY'] = 'value' Source code in dynaconf\\base.py 226 227 228 def __setitem__ ( self , key , value ): \"\"\"Allow `settings['KEY'] = 'value'`\"\"\" self . set ( key , value )","title":"__setitem__()"},{"location":"modules/base/#dynaconf.base.Settings.as_bool","text":"Partial method for get with bool cast Source code in dynaconf\\base.py 376 377 378 def as_bool ( self , key ): \"\"\"Partial method for get with bool cast\"\"\" return self . get ( key , cast = \"@bool\" )","title":"as_bool()"},{"location":"modules/base/#dynaconf.base.Settings.as_dict","text":"Returns a dictionary with set key and values. :param env: Str env name, default self.current_env DEVELOPMENT :param internal: bool - should include dynaconf internal vars? Source code in dynaconf\\base.py 243 244 245 246 247 248 249 250 251 252 253 254 255 256 def as_dict ( self , env = None , internal = False ): \"\"\"Returns a dictionary with set key and values. :param env: Str env name, default self.current_env `DEVELOPMENT` :param internal: bool - should include dynaconf internal vars? \"\"\" ctx_mgr = suppress () if env is None else self . using_env ( env ) with ctx_mgr : data = self . store . to_dict () . copy () # if not internal remove internal settings if not internal : for name in dir ( default_settings ): data . pop ( name , None ) return data","title":"as_dict()"},{"location":"modules/base/#dynaconf.base.Settings.as_float","text":"Partial method for get with float cast Source code in dynaconf\\base.py 384 385 386 def as_float ( self , key ): \"\"\"Partial method for get with float cast\"\"\" return self . get ( key , cast = \"@float\" )","title":"as_float()"},{"location":"modules/base/#dynaconf.base.Settings.as_int","text":"Partial method for get with int cast Source code in dynaconf\\base.py 380 381 382 def as_int ( self , key ): \"\"\"Partial method for get with int cast\"\"\" return self . get ( key , cast = \"@int\" )","title":"as_int()"},{"location":"modules/base/#dynaconf.base.Settings.as_json","text":"Partial method for get with json cast Source code in dynaconf\\base.py 388 389 390 def as_json ( self , key ): \"\"\"Partial method for get with json cast\"\"\" return self . get ( key , cast = \"@json\" )","title":"as_json()"},{"location":"modules/base/#dynaconf.base.Settings.clean","text":"Clean all loaded values to reload when switching envs Source code in dynaconf\\base.py 614 615 616 617 def clean ( self , * args , ** kwargs ): \"\"\"Clean all loaded values to reload when switching envs\"\"\" for key in list ( self . store . keys ()): self . unset ( key )","title":"clean()"},{"location":"modules/base/#dynaconf.base.Settings.execute_loaders","text":"Execute all internal and registered loaders :param env: The environment to load :param silent: If loading erros is silenced :param key: if provided load a single key :param filename: optional custom filename to load Source code in dynaconf\\base.py 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 def execute_loaders ( self , env = None , silent = None , key = None , filename = None ): \"\"\"Execute all internal and registered loaders :param env: The environment to load :param silent: If loading erros is silenced :param key: if provided load a single key :param filename: optional custom filename to load \"\"\" if key is None : default_loader ( self , self . _defaults ) env = ( env or self . current_env ) . upper () silent = silent or self . SILENT_ERRORS_FOR_DYNACONF self . pre_load ( env , silent = silent , key = key ) settings_loader ( self , env = env , silent = silent , key = key , filename = filename ) self . load_extra_yaml ( env , silent , key ) # DEPRECATED enable_external_loaders ( self ) for loader in self . loaders : self . logger . debug ( f \"Dynaconf executing: { loader . __name__ } \" ) loader . load ( self , env , silent = silent , key = key ) self . load_includes ( env , silent = silent , key = key ) self . logger . debug ( f \"Loaded Files: { deduplicate ( self . _loaded_files ) } \" )","title":"execute_loaders()"},{"location":"modules/base/#dynaconf.base.Settings.exists","text":"Check if key exists :param key: the name of setting variable :param fresh: if key should be taken from source direclty :return: Boolean Source code in dynaconf\\base.py 331 332 333 334 335 336 337 338 339 340 341 def exists ( self , key , fresh = False ): \"\"\"Check if key exists :param key: the name of setting variable :param fresh: if key should be taken from source direclty :return: Boolean \"\"\" key = upperfy ( key ) if key in self . _deleted : return False return self . get ( key , fresh = fresh , default = missing ) is not missing","title":"exists()"},{"location":"modules/base/#dynaconf.base.Settings.exists_in_environ","text":"Return True if env variable is exported Source code in dynaconf\\base.py 372 373 374 def exists_in_environ ( self , key ): \"\"\"Return True if env variable is exported\"\"\" return upperfy ( key ) in self . environ","title":"exists_in_environ()"},{"location":"modules/base/#dynaconf.base.Settings.flag","text":"Feature flagging system write flags to redis $ dynaconf write redis -s DASHBOARD=1 -e premiumuser meaning: Any premium user has DASHBOARD feature enabled In your program do:: # premium user has access to dashboard? >>> if settings.flag('dashboard', 'premiumuser'): ... activate_dashboard() The value is ensured to be loaded fresh from redis server It also works with file settings but the recommended is redis as the data can be loaded once it is updated. :param key: The flag name :param env: The env to look for Source code in dynaconf\\base.py 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 def flag ( self , key , env = None ): \"\"\"Feature flagging system write flags to redis $ dynaconf write redis -s DASHBOARD=1 -e premiumuser meaning: Any premium user has DASHBOARD feature enabled In your program do:: # premium user has access to dashboard? >>> if settings.flag('dashboard', 'premiumuser'): ... activate_dashboard() The value is ensured to be loaded fresh from redis server It also works with file settings but the recommended is redis as the data can be loaded once it is updated. :param key: The flag name :param env: The env to look for \"\"\" env = env or self . ENVVAR_PREFIX_FOR_DYNACONF or \"DYNACONF\" with self . using_env ( env ): value = self . get_fresh ( key ) return value is True or value in true_values","title":"flag()"},{"location":"modules/base/#dynaconf.base.Settings.fresh","text":"this context manager force the load of a key direct from the store:: $ export DYNACONF_VALUE='Original' >>> from dynaconf import settings >>> print settings.VALUE 'Original' $ export DYNACONF_VALUE='Changed Value' >>> print settings.VALUE # will not be reloaded from env vars 'Original >>> with settings.fresh(): # inside this context all is reloaded ... print settings.VALUE 'Changed Value' an alternative is using settings.get_fresh(key) :return: context Source code in dynaconf\\base.py 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 @contextmanager def fresh ( self ): \"\"\" this context manager force the load of a key direct from the store:: $ export DYNACONF_VALUE='Original' >>> from dynaconf import settings >>> print settings.VALUE 'Original' $ export DYNACONF_VALUE='Changed Value' >>> print settings.VALUE # will not be reloaded from env vars 'Original >>> with settings.fresh(): # inside this context all is reloaded ... print settings.VALUE 'Changed Value' an alternative is using `settings.get_fresh(key)` :return: context \"\"\" self . _fresh = True yield self . _fresh = False","title":"fresh()"},{"location":"modules/base/#dynaconf.base.Settings.from_env","text":"Return a new isolated settings object pointing to specified env. Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print(settings.MESSAGE) 'This is in dev' >>> print(settings.from_env('other').MESSAGE) 'This is in other env' # The existing settings object remains the same. >>> print(settings.MESSAGE) 'This is in dev' Arguments:: env {str} -- Env to load (development, production, custom) Keyword Arguments:: keep {bool} -- Keep pre-existing values (default: {False}) kwargs {dict} -- Passed directly to new instance. Source code in dynaconf\\base.py 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 def from_env ( self , env , keep = False , ** kwargs ): \"\"\"Return a new isolated settings object pointing to specified env. Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print(settings.MESSAGE) 'This is in dev' >>> print(settings.from_env('other').MESSAGE) 'This is in other env' # The existing settings object remains the same. >>> print(settings.MESSAGE) 'This is in dev' Arguments:: env {str} -- Env to load (development, production, custom) Keyword Arguments:: keep {bool} -- Keep pre-existing values (default: {False}) kwargs {dict} -- Passed directly to new instance. \"\"\" cache_key = f \" { env } _ { keep } _ { kwargs } \" if cache_key in self . _env_cache : self . logger . debug ( f \"Settings instance in env: { env } from cache\" ) return self . _env_cache [ cache_key ] new_data = { key : self . get ( key ) for key in dir ( default_settings ) if key . isupper () and key not in RENAMED_VARS } if keep : # keep existing values from current env new_data . update ( { key : value for key , value in self . store . to_dict () . copy () . items () if key . isupper () and key not in RENAMED_VARS } ) new_data . update ( kwargs ) new_data [ \"FORCE_ENV_FOR_DYNACONF\" ] = env new_settings = LazySettings ( ** new_data ) self . logger . debug ( f \"New settings instance in env: { env } \" ) self . _env_cache [ cache_key ] = new_settings return new_settings","title":"from_env()"},{"location":"modules/base/#dynaconf.base.Settings.get","text":"Get a value from settings store, this is the prefered way to access:: >>> from dynaconf import settings >>> settings.get('KEY') :param key: The name of the setting value, will always be upper case :param default: In case of not found it will be returned :param cast: Should cast in to @int, @float, @bool or @json ? :param fresh: Should reload from loaders store before access? :param dotted_lookup: Should perform dotted-path lookup? :param parent: Is there a pre-loaded parent in a nested data? :return: The value if found, default or None Source code in dynaconf\\base.py 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 @evaluate_lazy_format def get ( self , key , default = None , cast = None , fresh = False , dotted_lookup = True , parent = None , ): \"\"\" Get a value from settings store, this is the prefered way to access:: >>> from dynaconf import settings >>> settings.get('KEY') :param key: The name of the setting value, will always be upper case :param default: In case of not found it will be returned :param cast: Should cast in to @int, @float, @bool or @json ? :param fresh: Should reload from loaders store before access? :param dotted_lookup: Should perform dotted-path lookup? :param parent: Is there a pre-loaded parent in a nested data? :return: The value if found, default or None \"\"\" if \".\" in key and dotted_lookup : return self . _dotted_get ( dotted_key = key , default = default , cast = cast , fresh = fresh , parent = parent , ) key = upperfy ( key ) if key in self . _deleted : return default if ( fresh or self . _fresh or key in getattr ( self , \"FRESH_VARS_FOR_DYNACONF\" , ()) ) and key not in dir ( default_settings ): self . unset ( key ) self . execute_loaders ( key = key ) data = ( parent or self . store ) . get ( key , default ) if cast : data = converters . get ( cast )( data ) return data","title":"get()"},{"location":"modules/base/#dynaconf.base.Settings.get_environ","text":"Get value from environment variable using os.environ.get :param key: The name of the setting value, will always be upper case :param default: In case of not found it will be returned :param cast: Should cast in to @int, @float, @bool or @json ? or cast must be true to use cast inference :return: The value if found, default or None Source code in dynaconf\\base.py 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 def get_environ ( self , key , default = None , cast = None ): \"\"\"Get value from environment variable using os.environ.get :param key: The name of the setting value, will always be upper case :param default: In case of not found it will be returned :param cast: Should cast in to @int, @float, @bool or @json ? or cast must be true to use cast inference :return: The value if found, default or None \"\"\" key = upperfy ( key ) data = self . environ . get ( key , default ) if data : if cast in converters : data = converters . get ( cast )( data ) if cast is True : data = parse_conf_data ( data , tomlfy = True ) return data","title":"get_environ()"},{"location":"modules/base/#dynaconf.base.Settings.get_fresh","text":"This is a shortcut to get(key, fresh=True) . always reload from loaders store before getting the var. :param key: The name of the setting value, will always be upper case :param default: In case of not found it will be returned :param cast: Should cast in to @int, @float, @bool or @json ? :return: The value if found, default or None Source code in dynaconf\\base.py 343 344 345 346 347 348 349 350 351 352 def get_fresh ( self , key , default = None , cast = None ): \"\"\"This is a shortcut to `get(key, fresh=True)`. always reload from loaders store before getting the var. :param key: The name of the setting value, will always be upper case :param default: In case of not found it will be returned :param cast: Should cast in to @int, @float, @bool or @json ? :return: The value if found, default or None \"\"\" return self . get ( key , default = default , cast = cast , fresh = True )","title":"get_fresh()"},{"location":"modules/base/#dynaconf.base.Settings.keys","text":"Redirects to store object Source code in dynaconf\\base.py 235 236 237 def keys ( self ): \"\"\"Redirects to store object\"\"\" return self . store . keys ()","title":"keys()"},{"location":"modules/base/#dynaconf.base.Settings.load_extra_yaml","text":"This is deprecated, kept for compat .. deprecated:: 1.0.0 Use multiple settings or INCLUDES_FOR_DYNACONF files instead. Source code in dynaconf\\base.py 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 def load_extra_yaml ( self , env , silent , key ): \"\"\"This is deprecated, kept for compat .. deprecated:: 1.0.0 Use multiple settings or INCLUDES_FOR_DYNACONF files instead. \"\"\" if self . get ( \"YAML\" ) is not None : self . logger . warning ( \"The use of YAML var is deprecated, please define multiple \" \"filepaths instead: \" \"e.g: SETTINGS_FILE_FOR_DYNACONF = \" \"'settings.py,settings.yaml,settings.toml' or \" \"INCLUDES_FOR_DYNACONF=['path.toml', 'folder/*']\" ) yaml_loader . load ( self , env = env , filename = self . find_file ( self . get ( \"YAML\" )), silent = silent , key = key , )","title":"load_extra_yaml()"},{"location":"modules/base/#dynaconf.base.Settings.load_file","text":"Programmatically load files from path . :param path: A single filename or a file list :param env: Which env to load from file (default current_env) :param silent: Should raise errors? :param key: Load a single key? Source code in dynaconf\\base.py 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 def load_file ( self , path = None , env = None , silent = True , key = None ): \"\"\"Programmatically load files from ``path``. :param path: A single filename or a file list :param env: Which env to load from file (default current_env) :param silent: Should raise errors? :param key: Load a single key? \"\"\" env = ( env or self . current_env ) . upper () files = ensure_a_list ( path ) if files : self . logger . debug ( f \"Got { files } files to process\" ) already_loaded = set () for _filename in files : self . logger . debug ( f \"Processing file { _filename } \" ) if py_loader . try_to_load_from_py_module_name ( obj = self , name = _filename , silent = True ): # if it was possible to load from module name # continue the loop. continue filepath = os . path . join ( self . _root_path or os . getcwd (), _filename ) self . logger . debug ( f \"File path is { filepath } \" ) paths = [ p for p in sorted ( glob . glob ( filepath )) if \".local.\" not in p ] local_paths = [ p for p in sorted ( glob . glob ( filepath )) if \".local.\" in p ] # Handle possible *.globs sorted alphanumeric for path in paths + local_paths : self . logger . debug ( f \"Loading { path } \" ) if path in already_loaded : # pragma: no cover self . logger . debug ( f \"Skipping { path } , already loaded\" ) continue settings_loader ( obj = self , env = env , silent = silent , key = key , filename = path , ) already_loaded . add ( path ) if not already_loaded : self . logger . warning ( f \"Not able to locate the files { files } \" \"to load\" )","title":"load_file()"},{"location":"modules/base/#dynaconf.base.Settings.load_includes","text":"Do we have any nested includes we need to process? Source code in dynaconf\\base.py 905 906 907 908 909 910 911 912 913 914 915 def load_includes ( self , env , silent , key ): \"\"\"Do we have any nested includes we need to process?\"\"\" includes = self . get ( \"DYNACONF_INCLUDE\" , []) includes . extend ( ensure_a_list ( self . get ( \"INCLUDES_FOR_DYNACONF\" ))) if includes : self . logger . debug ( f \"Processing includes { includes } \" ) self . load_file ( path = includes , env = env , silent = silent , key = key ) # ensure env vars are the last thing loaded after all includes last_loader = self . loaders and self . loaders [ - 1 ] if last_loader and last_loader == env_loader : last_loader . load ( self , env , silent , key )","title":"load_includes()"},{"location":"modules/base/#dynaconf.base.Settings.namespace","text":"Used to interactively change the env Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print settings.MESSAGE 'This is in dev' >>> with settings.using_env('OTHER'): ... print settings.MESSAGE 'this is in other env' :param env: Upper case name of env without any _ :param clean: If preloaded vars should be cleaned :param silent: Silence errors :param filename: Custom filename to load (optional) :return: context Source code in dynaconf\\base.py 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 def setenv ( self , env = None , clean = True , silent = True , filename = None ): \"\"\"Used to interactively change the env Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print settings.MESSAGE 'This is in dev' >>> with settings.using_env('OTHER'): ... print settings.MESSAGE 'this is in other env' :param env: Upper case name of env without any _ :param clean: If preloaded vars should be cleaned :param silent: Silence errors :param filename: Custom filename to load (optional) :return: context \"\"\" env = env or self . ENV_FOR_DYNACONF if not isinstance ( env , str ): raise AttributeError ( \"env should be a string\" ) self . logger . debug ( f \"env switching to: { env } \" ) env = env . upper () if env != self . ENV_FOR_DYNACONF : self . loaded_envs . append ( env ) else : self . loaded_envs = [] if clean : self . clean ( env = env ) self . execute_loaders ( env = env , silent = silent , filename = filename )","title":"namespace()"},{"location":"modules/base/#dynaconf.base.Settings.path_for","text":"Path containing _root_path Source code in dynaconf\\base.py 1003 1004 1005 1006 1007 def path_for ( self , * args ): \"\"\"Path containing _root_path\"\"\" if args and args [ 0 ] . startswith ( os . path . sep ): return os . path . join ( * args ) return os . path . join ( self . _root_path or os . getcwd (), * args )","title":"path_for()"},{"location":"modules/base/#dynaconf.base.Settings.populate_obj","text":"Given the obj populate it using self.store items. :param obj: An object to be populated, a class instance. :param keys: A list of keys to be included. :param ignore: A list of keys to be excluded. Source code in dynaconf\\base.py 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 def populate_obj ( self , obj , keys = None , ignore = None ): \"\"\"Given the `obj` populate it using self.store items. :param obj: An object to be populated, a class instance. :param keys: A list of keys to be included. :param ignore: A list of keys to be excluded. \"\"\" keys = keys or self . keys () for key in keys : key = upperfy ( key ) if ignore and key in ignore : continue value = self . get ( key , empty ) if value is not empty : setattr ( obj , key , value )","title":"populate_obj()"},{"location":"modules/base/#dynaconf.base.Settings.pre_load","text":"Do we have any file to pre-load before main settings file? Source code in dynaconf\\base.py 898 899 900 901 902 903 def pre_load ( self , env , silent , key ): \"\"\"Do we have any file to pre-load before main settings file?\"\"\" preloads = self . get ( \"PRELOAD_FOR_DYNACONF\" , []) if preloads : self . logger . debug ( f \"Processing preloads { preloads } \" ) self . load_file ( path = preloads , env = env , silent = silent , key = key )","title":"pre_load()"},{"location":"modules/base/#dynaconf.base.Settings.reload","text":"Clean end Execute all loaders Source code in dynaconf\\base.py 869 870 871 872 def reload ( self , env = None , silent = None ): # pragma: no cover \"\"\"Clean end Execute all loaders\"\"\" self . clean () self . execute_loaders ( env , silent )","title":"reload()"},{"location":"modules/base/#dynaconf.base.Settings.set","text":"Set a value storing references for the loader :param key: The key to store :param value: The value to store :param loader_identifier: Optional loader name e.g: toml, yaml etc. :param tomlfy: Bool define if value is parsed by toml (defaults False) :param is_secret: Bool define if secret values is hidden on logs. :param merge: Bool define if existing nested data will be merged. Source code in dynaconf\\base.py 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 def set ( self , key , value , loader_identifier = None , tomlfy = False , dotted_lookup = True , is_secret = False , merge = False , ): \"\"\"Set a value storing references for the loader :param key: The key to store :param value: The value to store :param loader_identifier: Optional loader name e.g: toml, yaml etc. :param tomlfy: Bool define if value is parsed by toml (defaults False) :param is_secret: Bool define if secret values is hidden on logs. :param merge: Bool define if existing nested data will be merged. \"\"\" nested_sep = self . get ( \"NESTED_SEPARATOR_FOR_DYNACONF\" ) if nested_sep and nested_sep in key : # turn FOO__bar__ZAZ in `FOO.bar.ZAZ` key = key . replace ( nested_sep , \".\" ) if \".\" in key and dotted_lookup is True : return self . _dotted_set ( key , value , loader_identifier = loader_identifier , tomlfy = tomlfy ) value = parse_conf_data ( value , tomlfy = tomlfy ) key = upperfy ( key . strip ()) existing = getattr ( self , key , None ) if getattr ( value , \"_dynaconf_del\" , None ): # just in case someone use a `@del` in a first level var. self . unset ( key , force = True ) return if getattr ( value , \"_dynaconf_reset\" , False ): # pragma: no cover # just in case someone use a `@reset` in a first level var. # NOTE: @reset/Reset is deprecated in v3.0.0 value = value . unwrap () if getattr ( value , \"_dynaconf_merge\" , False ): # just in case someone use a `@merge` in a first level var if existing : object_merge ( existing , value . unwrap ()) value = value . unwrap () if existing is not None and existing != value : # `dynaconf_merge` used in file root `merge=True` if merge : object_merge ( existing , value ) else : # `dynaconf_merge` may be used within the key structure value = self . _merge_before_set ( key , existing , value , is_secret ) if isinstance ( value , dict ): value = DynaBox ( value ) setattr ( self , key , value ) self . store [ key ] = value self . _deleted . discard ( key ) # set loader identifiers so cleaners know which keys to clean if loader_identifier and loader_identifier in self . loaded_by_loaders : self . loaded_by_loaders [ loader_identifier ][ key ] = value elif loader_identifier : self . loaded_by_loaders [ loader_identifier ] = { key : value } elif loader_identifier is None : # if .set is called without loader identifier it becomes # a default value and goes away only when explicitly unset self . _defaults [ key ] = value","title":"set()"},{"location":"modules/base/#dynaconf.base.Settings.setenv","text":"Used to interactively change the env Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print settings.MESSAGE 'This is in dev' >>> with settings.using_env('OTHER'): ... print settings.MESSAGE 'this is in other env' :param env: Upper case name of env without any _ :param clean: If preloaded vars should be cleaned :param silent: Silence errors :param filename: Custom filename to load (optional) :return: context Source code in dynaconf\\base.py 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 def setenv ( self , env = None , clean = True , silent = True , filename = None ): \"\"\"Used to interactively change the env Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print settings.MESSAGE 'This is in dev' >>> with settings.using_env('OTHER'): ... print settings.MESSAGE 'this is in other env' :param env: Upper case name of env without any _ :param clean: If preloaded vars should be cleaned :param silent: Silence errors :param filename: Custom filename to load (optional) :return: context \"\"\" env = env or self . ENV_FOR_DYNACONF if not isinstance ( env , str ): raise AttributeError ( \"env should be a string\" ) self . logger . debug ( f \"env switching to: { env } \" ) env = env . upper () if env != self . ENV_FOR_DYNACONF : self . loaded_envs . append ( env ) else : self . loaded_envs = [] if clean : self . clean ( env = env ) self . execute_loaders ( env = env , silent = silent , filename = filename )","title":"setenv()"},{"location":"modules/base/#dynaconf.base.Settings.to_dict","text":"Returns a dictionary with set key and values. :param env: Str env name, default self.current_env DEVELOPMENT :param internal: bool - should include dynaconf internal vars? Source code in dynaconf\\base.py 243 244 245 246 247 248 249 250 251 252 253 254 255 256 def as_dict ( self , env = None , internal = False ): \"\"\"Returns a dictionary with set key and values. :param env: Str env name, default self.current_env `DEVELOPMENT` :param internal: bool - should include dynaconf internal vars? \"\"\" ctx_mgr = suppress () if env is None else self . using_env ( env ) with ctx_mgr : data = self . store . to_dict () . copy () # if not internal remove internal settings if not internal : for name in dir ( default_settings ): data . pop ( name , None ) return data","title":"to_dict()"},{"location":"modules/base/#dynaconf.base.Settings.unset","text":"Unset on all references :param key: The key to be unset :param force: Bypass default checks and force unset Source code in dynaconf\\base.py 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 def unset ( self , key , force = False ): \"\"\"Unset on all references :param key: The key to be unset :param force: Bypass default checks and force unset \"\"\" key = upperfy ( key . strip ()) if ( key not in dir ( default_settings ) and key not in self . _defaults or force ): self . logger . debug ( f \"Unset { key } \" ) delattr ( self , key ) self . store . pop ( key , None )","title":"unset()"},{"location":"modules/base/#dynaconf.base.Settings.unset_all","text":"Unset based on a list of keys :param keys: a list of keys :param force: Bypass default checks and force unset Source code in dynaconf\\base.py 635 636 637 638 639 640 641 642 def unset_all ( self , keys , force = False ): # pragma: no cover \"\"\"Unset based on a list of keys :param keys: a list of keys :param force: Bypass default checks and force unset \"\"\" for key in keys : self . unset ( key , force = force )","title":"unset_all()"},{"location":"modules/base/#dynaconf.base.Settings.update","text":"Update values in the current settings object without saving in stores:: >>> from dynaconf import settings >>> print settings.NAME 'Bruno' >>> settings.update({'NAME': 'John'}, other_value=1) >>> print settings.NAME 'John' >>> print settings.OTHER_VALUE 1 :param data: Data to be updated :param loader_identifier: Only to be used by custom loaders :param tomlfy: Bool define if value is parsed by toml (defaults False) :param merge: Bool define if existing nested data will be merged. :param kwargs: extra values to update :return: None Source code in dynaconf\\base.py 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 def update ( self , data = None , loader_identifier = None , tomlfy = False , is_secret = False , merge = False , ** kwargs , ): \"\"\" Update values in the current settings object without saving in stores:: >>> from dynaconf import settings >>> print settings.NAME 'Bruno' >>> settings.update({'NAME': 'John'}, other_value=1) >>> print settings.NAME 'John' >>> print settings.OTHER_VALUE 1 :param data: Data to be updated :param loader_identifier: Only to be used by custom loaders :param tomlfy: Bool define if value is parsed by toml (defaults False) :param merge: Bool define if existing nested data will be merged. :param kwargs: extra values to update :return: None \"\"\" data = data or {} data . update ( kwargs ) for key , value in data . items (): self . set ( key , value , loader_identifier = loader_identifier , tomlfy = tomlfy , is_secret = is_secret , merge = merge , )","title":"update()"},{"location":"modules/base/#dynaconf.base.Settings.using_env","text":"This context manager allows the contextual use of a different env Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print settings.MESSAGE 'This is in dev' >>> with settings.using_env('OTHER'): ... print settings.MESSAGE 'this is in other env' :param env: Upper case name of env without any _ :param clean: If preloaded vars should be cleaned :param silent: Silence errors :param filename: Custom filename to load (optional) :return: context Source code in dynaconf\\base.py 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 @contextmanager def using_env ( self , env , clean = True , silent = True , filename = None ): \"\"\" This context manager allows the contextual use of a different env Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print settings.MESSAGE 'This is in dev' >>> with settings.using_env('OTHER'): ... print settings.MESSAGE 'this is in other env' :param env: Upper case name of env without any _ :param clean: If preloaded vars should be cleaned :param silent: Silence errors :param filename: Custom filename to load (optional) :return: context \"\"\" try : self . setenv ( env , clean = clean , silent = silent , filename = filename ) self . logger . debug ( f \"In env: { env } \" ) yield finally : if env . lower () != self . ENV_FOR_DYNACONF . lower (): del self . loaded_envs [ - 1 ] self . logger . debug ( f \"Out env: { env } \" ) self . setenv ( self . current_env , clean = clean , filename = filename )","title":"using_env()"},{"location":"modules/base/#dynaconf.base.Settings.using_namespace","text":"This context manager allows the contextual use of a different env Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print settings.MESSAGE 'This is in dev' >>> with settings.using_env('OTHER'): ... print settings.MESSAGE 'this is in other env' :param env: Upper case name of env without any _ :param clean: If preloaded vars should be cleaned :param silent: Silence errors :param filename: Custom filename to load (optional) :return: context Source code in dynaconf\\base.py 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 @contextmanager def using_env ( self , env , clean = True , silent = True , filename = None ): \"\"\" This context manager allows the contextual use of a different env Example of settings.toml:: [development] message = 'This is in dev' [other] message = 'this is in other env' Program:: >>> from dynaconf import settings >>> print settings.MESSAGE 'This is in dev' >>> with settings.using_env('OTHER'): ... print settings.MESSAGE 'this is in other env' :param env: Upper case name of env without any _ :param clean: If preloaded vars should be cleaned :param silent: Silence errors :param filename: Custom filename to load (optional) :return: context \"\"\" try : self . setenv ( env , clean = clean , silent = silent , filename = filename ) self . logger . debug ( f \"In env: { env } \" ) yield finally : if env . lower () != self . ENV_FOR_DYNACONF . lower (): del self . loaded_envs [ - 1 ] self . logger . debug ( f \"Out env: { env } \" ) self . setenv ( self . current_env , clean = clean , filename = filename )","title":"using_namespace()"},{"location":"modules/base/#dynaconf.base.Settings.values","text":"Redirects to store object Source code in dynaconf\\base.py 239 240 241 def values ( self ): \"\"\"Redirects to store object\"\"\" return self . store . values ()","title":"values()"},{"location":"modules/cli/","text":"import_settings ( dotted_path ) Import settings instance from python dotted path. Last item in dotted path must be settings instace. Example: import_settings('path.to.settings') Source code in dynaconf\\cli.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def import_settings ( dotted_path ): \"\"\"Import settings instance from python dotted path. Last item in dotted path must be settings instace. Example: import_settings('path.to.settings') \"\"\" if \".\" in dotted_path : module , name = dotted_path . rsplit ( \".\" , 1 ) else : raise click . UsageError ( f \"invalid path to settings instance: { dotted_path } \" ) try : module = importlib . import_module ( module ) except ImportError as e : raise click . UsageError ( e ) try : return getattr ( module , name ) except AttributeError as e : raise click . UsageError ( e ) read_file_in_root_directory ( * names , ** kwargs ) Read a file on root dir. Source code in dynaconf\\cli.py 119 120 121 122 123 124 def read_file_in_root_directory ( * names , ** kwargs ): \"\"\"Read a file on root dir.\"\"\" return read_file ( os . path . join ( os . path . dirname ( __file__ ), * names ), encoding = kwargs . get ( \"encoding\" , \"utf-8\" ), ) set_settings ( instance = None ) Pick correct settings instance and set it to a global variable. Source code in dynaconf\\cli.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def set_settings ( instance = None ): \"\"\"Pick correct settings instance and set it to a global variable.\"\"\" global settings settings = None if instance : settings = import_settings ( instance ) elif \"INSTANCE_FOR_DYNACONF\" in os . environ : settings = import_settings ( os . environ [ \"INSTANCE_FOR_DYNACONF\" ]) elif \"FLASK_APP\" in os . environ : # pragma: no cover with suppress ( ImportError , click . UsageError ): from flask.cli import ScriptInfo flask_app = ScriptInfo () . load_app () settings = flask_app . config click . echo ( click . style ( \"Flask app detected\" , fg = \"white\" , bg = \"bright_black\" ) ) elif \"DJANGO_SETTINGS_MODULE\" in os . environ : # pragma: no cover sys . path . insert ( 0 , os . path . abspath ( os . getcwd ())) try : # Django extension v2 from django.conf import settings settings . DYNACONF . configure () except ( ImportError , AttributeError ): # Backwards compatible with old django extension (pre 2.0.0) import dynaconf.contrib.django_dynaconf # noqa from django.conf import settings as django_settings django_settings . configure () settings = django_settings if settings is not None : click . echo ( click . style ( \"Django app detected\" , fg = \"white\" , bg = \"bright_black\" ) ) if settings is None : settings = LazySettings () show_banner ( ctx , param , value ) Shows dynaconf awesome banner Source code in dynaconf\\cli.py 143 144 145 146 147 148 149 150 def show_banner ( ctx , param , value ): \"\"\"Shows dynaconf awesome banner\"\"\" if not value or ctx . resilient_parsing : return set_settings () click . echo ( settings . dynaconf_banner ) click . echo ( \"Learn more at: http://github.com/rochacbruno/dynaconf\" ) ctx . exit () split_vars ( _vars ) Splits values like foo=bar=zaz in {'foo': 'bar=zaz'} Source code in dynaconf\\cli.py 107 108 109 110 111 112 113 114 115 116 def split_vars ( _vars ): \"\"\"Splits values like foo=bar=zaz in {'foo': 'bar=zaz'}\"\"\" return ( { upperfy ( k . strip ()): parse_conf_data ( v . strip (), tomlfy = True ) for k , _ , v in [ item . partition ( \"=\" ) for item in _vars ] } if _vars else {} )","title":"CLI"},{"location":"modules/cli/#dynaconf.cli","text":"","title":"dynaconf.cli"},{"location":"modules/cli/#dynaconf.cli.import_settings","text":"Import settings instance from python dotted path. Last item in dotted path must be settings instace. Example: import_settings('path.to.settings') Source code in dynaconf\\cli.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def import_settings ( dotted_path ): \"\"\"Import settings instance from python dotted path. Last item in dotted path must be settings instace. Example: import_settings('path.to.settings') \"\"\" if \".\" in dotted_path : module , name = dotted_path . rsplit ( \".\" , 1 ) else : raise click . UsageError ( f \"invalid path to settings instance: { dotted_path } \" ) try : module = importlib . import_module ( module ) except ImportError as e : raise click . UsageError ( e ) try : return getattr ( module , name ) except AttributeError as e : raise click . UsageError ( e )","title":"import_settings()"},{"location":"modules/cli/#dynaconf.cli.read_file_in_root_directory","text":"Read a file on root dir. Source code in dynaconf\\cli.py 119 120 121 122 123 124 def read_file_in_root_directory ( * names , ** kwargs ): \"\"\"Read a file on root dir.\"\"\" return read_file ( os . path . join ( os . path . dirname ( __file__ ), * names ), encoding = kwargs . get ( \"encoding\" , \"utf-8\" ), )","title":"read_file_in_root_directory()"},{"location":"modules/cli/#dynaconf.cli.set_settings","text":"Pick correct settings instance and set it to a global variable. Source code in dynaconf\\cli.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def set_settings ( instance = None ): \"\"\"Pick correct settings instance and set it to a global variable.\"\"\" global settings settings = None if instance : settings = import_settings ( instance ) elif \"INSTANCE_FOR_DYNACONF\" in os . environ : settings = import_settings ( os . environ [ \"INSTANCE_FOR_DYNACONF\" ]) elif \"FLASK_APP\" in os . environ : # pragma: no cover with suppress ( ImportError , click . UsageError ): from flask.cli import ScriptInfo flask_app = ScriptInfo () . load_app () settings = flask_app . config click . echo ( click . style ( \"Flask app detected\" , fg = \"white\" , bg = \"bright_black\" ) ) elif \"DJANGO_SETTINGS_MODULE\" in os . environ : # pragma: no cover sys . path . insert ( 0 , os . path . abspath ( os . getcwd ())) try : # Django extension v2 from django.conf import settings settings . DYNACONF . configure () except ( ImportError , AttributeError ): # Backwards compatible with old django extension (pre 2.0.0) import dynaconf.contrib.django_dynaconf # noqa from django.conf import settings as django_settings django_settings . configure () settings = django_settings if settings is not None : click . echo ( click . style ( \"Django app detected\" , fg = \"white\" , bg = \"bright_black\" ) ) if settings is None : settings = LazySettings ()","title":"set_settings()"},{"location":"modules/cli/#dynaconf.cli.show_banner","text":"Shows dynaconf awesome banner Source code in dynaconf\\cli.py 143 144 145 146 147 148 149 150 def show_banner ( ctx , param , value ): \"\"\"Shows dynaconf awesome banner\"\"\" if not value or ctx . resilient_parsing : return set_settings () click . echo ( settings . dynaconf_banner ) click . echo ( \"Learn more at: http://github.com/rochacbruno/dynaconf\" ) ctx . exit ()","title":"show_banner()"},{"location":"modules/cli/#dynaconf.cli.split_vars","text":"Splits values like foo=bar=zaz in {'foo': 'bar=zaz'} Source code in dynaconf\\cli.py 107 108 109 110 111 112 113 114 115 116 def split_vars ( _vars ): \"\"\"Splits values like foo=bar=zaz in {'foo': 'bar=zaz'}\"\"\" return ( { upperfy ( k . strip ()): parse_conf_data ( v . strip (), tomlfy = True ) for k , _ , v in [ item . partition ( \"=\" ) for item in _vars ] } if _vars else {} )","title":"split_vars()"},{"location":"modules/constants/","text":"","title":"Constants"},{"location":"modules/constants/#dynaconf.constants","text":"","title":"dynaconf.constants"},{"location":"modules/default_settings/","text":"","title":"Default Settings"},{"location":"modules/default_settings/#dynaconf.default_settings","text":"","title":"dynaconf.default_settings"},{"location":"modules/modules/","text":"Submodules Base CLI Default Settings Constants Test Settings Validator Validator Conditions Subpackages Contrib Flask Loaders base env ini json py redis toml vault yaml Utils Boxing Parse Config Files","title":"Guide"},{"location":"modules/modules/#submodules","text":"Base CLI Default Settings Constants Test Settings Validator Validator Conditions","title":"Submodules"},{"location":"modules/modules/#subpackages","text":"","title":"Subpackages"},{"location":"modules/modules/#contrib","text":"Flask","title":"Contrib"},{"location":"modules/modules/#loaders","text":"base env ini json py redis toml vault yaml","title":"Loaders"},{"location":"modules/modules/#utils","text":"Boxing Parse Config Files","title":"Utils"},{"location":"modules/test_settings/","text":"","title":"Test Settings"},{"location":"modules/test_settings/#dynaconf.test_settings","text":"","title":"dynaconf.test_settings"},{"location":"modules/validator/","text":"Validator Validators are conditions attached to settings variables names or patterns:: Validator('MESSAGE', must_exist=True, eq='Hello World') The above ensure MESSAGE is available in default env and is equal to 'Hello World' `names` are a one (or more) names or patterns:: Validator('NAME') Validator('NAME', 'OTHER_NAME', 'EVEN_OTHER') Validator(r'^NAME', r'OTHER./*') The `operations` are:: eq: value == other ne: value != other gt: value > other lt: value < other gte: value >= other lte: value <= other is_type_of: isinstance(value, type) is_in: value in sequence is_not_in: value not in sequence identity: value is other cont: contain value in len_eq: len(value) == other len_ne: len(value) != other len_min: len(value) > other len_max: len(value) < other `env` is which env to be checked, can be a list or default is used. `when` holds a validator and its return decides if validator runs or not:: Validator('NAME', must_exist=True, when=Validator('OTHER', eq=2)) # NAME is required only if OTHER eq to 2 # When the very first thing to be performed when passed. # if no env is passed to `when` it is inherited `must_exist` is `exists` requirement. (executed after when):: settings.exists(value) condition is a callable to be executed and return boolean:: Validator('NAME', condition=lambda x: x == 1) # it is executed before operations. validate ( self , settings ) Raise ValidationError if invalid Source code in dynaconf\\validator.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 def validate ( self , settings ): \"\"\"Raise ValidationError if invalid\"\"\" if self . envs is None : self . envs = [ settings . current_env ] if self . when is not None : try : # inherit env if not defined if self . when . envs is None : self . when . envs = self . envs self . when . validate ( settings ) except ValidationError : # if when is invalid, return canceling validation flow return # If only using current_env, skip using_env decoration (reload) if ( len ( self . envs ) == 1 and self . envs [ 0 ] . upper () == settings . current_env . upper () ): self . _validate_items ( settings , settings . current_env ) return for env in self . envs : self . _validate_items ( settings . from_env ( env ))","title":"Validator"},{"location":"modules/validator/#dynaconf.validator","text":"","title":"dynaconf.validator"},{"location":"modules/validator/#dynaconf.validator.Validator","text":"Validators are conditions attached to settings variables names or patterns:: Validator('MESSAGE', must_exist=True, eq='Hello World') The above ensure MESSAGE is available in default env and is equal to 'Hello World' `names` are a one (or more) names or patterns:: Validator('NAME') Validator('NAME', 'OTHER_NAME', 'EVEN_OTHER') Validator(r'^NAME', r'OTHER./*') The `operations` are:: eq: value == other ne: value != other gt: value > other lt: value < other gte: value >= other lte: value <= other is_type_of: isinstance(value, type) is_in: value in sequence is_not_in: value not in sequence identity: value is other cont: contain value in len_eq: len(value) == other len_ne: len(value) != other len_min: len(value) > other len_max: len(value) < other `env` is which env to be checked, can be a list or default is used. `when` holds a validator and its return decides if validator runs or not:: Validator('NAME', must_exist=True, when=Validator('OTHER', eq=2)) # NAME is required only if OTHER eq to 2 # When the very first thing to be performed when passed. # if no env is passed to `when` it is inherited `must_exist` is `exists` requirement. (executed after when):: settings.exists(value) condition is a callable to be executed and return boolean:: Validator('NAME', condition=lambda x: x == 1) # it is executed before operations.","title":"Validator"},{"location":"modules/validator/#dynaconf.validator.Validator.validate","text":"Raise ValidationError if invalid Source code in dynaconf\\validator.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 def validate ( self , settings ): \"\"\"Raise ValidationError if invalid\"\"\" if self . envs is None : self . envs = [ settings . current_env ] if self . when is not None : try : # inherit env if not defined if self . when . envs is None : self . when . envs = self . envs self . when . validate ( settings ) except ValidationError : # if when is invalid, return canceling validation flow return # If only using current_env, skip using_env decoration (reload) if ( len ( self . envs ) == 1 and self . envs [ 0 ] . upper () == settings . current_env . upper () ): self . _validate_items ( settings , settings . current_env ) return for env in self . envs : self . _validate_items ( settings . from_env ( env ))","title":"validate()"},{"location":"modules/validator_conditions/","text":"Implement basic assertions to be used in assertion action cont ( value , other ) Contains Source code in dynaconf\\validator_conditions.py 57 58 59 def cont ( value , other ): \"\"\"Contains\"\"\" return other in value eq ( value , other ) Equal Source code in dynaconf\\validator_conditions.py 7 8 9 def eq ( value , other ): \"\"\"Equal\"\"\" return value == other gt ( value , other ) Greater than Source code in dynaconf\\validator_conditions.py 17 18 19 def gt ( value , other ): \"\"\"Greater than\"\"\" return value > other gte ( value , other ) Greater than or equal Source code in dynaconf\\validator_conditions.py 27 28 29 def gte ( value , other ): \"\"\"Greater than or equal\"\"\" return value >= other identity ( value , other ) Identity check using ID Source code in dynaconf\\validator_conditions.py 37 38 39 def identity ( value , other ): \"\"\"Identity check using ID\"\"\" return value is other is_in ( value , other ) Existence Source code in dynaconf\\validator_conditions.py 47 48 49 def is_in ( value , other ): \"\"\"Existence\"\"\" return value in other is_not_in ( value , other ) Inexistence Source code in dynaconf\\validator_conditions.py 52 53 54 def is_not_in ( value , other ): \"\"\"Inexistence\"\"\" return value not in other is_type_of ( value , other ) Type check Source code in dynaconf\\validator_conditions.py 42 43 44 def is_type_of ( value , other ): \"\"\"Type check\"\"\" return isinstance ( value , other ) len_eq ( value , other ) Length Equal Source code in dynaconf\\validator_conditions.py 62 63 64 def len_eq ( value , other ): \"\"\"Length Equal\"\"\" return len ( str ( value )) == other len_max ( value , other ) Maximum lenght Source code in dynaconf\\validator_conditions.py 77 78 79 def len_max ( value , other ): \"\"\"Maximum lenght\"\"\" return len ( str ( value )) < other len_min ( value , other ) Minimum length Source code in dynaconf\\validator_conditions.py 72 73 74 def len_min ( value , other ): \"\"\"Minimum length\"\"\" return len ( str ( value )) > other len_ne ( value , other ) Length Not equal Source code in dynaconf\\validator_conditions.py 67 68 69 def len_ne ( value , other ): \"\"\"Length Not equal\"\"\" return len ( str ( value )) != other lt ( value , other ) Lower than Source code in dynaconf\\validator_conditions.py 22 23 24 def lt ( value , other ): \"\"\"Lower than\"\"\" return value < other lte ( value , other ) Lower than or equal Source code in dynaconf\\validator_conditions.py 32 33 34 def lte ( value , other ): \"\"\"Lower than or equal\"\"\" return value <= other ne ( value , other ) Not equal Source code in dynaconf\\validator_conditions.py 12 13 14 def ne ( value , other ): \"\"\"Not equal\"\"\" return value != other","title":"Validator Conditions"},{"location":"modules/validator_conditions/#dynaconf.validator_conditions","text":"Implement basic assertions to be used in assertion action","title":"dynaconf.validator_conditions"},{"location":"modules/validator_conditions/#dynaconf.validator_conditions.cont","text":"Contains Source code in dynaconf\\validator_conditions.py 57 58 59 def cont ( value , other ): \"\"\"Contains\"\"\" return other in value","title":"cont()"},{"location":"modules/validator_conditions/#dynaconf.validator_conditions.eq","text":"Equal Source code in dynaconf\\validator_conditions.py 7 8 9 def eq ( value , other ): \"\"\"Equal\"\"\" return value == other","title":"eq()"},{"location":"modules/validator_conditions/#dynaconf.validator_conditions.gt","text":"Greater than Source code in dynaconf\\validator_conditions.py 17 18 19 def gt ( value , other ): \"\"\"Greater than\"\"\" return value > other","title":"gt()"},{"location":"modules/validator_conditions/#dynaconf.validator_conditions.gte","text":"Greater than or equal Source code in dynaconf\\validator_conditions.py 27 28 29 def gte ( value , other ): \"\"\"Greater than or equal\"\"\" return value >= other","title":"gte()"},{"location":"modules/validator_conditions/#dynaconf.validator_conditions.identity","text":"Identity check using ID Source code in dynaconf\\validator_conditions.py 37 38 39 def identity ( value , other ): \"\"\"Identity check using ID\"\"\" return value is other","title":"identity()"},{"location":"modules/validator_conditions/#dynaconf.validator_conditions.is_in","text":"Existence Source code in dynaconf\\validator_conditions.py 47 48 49 def is_in ( value , other ): \"\"\"Existence\"\"\" return value in other","title":"is_in()"},{"location":"modules/validator_conditions/#dynaconf.validator_conditions.is_not_in","text":"Inexistence Source code in dynaconf\\validator_conditions.py 52 53 54 def is_not_in ( value , other ): \"\"\"Inexistence\"\"\" return value not in other","title":"is_not_in()"},{"location":"modules/validator_conditions/#dynaconf.validator_conditions.is_type_of","text":"Type check Source code in dynaconf\\validator_conditions.py 42 43 44 def is_type_of ( value , other ): \"\"\"Type check\"\"\" return isinstance ( value , other )","title":"is_type_of()"},{"location":"modules/validator_conditions/#dynaconf.validator_conditions.len_eq","text":"Length Equal Source code in dynaconf\\validator_conditions.py 62 63 64 def len_eq ( value , other ): \"\"\"Length Equal\"\"\" return len ( str ( value )) == other","title":"len_eq()"},{"location":"modules/validator_conditions/#dynaconf.validator_conditions.len_max","text":"Maximum lenght Source code in dynaconf\\validator_conditions.py 77 78 79 def len_max ( value , other ): \"\"\"Maximum lenght\"\"\" return len ( str ( value )) < other","title":"len_max()"},{"location":"modules/validator_conditions/#dynaconf.validator_conditions.len_min","text":"Minimum length Source code in dynaconf\\validator_conditions.py 72 73 74 def len_min ( value , other ): \"\"\"Minimum length\"\"\" return len ( str ( value )) > other","title":"len_min()"},{"location":"modules/validator_conditions/#dynaconf.validator_conditions.len_ne","text":"Length Not equal Source code in dynaconf\\validator_conditions.py 67 68 69 def len_ne ( value , other ): \"\"\"Length Not equal\"\"\" return len ( str ( value )) != other","title":"len_ne()"},{"location":"modules/validator_conditions/#dynaconf.validator_conditions.lt","text":"Lower than Source code in dynaconf\\validator_conditions.py 22 23 24 def lt ( value , other ): \"\"\"Lower than\"\"\" return value < other","title":"lt()"},{"location":"modules/validator_conditions/#dynaconf.validator_conditions.lte","text":"Lower than or equal Source code in dynaconf\\validator_conditions.py 32 33 34 def lte ( value , other ): \"\"\"Lower than or equal\"\"\" return value <= other","title":"lte()"},{"location":"modules/validator_conditions/#dynaconf.validator_conditions.ne","text":"Not equal Source code in dynaconf\\validator_conditions.py 12 13 14 def ne ( value , other ): \"\"\"Not equal\"\"\" return value != other","title":"ne()"},{"location":"modules/contrib/flask_dynaconf/","text":"DynaconfConfig Settings load order in Dynaconf: Load all defaults and Flask defaults Load all passed variables when applying FlaskDynaconf Update with data in settings files Update with data in environmente vars ENV_FOR_DYNACONF_ __getattr__ ( self , name ) special First try to get value from dynaconf then from Flask Source code in dynaconf\\contrib\\flask_dynaconf.py 154 155 156 157 158 159 160 161 def __getattr__ ( self , name ): \"\"\" First try to get value from dynaconf then from Flask \"\"\" try : return getattr ( self . _settings , name ) except AttributeError : return self [ name ] __getitem__ ( self , key ) special Flask templates always expects a None when key is not found in config Source code in dynaconf\\contrib\\flask_dynaconf.py 142 143 144 145 146 def __getitem__ ( self , key ): \"\"\" Flask templates always expects a None when key is not found in config \"\"\" return self . get ( key ) __init__ ( self , _settings , _app , * args , ** kwargs ) special perform the initial load Source code in dynaconf\\contrib\\flask_dynaconf.py 135 136 137 138 139 140 def __init__ ( self , _settings , _app , * args , ** kwargs ): \"\"\"perform the initial load\"\"\" super ( DynaconfConfig , self ) . __init__ ( * args , ** kwargs ) Config . update ( self , _settings . store ) self . _settings = _settings self . _app = _app __setitem__ ( self , key , value ) special Allows app.config['key'] = 'foo' Source code in dynaconf\\contrib\\flask_dynaconf.py 148 149 150 151 152 def __setitem__ ( self , key , value ): \"\"\" Allows app.config['key'] = 'foo' \"\"\" return self . _settings . __setitem__ ( key , value ) get ( self , key , default = None ) Gets config from dynaconf variables if variables does not exists in dynaconf try getting from app.config to support runtime settings. Source code in dynaconf\\contrib\\flask_dynaconf.py 166 167 168 169 170 def get ( self , key , default = None ): \"\"\"Gets config from dynaconf variables if variables does not exists in dynaconf try getting from `app.config` to support runtime settings.\"\"\" return self . _settings . get ( key , Config . get ( self , key , default )) load_extensions ( self , key = 'EXTENSIONS' , app = None ) Loads flask extensions dynamically. Source code in dynaconf\\contrib\\flask_dynaconf.py 172 173 174 175 176 177 178 179 180 181 def load_extensions ( self , key = \"EXTENSIONS\" , app = None ): \"\"\"Loads flask extensions dynamically.\"\"\" app = app or self . _app for extension in app . config [ key ]: # Split data in form `extension.path:factory_function` module_name , factory = extension . split ( \":\" ) # Dynamically import extension module. ext = import_module ( module_name ) # Invoke factory passing app. getattr ( ext , factory )( app ) FlaskDynaconf The arguments are. app = The created app dynaconf_args = Extra args to be passed to Dynaconf (validator for example) All other values are stored as config vars specially:: ENVVAR_PREFIX_FOR_DYNACONF = env prefix for your envvars to be loaded !!! example if you set to `MYSITE` then export MYSITE_SQL_PORT='@int 5445' with that exported to env you access using: app.config.SQL_PORT app.config.get('SQL_PORT') app.config.get('sql_port') # get is case insensitive app.config['SQL_PORT'] Dynaconf uses `@int, @bool, @float, @json` to cast env vars SETTINGS_FILE_FOR_DYNACONF = The name of the module or file to use as default to load settings. If nothing is passed it will be `settings.*` or value found in `ENVVAR_FOR_DYNACONF` Dynaconf supports .py, .yml, .toml, ini, json !!! attention \"Take a look at `settings.yml` and `.secrets.yml` to know the\" required settings format. Settings load order in Dynaconf: - Load all defaults and Flask defaults - Load all passed variables when applying FlaskDynaconf - Update with data in settings files - Update with data in environment vars `ENVVAR_FOR_DYNACONF_` TOML files are very useful to have `envd` settings, lets say, `production` and `development`. You can also achieve the same using multiple `.py` files naming as `settings.py`, `production_settings.py` and `development_settings.py` (see examples/validator) Example:: app = Flask(__name__) FlaskDynaconf( app, ENV_FOR_DYNACONF='MYSITE', SETTINGS_FILE_FOR_DYNACONF='settings.yml', EXTRA_VALUE='You can add aditional config vars here' ) Take a look at examples/flask in Dynaconf repository __init__ ( self , app = None , instance_relative_config = False , dynaconf_instance = None , ** kwargs ) special kwargs holds initial dynaconf configuration Source code in dynaconf\\contrib\\flask_dynaconf.py 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 def __init__ ( self , app = None , instance_relative_config = False , dynaconf_instance = None , ** kwargs , ): \"\"\"kwargs holds initial dynaconf configuration\"\"\" if not flask_installed : # pragma: no cover raise RuntimeError ( \"To use this extension Flask must be installed \" \"install it with: pip install flask\" ) self . kwargs = kwargs kwargs . setdefault ( \"ENVVAR_PREFIX_FOR_DYNACONF\" , \"FLASK\" ) env_prefix = f \" { kwargs [ 'ENVVAR_PREFIX_FOR_DYNACONF' ] } _ENV\" # FLASK_ENV kwargs . setdefault ( \"ENV_SWITCHER_FOR_DYNACONF\" , env_prefix ) self . dynaconf_instance = dynaconf_instance self . instance_relative_config = instance_relative_config if app : self . init_app ( app , ** kwargs ) init_app ( self , app , ** kwargs ) kwargs holds initial dynaconf configuration Source code in dynaconf\\contrib\\flask_dynaconf.py 101 102 103 104 105 106 107 108 109 def init_app ( self , app , ** kwargs ): \"\"\"kwargs holds initial dynaconf configuration\"\"\" self . kwargs . update ( kwargs ) self . settings = self . dynaconf_instance or dynaconf . LazySettings ( ** self . kwargs ) dynaconf . settings = self . settings # rebind customized settings app . config = self . make_config ( app ) app . dynaconf = self . settings","title":"Flask dynaconf"},{"location":"modules/contrib/flask_dynaconf/#dynaconf.contrib.flask_dynaconf","text":"","title":"dynaconf.contrib.flask_dynaconf"},{"location":"modules/contrib/flask_dynaconf/#dynaconf.contrib.flask_dynaconf.DynaconfConfig","text":"Settings load order in Dynaconf: Load all defaults and Flask defaults Load all passed variables when applying FlaskDynaconf Update with data in settings files Update with data in environmente vars ENV_FOR_DYNACONF_","title":"DynaconfConfig"},{"location":"modules/contrib/flask_dynaconf/#dynaconf.contrib.flask_dynaconf.DynaconfConfig.__getattr__","text":"First try to get value from dynaconf then from Flask Source code in dynaconf\\contrib\\flask_dynaconf.py 154 155 156 157 158 159 160 161 def __getattr__ ( self , name ): \"\"\" First try to get value from dynaconf then from Flask \"\"\" try : return getattr ( self . _settings , name ) except AttributeError : return self [ name ]","title":"__getattr__()"},{"location":"modules/contrib/flask_dynaconf/#dynaconf.contrib.flask_dynaconf.DynaconfConfig.__getitem__","text":"Flask templates always expects a None when key is not found in config Source code in dynaconf\\contrib\\flask_dynaconf.py 142 143 144 145 146 def __getitem__ ( self , key ): \"\"\" Flask templates always expects a None when key is not found in config \"\"\" return self . get ( key )","title":"__getitem__()"},{"location":"modules/contrib/flask_dynaconf/#dynaconf.contrib.flask_dynaconf.DynaconfConfig.__init__","text":"perform the initial load Source code in dynaconf\\contrib\\flask_dynaconf.py 135 136 137 138 139 140 def __init__ ( self , _settings , _app , * args , ** kwargs ): \"\"\"perform the initial load\"\"\" super ( DynaconfConfig , self ) . __init__ ( * args , ** kwargs ) Config . update ( self , _settings . store ) self . _settings = _settings self . _app = _app","title":"__init__()"},{"location":"modules/contrib/flask_dynaconf/#dynaconf.contrib.flask_dynaconf.DynaconfConfig.__setitem__","text":"Allows app.config['key'] = 'foo' Source code in dynaconf\\contrib\\flask_dynaconf.py 148 149 150 151 152 def __setitem__ ( self , key , value ): \"\"\" Allows app.config['key'] = 'foo' \"\"\" return self . _settings . __setitem__ ( key , value )","title":"__setitem__()"},{"location":"modules/contrib/flask_dynaconf/#dynaconf.contrib.flask_dynaconf.DynaconfConfig.get","text":"Gets config from dynaconf variables if variables does not exists in dynaconf try getting from app.config to support runtime settings. Source code in dynaconf\\contrib\\flask_dynaconf.py 166 167 168 169 170 def get ( self , key , default = None ): \"\"\"Gets config from dynaconf variables if variables does not exists in dynaconf try getting from `app.config` to support runtime settings.\"\"\" return self . _settings . get ( key , Config . get ( self , key , default ))","title":"get()"},{"location":"modules/contrib/flask_dynaconf/#dynaconf.contrib.flask_dynaconf.DynaconfConfig.load_extensions","text":"Loads flask extensions dynamically. Source code in dynaconf\\contrib\\flask_dynaconf.py 172 173 174 175 176 177 178 179 180 181 def load_extensions ( self , key = \"EXTENSIONS\" , app = None ): \"\"\"Loads flask extensions dynamically.\"\"\" app = app or self . _app for extension in app . config [ key ]: # Split data in form `extension.path:factory_function` module_name , factory = extension . split ( \":\" ) # Dynamically import extension module. ext = import_module ( module_name ) # Invoke factory passing app. getattr ( ext , factory )( app )","title":"load_extensions()"},{"location":"modules/contrib/flask_dynaconf/#dynaconf.contrib.flask_dynaconf.FlaskDynaconf","text":"The arguments are. app = The created app dynaconf_args = Extra args to be passed to Dynaconf (validator for example) All other values are stored as config vars specially:: ENVVAR_PREFIX_FOR_DYNACONF = env prefix for your envvars to be loaded !!! example if you set to `MYSITE` then export MYSITE_SQL_PORT='@int 5445' with that exported to env you access using: app.config.SQL_PORT app.config.get('SQL_PORT') app.config.get('sql_port') # get is case insensitive app.config['SQL_PORT'] Dynaconf uses `@int, @bool, @float, @json` to cast env vars SETTINGS_FILE_FOR_DYNACONF = The name of the module or file to use as default to load settings. If nothing is passed it will be `settings.*` or value found in `ENVVAR_FOR_DYNACONF` Dynaconf supports .py, .yml, .toml, ini, json !!! attention \"Take a look at `settings.yml` and `.secrets.yml` to know the\" required settings format. Settings load order in Dynaconf: - Load all defaults and Flask defaults - Load all passed variables when applying FlaskDynaconf - Update with data in settings files - Update with data in environment vars `ENVVAR_FOR_DYNACONF_` TOML files are very useful to have `envd` settings, lets say, `production` and `development`. You can also achieve the same using multiple `.py` files naming as `settings.py`, `production_settings.py` and `development_settings.py` (see examples/validator) Example:: app = Flask(__name__) FlaskDynaconf( app, ENV_FOR_DYNACONF='MYSITE', SETTINGS_FILE_FOR_DYNACONF='settings.yml', EXTRA_VALUE='You can add aditional config vars here' ) Take a look at examples/flask in Dynaconf repository","title":"FlaskDynaconf"},{"location":"modules/contrib/flask_dynaconf/#dynaconf.contrib.flask_dynaconf.FlaskDynaconf.__init__","text":"kwargs holds initial dynaconf configuration Source code in dynaconf\\contrib\\flask_dynaconf.py 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 def __init__ ( self , app = None , instance_relative_config = False , dynaconf_instance = None , ** kwargs , ): \"\"\"kwargs holds initial dynaconf configuration\"\"\" if not flask_installed : # pragma: no cover raise RuntimeError ( \"To use this extension Flask must be installed \" \"install it with: pip install flask\" ) self . kwargs = kwargs kwargs . setdefault ( \"ENVVAR_PREFIX_FOR_DYNACONF\" , \"FLASK\" ) env_prefix = f \" { kwargs [ 'ENVVAR_PREFIX_FOR_DYNACONF' ] } _ENV\" # FLASK_ENV kwargs . setdefault ( \"ENV_SWITCHER_FOR_DYNACONF\" , env_prefix ) self . dynaconf_instance = dynaconf_instance self . instance_relative_config = instance_relative_config if app : self . init_app ( app , ** kwargs )","title":"__init__()"},{"location":"modules/contrib/flask_dynaconf/#dynaconf.contrib.flask_dynaconf.FlaskDynaconf.init_app","text":"kwargs holds initial dynaconf configuration Source code in dynaconf\\contrib\\flask_dynaconf.py 101 102 103 104 105 106 107 108 109 def init_app ( self , app , ** kwargs ): \"\"\"kwargs holds initial dynaconf configuration\"\"\" self . kwargs . update ( kwargs ) self . settings = self . dynaconf_instance or dynaconf . LazySettings ( ** self . kwargs ) dynaconf . settings = self . settings # rebind customized settings app . config = self . make_config ( app ) app . dynaconf = self . settings","title":"init_app()"},{"location":"modules/loaders/base/","text":"BaseLoader Base loader for dynaconf source files. :param obj: {[LazySettings]} -- [Dynaconf settings] :param env: {[string]} -- [the current env to be loaded defaults to [development]] :param identifier: {[string]} -- [identifier ini, yaml, json, py, toml] :param extensions: {[list]} -- [List of extensions with dots ['.a', '.b']] :param file_reader: {[callable]} -- [reads file return dict] :param string_reader: {[callable]} -- [reads string return dict] __init__ ( self , obj , env , identifier , extensions , file_reader , string_reader ) special Instantiates a loader for different sources Source code in dynaconf\\loaders\\base.py 25 26 27 28 29 30 31 32 33 34 def __init__ ( self , obj , env , identifier , extensions , file_reader , string_reader ): \"\"\"Instantiates a loader for different sources\"\"\" self . obj = obj self . env = env or obj . current_env self . identifier = identifier self . extensions = extensions self . file_reader = file_reader self . string_reader = string_reader load ( self , filename = None , key = None , silent = True ) Reads and loads in to self.obj a single key or all keys from source :param filename: Optional filename to load :param key: if provided load a single key :param silent: if load erros should be silenced Source code in dynaconf\\loaders\\base.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 def load ( self , filename = None , key = None , silent = True ): \"\"\" Reads and loads in to `self.obj` a single key or all keys from source :param filename: Optional filename to load :param key: if provided load a single key :param silent: if load erros should be silenced \"\"\" filename = filename or self . obj . get ( self . identifier . upper ()) if not filename : return if not isinstance ( filename , ( list , tuple )): split_files = ensure_a_list ( filename ) if all ([ f . endswith ( self . extensions ) for f in split_files ]): # noqa files = split_files # it is a ['file.ext', ...] else : # it is a single config as string files = [ filename ] else : # it is already a list/tuple files = filename self . obj . _loaded_files . extend ( files ) env_list = build_env_list ( self . obj , self . env ) # load all envs self . _read ( files , env_list , silent , key )","title":"Base"},{"location":"modules/loaders/base/#dynaconf.loaders.base","text":"","title":"dynaconf.loaders.base"},{"location":"modules/loaders/base/#dynaconf.loaders.base.BaseLoader","text":"Base loader for dynaconf source files. :param obj: {[LazySettings]} -- [Dynaconf settings] :param env: {[string]} -- [the current env to be loaded defaults to [development]] :param identifier: {[string]} -- [identifier ini, yaml, json, py, toml] :param extensions: {[list]} -- [List of extensions with dots ['.a', '.b']] :param file_reader: {[callable]} -- [reads file return dict] :param string_reader: {[callable]} -- [reads string return dict]","title":"BaseLoader"},{"location":"modules/loaders/base/#dynaconf.loaders.base.BaseLoader.__init__","text":"Instantiates a loader for different sources Source code in dynaconf\\loaders\\base.py 25 26 27 28 29 30 31 32 33 34 def __init__ ( self , obj , env , identifier , extensions , file_reader , string_reader ): \"\"\"Instantiates a loader for different sources\"\"\" self . obj = obj self . env = env or obj . current_env self . identifier = identifier self . extensions = extensions self . file_reader = file_reader self . string_reader = string_reader","title":"__init__()"},{"location":"modules/loaders/base/#dynaconf.loaders.base.BaseLoader.load","text":"Reads and loads in to self.obj a single key or all keys from source :param filename: Optional filename to load :param key: if provided load a single key :param silent: if load erros should be silenced Source code in dynaconf\\loaders\\base.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 def load ( self , filename = None , key = None , silent = True ): \"\"\" Reads and loads in to `self.obj` a single key or all keys from source :param filename: Optional filename to load :param key: if provided load a single key :param silent: if load erros should be silenced \"\"\" filename = filename or self . obj . get ( self . identifier . upper ()) if not filename : return if not isinstance ( filename , ( list , tuple )): split_files = ensure_a_list ( filename ) if all ([ f . endswith ( self . extensions ) for f in split_files ]): # noqa files = split_files # it is a ['file.ext', ...] else : # it is a single config as string files = [ filename ] else : # it is already a list/tuple files = filename self . obj . _loaded_files . extend ( files ) env_list = build_env_list ( self . obj , self . env ) # load all envs self . _read ( files , env_list , silent , key )","title":"load()"},{"location":"modules/loaders/env_loader/","text":"load ( obj , env = None , silent = True , key = None ) Loads envvars with prefixes: DYNACONF_ (default global) or $(ENVVAR_PREFIX_FOR_DYNACONF)_ Source code in dynaconf\\loaders\\env_loader.py 10 11 12 13 14 15 16 17 18 19 20 def load ( obj , env = None , silent = True , key = None ): \"\"\"Loads envvars with prefixes: `DYNACONF_` (default global) or `$(ENVVAR_PREFIX_FOR_DYNACONF)_` \"\"\" global_env = obj . get ( \"ENVVAR_PREFIX_FOR_DYNACONF\" ) if global_env is False or global_env . upper () != \"DYNACONF\" : load_from_env ( IDENTIFIER + \"_global\" , key , \"DYNACONF\" , obj , silent ) # Load the global env if exists and overwrite everything load_from_env ( IDENTIFIER + \"_global\" , key , global_env , obj , silent ) write ( settings_path , settings_data , ** kwargs ) Write data to .env file Source code in dynaconf\\loaders\\env_loader.py 58 59 60 61 62 63 64 65 66 67 68 69 70 def write ( settings_path , settings_data , ** kwargs ): \"\"\"Write data to .env file\"\"\" for key , value in settings_data . items (): quote_mode = ( isinstance ( value , str ) and ( value . startswith ( \"'\" ) or value . startswith ( '\"' )) ) or isinstance ( value , ( list , dict )) dotenv_cli . set_key ( str ( settings_path ), key , str ( value ), quote_mode = \"always\" if quote_mode else \"none\" , )","title":"env"},{"location":"modules/loaders/env_loader/#dynaconf.loaders.env_loader","text":"","title":"dynaconf.loaders.env_loader"},{"location":"modules/loaders/env_loader/#dynaconf.loaders.env_loader.load","text":"Loads envvars with prefixes: DYNACONF_ (default global) or $(ENVVAR_PREFIX_FOR_DYNACONF)_ Source code in dynaconf\\loaders\\env_loader.py 10 11 12 13 14 15 16 17 18 19 20 def load ( obj , env = None , silent = True , key = None ): \"\"\"Loads envvars with prefixes: `DYNACONF_` (default global) or `$(ENVVAR_PREFIX_FOR_DYNACONF)_` \"\"\" global_env = obj . get ( \"ENVVAR_PREFIX_FOR_DYNACONF\" ) if global_env is False or global_env . upper () != \"DYNACONF\" : load_from_env ( IDENTIFIER + \"_global\" , key , \"DYNACONF\" , obj , silent ) # Load the global env if exists and overwrite everything load_from_env ( IDENTIFIER + \"_global\" , key , global_env , obj , silent )","title":"load()"},{"location":"modules/loaders/env_loader/#dynaconf.loaders.env_loader.write","text":"Write data to .env file Source code in dynaconf\\loaders\\env_loader.py 58 59 60 61 62 63 64 65 66 67 68 69 70 def write ( settings_path , settings_data , ** kwargs ): \"\"\"Write data to .env file\"\"\" for key , value in settings_data . items (): quote_mode = ( isinstance ( value , str ) and ( value . startswith ( \"'\" ) or value . startswith ( '\"' )) ) or isinstance ( value , ( list , dict )) dotenv_cli . set_key ( str ( settings_path ), key , str ( value ), quote_mode = \"always\" if quote_mode else \"none\" , )","title":"write()"},{"location":"modules/loaders/ini_loader/","text":"load ( obj , env = None , silent = True , key = None , filename = None ) Reads and loads in to \"obj\" a single key or all keys from source file. :param obj: the settings instance :param env: settings current env default='development' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :param filename: Optional custom filename to load :return: None Source code in dynaconf\\loaders\\ini_loader.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def load ( obj , env = None , silent = True , key = None , filename = None ): \"\"\" Reads and loads in to \"obj\" a single key or all keys from source file. :param obj: the settings instance :param env: settings current env default='development' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :param filename: Optional custom filename to load :return: None \"\"\" if ConfigObj is None : # pragma: no cover BaseLoader . warn_not_installed ( obj , \"ini\" ) return loader = BaseLoader ( obj = obj , env = env , identifier = \"ini\" , extensions = INI_EXTENSIONS , file_reader = lambda fileobj : ConfigObj ( fileobj ) . dict (), string_reader = lambda strobj : ConfigObj ( strobj . split ( \" \\n \" )) . dict (), ) loader . load ( filename = filename , key = key , silent = silent ) write ( settings_path , settings_data , merge = True ) Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data Source code in dynaconf\\loaders\\ini_loader.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 def write ( settings_path , settings_data , merge = True ): \"\"\"Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data \"\"\" settings_path = Path ( settings_path ) if settings_path . exists () and merge : # pragma: no cover with io . open ( str ( settings_path ), encoding = default_settings . ENCODING_FOR_DYNACONF ) as open_file : object_merge ( ConfigObj ( open_file ) . dict (), settings_data ) new = ConfigObj () new . update ( settings_data ) new . write ( open ( str ( settings_path ), \"bw\" ))","title":"ini"},{"location":"modules/loaders/ini_loader/#dynaconf.loaders.ini_loader","text":"","title":"dynaconf.loaders.ini_loader"},{"location":"modules/loaders/ini_loader/#dynaconf.loaders.ini_loader.load","text":"Reads and loads in to \"obj\" a single key or all keys from source file. :param obj: the settings instance :param env: settings current env default='development' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :param filename: Optional custom filename to load :return: None Source code in dynaconf\\loaders\\ini_loader.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def load ( obj , env = None , silent = True , key = None , filename = None ): \"\"\" Reads and loads in to \"obj\" a single key or all keys from source file. :param obj: the settings instance :param env: settings current env default='development' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :param filename: Optional custom filename to load :return: None \"\"\" if ConfigObj is None : # pragma: no cover BaseLoader . warn_not_installed ( obj , \"ini\" ) return loader = BaseLoader ( obj = obj , env = env , identifier = \"ini\" , extensions = INI_EXTENSIONS , file_reader = lambda fileobj : ConfigObj ( fileobj ) . dict (), string_reader = lambda strobj : ConfigObj ( strobj . split ( \" \\n \" )) . dict (), ) loader . load ( filename = filename , key = key , silent = silent )","title":"load()"},{"location":"modules/loaders/ini_loader/#dynaconf.loaders.ini_loader.write","text":"Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data Source code in dynaconf\\loaders\\ini_loader.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 def write ( settings_path , settings_data , merge = True ): \"\"\"Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data \"\"\" settings_path = Path ( settings_path ) if settings_path . exists () and merge : # pragma: no cover with io . open ( str ( settings_path ), encoding = default_settings . ENCODING_FOR_DYNACONF ) as open_file : object_merge ( ConfigObj ( open_file ) . dict (), settings_data ) new = ConfigObj () new . update ( settings_data ) new . write ( open ( str ( settings_path ), \"bw\" ))","title":"write()"},{"location":"modules/loaders/json_loader/","text":"DynaconfEncoder Transform Dynaconf custom types instances to json representation default ( self , o ) Implement this method in a subclass such that it returns a serializable object for o , or calls the base implementation (to raise a TypeError ). For example, to support arbitrary iterators, you could implement default like this:: def default(self, o): !!! try iterable = iter(o) except TypeError: pass !!! else return list(iterable) # Let the base class default method raise the TypeError return JSONEncoder.default(self, o) Source code in dynaconf\\loaders\\json_loader.py 73 74 def default ( self , o ): return try_to_encode ( o , callback = super () . default ) load ( obj , env = None , silent = True , key = None , filename = None ) Reads and loads in to \"obj\" a single key or all keys from source file. :param obj: the settings instance :param env: settings current env default='development' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :param filename: Optional custom filename to load :return: None Source code in dynaconf\\loaders\\json_loader.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def load ( obj , env = None , silent = True , key = None , filename = None ): \"\"\" Reads and loads in to \"obj\" a single key or all keys from source file. :param obj: the settings instance :param env: settings current env default='development' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :param filename: Optional custom filename to load :return: None \"\"\" if ( obj . get ( \"COMMENTJSON_ENABLED_FOR_DYNACONF\" ) and commentjson ): # pragma: no cover # noqa file_reader = commentjson . load string_reader = commentjson . loads else : file_reader = json . load string_reader = json . loads loader = BaseLoader ( obj = obj , env = env , identifier = \"json\" , extensions = JSON_EXTENSIONS , file_reader = file_reader , string_reader = string_reader , ) loader . load ( filename = filename , key = key , silent = silent ) write ( settings_path , settings_data , merge = True ) Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data Source code in dynaconf\\loaders\\json_loader.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def write ( settings_path , settings_data , merge = True ): \"\"\"Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data \"\"\" settings_path = Path ( settings_path ) if settings_path . exists () and merge : # pragma: no cover with io . open ( str ( settings_path ), encoding = default_settings . ENCODING_FOR_DYNACONF ) as open_file : object_merge ( json . load ( open_file ), settings_data ) with io . open ( str ( settings_path ), \"w\" , encoding = default_settings . ENCODING_FOR_DYNACONF , ) as open_file : json . dump ( settings_data , open_file , cls = DynaconfEncoder )","title":"json"},{"location":"modules/loaders/json_loader/#dynaconf.loaders.json_loader","text":"","title":"dynaconf.loaders.json_loader"},{"location":"modules/loaders/json_loader/#dynaconf.loaders.json_loader.DynaconfEncoder","text":"Transform Dynaconf custom types instances to json representation","title":"DynaconfEncoder"},{"location":"modules/loaders/json_loader/#dynaconf.loaders.json_loader.DynaconfEncoder.default","text":"Implement this method in a subclass such that it returns a serializable object for o , or calls the base implementation (to raise a TypeError ). For example, to support arbitrary iterators, you could implement default like this:: def default(self, o): !!! try iterable = iter(o) except TypeError: pass !!! else return list(iterable) # Let the base class default method raise the TypeError return JSONEncoder.default(self, o) Source code in dynaconf\\loaders\\json_loader.py 73 74 def default ( self , o ): return try_to_encode ( o , callback = super () . default )","title":"default()"},{"location":"modules/loaders/json_loader/#dynaconf.loaders.json_loader.load","text":"Reads and loads in to \"obj\" a single key or all keys from source file. :param obj: the settings instance :param env: settings current env default='development' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :param filename: Optional custom filename to load :return: None Source code in dynaconf\\loaders\\json_loader.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def load ( obj , env = None , silent = True , key = None , filename = None ): \"\"\" Reads and loads in to \"obj\" a single key or all keys from source file. :param obj: the settings instance :param env: settings current env default='development' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :param filename: Optional custom filename to load :return: None \"\"\" if ( obj . get ( \"COMMENTJSON_ENABLED_FOR_DYNACONF\" ) and commentjson ): # pragma: no cover # noqa file_reader = commentjson . load string_reader = commentjson . loads else : file_reader = json . load string_reader = json . loads loader = BaseLoader ( obj = obj , env = env , identifier = \"json\" , extensions = JSON_EXTENSIONS , file_reader = file_reader , string_reader = string_reader , ) loader . load ( filename = filename , key = key , silent = silent )","title":"load()"},{"location":"modules/loaders/json_loader/#dynaconf.loaders.json_loader.write","text":"Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data Source code in dynaconf\\loaders\\json_loader.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def write ( settings_path , settings_data , merge = True ): \"\"\"Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data \"\"\" settings_path = Path ( settings_path ) if settings_path . exists () and merge : # pragma: no cover with io . open ( str ( settings_path ), encoding = default_settings . ENCODING_FOR_DYNACONF ) as open_file : object_merge ( json . load ( open_file ), settings_data ) with io . open ( str ( settings_path ), \"w\" , encoding = default_settings . ENCODING_FOR_DYNACONF , ) as open_file : json . dump ( settings_data , open_file , cls = DynaconfEncoder )","title":"write()"},{"location":"modules/loaders/py_loader/","text":"import_from_filename ( obj , filename , silent = False ) If settings_module is a filename path import it. Source code in dynaconf\\loaders\\py_loader.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 def import_from_filename ( obj , filename , silent = False ): # pragma: no cover \"\"\"If settings_module is a filename path import it.\"\"\" if filename in [ item . filename for item in inspect . stack ()]: raise ImportError ( \"Looks like you are loading dynaconf \" f \"from inside the { filename } file and then it is trying \" \"to load itself entering in a circular reference \" \"problem. To solve it you have to \" \"invoke your program from another root folder \" \"or rename your program file.\" ) _find_file = getattr ( obj , \"find_file\" , find_file ) if not filename . endswith ( \".py\" ): filename = f \" { filename } .py\" if filename in default_settings . SETTINGS_FILE_FOR_DYNACONF : silent = True mod = types . ModuleType ( filename . rstrip ( \".py\" )) mod . __file__ = filename mod . _is_error = False try : with io . open ( _find_file ( filename ), encoding = default_settings . ENCODING_FOR_DYNACONF , ) as config_file : exec ( compile ( config_file . read (), filename , \"exec\" ), mod . __dict__ ) except IOError as e : e . strerror = ( f \"py_loader: error loading file \" f \"( { e . strerror } { filename } ) \\n \" ) if silent and e . errno in ( errno . ENOENT , errno . EISDIR ): return raw_logger () . debug ( e . strerror ) mod . _is_error = True return mod load ( obj , settings_module , identifier = 'py' , silent = False , key = None ) Tries to import a python module Source code in dynaconf\\loaders\\py_loader.py 17 18 19 20 21 22 23 24 25 26 27 def load ( obj , settings_module , identifier = \"py\" , silent = False , key = None ): \"\"\"Tries to import a python module\"\"\" mod , loaded_from = get_module ( obj , settings_module , silent ) if mod and loaded_from : obj . logger . debug ( f \"py_loader: { mod } \" ) else : obj . logger . debug ( f \"py_loader: { settings_module } (Ignoring, Not Found)\" ) return load_from_python_object ( obj , mod , settings_module , key , identifier ) try_to_load_from_py_module_name ( obj , name , key = None , identifier = 'py' , silent = False ) Try to load module by its string name. Arguments:: obj {LAzySettings} -- Dynaconf settings instance name {str} -- Name of the module e.g: foo.bar.zaz Keyword Arguments:: key {str} -- Single key to be loaded (default: {None}) identifier {str} -- Name of identifier to store (default: 'py') silent {bool} -- Weather to raise or silence exceptions. Source code in dynaconf\\loaders\\py_loader.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def try_to_load_from_py_module_name ( obj , name , key = None , identifier = \"py\" , silent = False ): \"\"\"Try to load module by its string name. Arguments:: obj {LAzySettings} -- Dynaconf settings instance name {str} -- Name of the module e.g: foo.bar.zaz Keyword Arguments:: key {str} -- Single key to be loaded (default: {None}) identifier {str} -- Name of identifier to store (default: 'py') silent {bool} -- Weather to raise or silence exceptions. \"\"\" ctx = suppress ( ImportError , TypeError ) if silent else suppress () with ctx : mod = importlib . import_module ( name ) load_from_python_object ( obj , mod , name , key , identifier ) return True # loaded ok! # if it reaches this point that means exception occurred, module not found. return False write ( settings_path , settings_data , merge = True ) Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data Source code in dynaconf\\loaders\\py_loader.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 def write ( settings_path , settings_data , merge = True ): \"\"\"Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data \"\"\" settings_path = Path ( settings_path ) if settings_path . exists () and merge : # pragma: no cover existing = DynaconfDict () load ( existing , str ( settings_path )) object_merge ( existing , settings_data ) with io . open ( str ( settings_path ), \"w\" , encoding = default_settings . ENCODING_FOR_DYNACONF , ) as f : f . writelines ( [ f \" { upperfy ( k ) } = { repr ( v ) } \\n \" for k , v in settings_data . items ()] )","title":"py"},{"location":"modules/loaders/py_loader/#dynaconf.loaders.py_loader","text":"","title":"dynaconf.loaders.py_loader"},{"location":"modules/loaders/py_loader/#dynaconf.loaders.py_loader.import_from_filename","text":"If settings_module is a filename path import it. Source code in dynaconf\\loaders\\py_loader.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 def import_from_filename ( obj , filename , silent = False ): # pragma: no cover \"\"\"If settings_module is a filename path import it.\"\"\" if filename in [ item . filename for item in inspect . stack ()]: raise ImportError ( \"Looks like you are loading dynaconf \" f \"from inside the { filename } file and then it is trying \" \"to load itself entering in a circular reference \" \"problem. To solve it you have to \" \"invoke your program from another root folder \" \"or rename your program file.\" ) _find_file = getattr ( obj , \"find_file\" , find_file ) if not filename . endswith ( \".py\" ): filename = f \" { filename } .py\" if filename in default_settings . SETTINGS_FILE_FOR_DYNACONF : silent = True mod = types . ModuleType ( filename . rstrip ( \".py\" )) mod . __file__ = filename mod . _is_error = False try : with io . open ( _find_file ( filename ), encoding = default_settings . ENCODING_FOR_DYNACONF , ) as config_file : exec ( compile ( config_file . read (), filename , \"exec\" ), mod . __dict__ ) except IOError as e : e . strerror = ( f \"py_loader: error loading file \" f \"( { e . strerror } { filename } ) \\n \" ) if silent and e . errno in ( errno . ENOENT , errno . EISDIR ): return raw_logger () . debug ( e . strerror ) mod . _is_error = True return mod","title":"import_from_filename()"},{"location":"modules/loaders/py_loader/#dynaconf.loaders.py_loader.load","text":"Tries to import a python module Source code in dynaconf\\loaders\\py_loader.py 17 18 19 20 21 22 23 24 25 26 27 def load ( obj , settings_module , identifier = \"py\" , silent = False , key = None ): \"\"\"Tries to import a python module\"\"\" mod , loaded_from = get_module ( obj , settings_module , silent ) if mod and loaded_from : obj . logger . debug ( f \"py_loader: { mod } \" ) else : obj . logger . debug ( f \"py_loader: { settings_module } (Ignoring, Not Found)\" ) return load_from_python_object ( obj , mod , settings_module , key , identifier )","title":"load()"},{"location":"modules/loaders/py_loader/#dynaconf.loaders.py_loader.try_to_load_from_py_module_name","text":"Try to load module by its string name. Arguments:: obj {LAzySettings} -- Dynaconf settings instance name {str} -- Name of the module e.g: foo.bar.zaz Keyword Arguments:: key {str} -- Single key to be loaded (default: {None}) identifier {str} -- Name of identifier to store (default: 'py') silent {bool} -- Weather to raise or silence exceptions. Source code in dynaconf\\loaders\\py_loader.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def try_to_load_from_py_module_name ( obj , name , key = None , identifier = \"py\" , silent = False ): \"\"\"Try to load module by its string name. Arguments:: obj {LAzySettings} -- Dynaconf settings instance name {str} -- Name of the module e.g: foo.bar.zaz Keyword Arguments:: key {str} -- Single key to be loaded (default: {None}) identifier {str} -- Name of identifier to store (default: 'py') silent {bool} -- Weather to raise or silence exceptions. \"\"\" ctx = suppress ( ImportError , TypeError ) if silent else suppress () with ctx : mod = importlib . import_module ( name ) load_from_python_object ( obj , mod , name , key , identifier ) return True # loaded ok! # if it reaches this point that means exception occurred, module not found. return False","title":"try_to_load_from_py_module_name()"},{"location":"modules/loaders/py_loader/#dynaconf.loaders.py_loader.write","text":"Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data Source code in dynaconf\\loaders\\py_loader.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 def write ( settings_path , settings_data , merge = True ): \"\"\"Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data \"\"\" settings_path = Path ( settings_path ) if settings_path . exists () and merge : # pragma: no cover existing = DynaconfDict () load ( existing , str ( settings_path )) object_merge ( existing , settings_data ) with io . open ( str ( settings_path ), \"w\" , encoding = default_settings . ENCODING_FOR_DYNACONF , ) as f : f . writelines ( [ f \" { upperfy ( k ) } = { repr ( v ) } \\n \" for k , v in settings_data . items ()] )","title":"write()"},{"location":"modules/loaders/redis_loader/","text":"delete ( obj , key = None ) Delete a single key if specified, or all env if key is none :param obj: settings object :param key: key to delete from store location :return: None Source code in dynaconf\\loaders\\redis_loader.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def delete ( obj , key = None ): \"\"\" Delete a single key if specified, or all env if key is none :param obj: settings object :param key: key to delete from store location :return: None \"\"\" client = StrictRedis ( ** obj . REDIS_FOR_DYNACONF ) holder = obj . get ( \"ENVVAR_PREFIX_FOR_DYNACONF\" ) . upper () # add env to holder holder = f \" { holder } _ { obj . current_env . upper () } \" if key : client . hdel ( holder . upper (), upperfy ( key )) obj . unset ( key ) else : keys = client . hkeys ( holder . upper ()) client . delete ( holder . upper ()) obj . unset_all ( keys ) load ( obj , env = None , silent = True , key = None ) Reads and loads in to \"settings\" a single key or all keys from redis :param obj: the settings instance :param env: settings env default='DYNACONF' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :return: None Source code in dynaconf\\loaders\\redis_loader.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def load ( obj , env = None , silent = True , key = None ): \"\"\"Reads and loads in to \"settings\" a single key or all keys from redis :param obj: the settings instance :param env: settings env default='DYNACONF' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :return: None \"\"\" redis = StrictRedis ( ** obj . get ( \"REDIS_FOR_DYNACONF\" )) prefix = obj . get ( \"ENVVAR_PREFIX_FOR_DYNACONF\" ) # prefix is added to env_list to keep backwards compatibility env_list = [ prefix ] + build_env_list ( obj , env or obj . current_env ) for env_name in env_list : holder = f \" { prefix . upper () } _ { env_name . upper () } \" try : if key : value = redis . hget ( holder . upper (), key ) if value : obj . logger . debug ( f \"redis_loader: loading by key: { key } : { value } \" f \"( { IDENTIFIER } : { holder } )\" ) if value : parsed_value = parse_conf_data ( value , tomlfy = True ) if parsed_value : obj . set ( key , parsed_value ) else : data = { key : parse_conf_data ( value , tomlfy = True ) for key , value in redis . hgetall ( holder . upper ()) . items () } if data : obj . logger . debug ( f \"redis_loader: loading: { data } ( { IDENTIFIER } :\" f \" { holder } )\" ) obj . update ( data , loader_identifier = IDENTIFIER ) except Exception as e : if silent : if hasattr ( obj , \"logger\" ): obj . logger . error ( str ( e )) return False raise write ( obj , data = None , ** kwargs ) Write a value in to loader source :param obj: settings object :param data: vars to be stored :param kwargs: vars to be stored :return: Source code in dynaconf\\loaders\\redis_loader.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 def write ( obj , data = None , ** kwargs ): \"\"\"Write a value in to loader source :param obj: settings object :param data: vars to be stored :param kwargs: vars to be stored :return: \"\"\" if obj . REDIS_ENABLED_FOR_DYNACONF is False : raise RuntimeError ( \"Redis is not configured \\n \" \"export REDIS_ENABLED_FOR_DYNACONF=true \\n \" \"and configure the REDIS_FOR_DYNACONF_* variables\" ) client = StrictRedis ( ** obj . REDIS_FOR_DYNACONF ) holder = obj . get ( \"ENVVAR_PREFIX_FOR_DYNACONF\" ) . upper () # add env to holder holder = f \" { holder } _ { obj . current_env . upper () } \" data = data or {} data . update ( kwargs ) if not data : raise AttributeError ( \"Data must be provided\" ) redis_data = { upperfy ( key ): unparse_conf_data ( value ) for key , value in data . items () } client . hmset ( holder . upper (), redis_data ) load ( obj )","title":"redis"},{"location":"modules/loaders/redis_loader/#dynaconf.loaders.redis_loader","text":"","title":"dynaconf.loaders.redis_loader"},{"location":"modules/loaders/redis_loader/#dynaconf.loaders.redis_loader.delete","text":"Delete a single key if specified, or all env if key is none :param obj: settings object :param key: key to delete from store location :return: None Source code in dynaconf\\loaders\\redis_loader.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def delete ( obj , key = None ): \"\"\" Delete a single key if specified, or all env if key is none :param obj: settings object :param key: key to delete from store location :return: None \"\"\" client = StrictRedis ( ** obj . REDIS_FOR_DYNACONF ) holder = obj . get ( \"ENVVAR_PREFIX_FOR_DYNACONF\" ) . upper () # add env to holder holder = f \" { holder } _ { obj . current_env . upper () } \" if key : client . hdel ( holder . upper (), upperfy ( key )) obj . unset ( key ) else : keys = client . hkeys ( holder . upper ()) client . delete ( holder . upper ()) obj . unset_all ( keys )","title":"delete()"},{"location":"modules/loaders/redis_loader/#dynaconf.loaders.redis_loader.load","text":"Reads and loads in to \"settings\" a single key or all keys from redis :param obj: the settings instance :param env: settings env default='DYNACONF' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :return: None Source code in dynaconf\\loaders\\redis_loader.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def load ( obj , env = None , silent = True , key = None ): \"\"\"Reads and loads in to \"settings\" a single key or all keys from redis :param obj: the settings instance :param env: settings env default='DYNACONF' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :return: None \"\"\" redis = StrictRedis ( ** obj . get ( \"REDIS_FOR_DYNACONF\" )) prefix = obj . get ( \"ENVVAR_PREFIX_FOR_DYNACONF\" ) # prefix is added to env_list to keep backwards compatibility env_list = [ prefix ] + build_env_list ( obj , env or obj . current_env ) for env_name in env_list : holder = f \" { prefix . upper () } _ { env_name . upper () } \" try : if key : value = redis . hget ( holder . upper (), key ) if value : obj . logger . debug ( f \"redis_loader: loading by key: { key } : { value } \" f \"( { IDENTIFIER } : { holder } )\" ) if value : parsed_value = parse_conf_data ( value , tomlfy = True ) if parsed_value : obj . set ( key , parsed_value ) else : data = { key : parse_conf_data ( value , tomlfy = True ) for key , value in redis . hgetall ( holder . upper ()) . items () } if data : obj . logger . debug ( f \"redis_loader: loading: { data } ( { IDENTIFIER } :\" f \" { holder } )\" ) obj . update ( data , loader_identifier = IDENTIFIER ) except Exception as e : if silent : if hasattr ( obj , \"logger\" ): obj . logger . error ( str ( e )) return False raise","title":"load()"},{"location":"modules/loaders/redis_loader/#dynaconf.loaders.redis_loader.write","text":"Write a value in to loader source :param obj: settings object :param data: vars to be stored :param kwargs: vars to be stored :return: Source code in dynaconf\\loaders\\redis_loader.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 def write ( obj , data = None , ** kwargs ): \"\"\"Write a value in to loader source :param obj: settings object :param data: vars to be stored :param kwargs: vars to be stored :return: \"\"\" if obj . REDIS_ENABLED_FOR_DYNACONF is False : raise RuntimeError ( \"Redis is not configured \\n \" \"export REDIS_ENABLED_FOR_DYNACONF=true \\n \" \"and configure the REDIS_FOR_DYNACONF_* variables\" ) client = StrictRedis ( ** obj . REDIS_FOR_DYNACONF ) holder = obj . get ( \"ENVVAR_PREFIX_FOR_DYNACONF\" ) . upper () # add env to holder holder = f \" { holder } _ { obj . current_env . upper () } \" data = data or {} data . update ( kwargs ) if not data : raise AttributeError ( \"Data must be provided\" ) redis_data = { upperfy ( key ): unparse_conf_data ( value ) for key , value in data . items () } client . hmset ( holder . upper (), redis_data ) load ( obj )","title":"write()"},{"location":"modules/loaders/toml_loader/","text":"encode_nulls ( data ) TOML does not support None so this function transforms to '@none '. Source code in dynaconf\\loaders\\toml_loader.py 63 64 65 66 67 68 69 70 71 def encode_nulls ( data ): \"\"\"TOML does not support `None` so this function transforms to '@none '.\"\"\" if data is None : return \"@none \" if isinstance ( data , dict ): return { key : encode_nulls ( value ) for key , value in data . items ()} elif isinstance ( data , ( list , tuple )): return [ encode_nulls ( item ) for item in data ] return data load ( obj , env = None , silent = True , key = None , filename = None ) Reads and loads in to \"obj\" a single key or all keys from source file. :param obj: the settings instance :param env: settings current env default='development' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :param filename: Optional custom filename to load :return: None Source code in dynaconf\\loaders\\toml_loader.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def load ( obj , env = None , silent = True , key = None , filename = None ): \"\"\" Reads and loads in to \"obj\" a single key or all keys from source file. :param obj: the settings instance :param env: settings current env default='development' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :param filename: Optional custom filename to load :return: None \"\"\" if toml is None : # pragma: no cover BaseLoader . warn_not_installed ( obj , \"toml\" ) return loader = BaseLoader ( obj = obj , env = env , identifier = \"toml\" , extensions = TOML_EXTENSIONS , file_reader = toml . load , string_reader = toml . loads , ) loader . load ( filename = filename , key = key , silent = silent ) write ( settings_path , settings_data , merge = True ) Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data Source code in dynaconf\\loaders\\toml_loader.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def write ( settings_path , settings_data , merge = True ): \"\"\"Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data \"\"\" settings_path = Path ( settings_path ) if settings_path . exists () and merge : # pragma: no cover with io . open ( str ( settings_path ), encoding = default_settings . ENCODING_FOR_DYNACONF ) as open_file : object_merge ( toml . load ( open_file ), settings_data ) with io . open ( str ( settings_path ), \"w\" , encoding = default_settings . ENCODING_FOR_DYNACONF , ) as open_file : toml . dump ( encode_nulls ( settings_data ), open_file )","title":"toml"},{"location":"modules/loaders/toml_loader/#dynaconf.loaders.toml_loader","text":"","title":"dynaconf.loaders.toml_loader"},{"location":"modules/loaders/toml_loader/#dynaconf.loaders.toml_loader.encode_nulls","text":"TOML does not support None so this function transforms to '@none '. Source code in dynaconf\\loaders\\toml_loader.py 63 64 65 66 67 68 69 70 71 def encode_nulls ( data ): \"\"\"TOML does not support `None` so this function transforms to '@none '.\"\"\" if data is None : return \"@none \" if isinstance ( data , dict ): return { key : encode_nulls ( value ) for key , value in data . items ()} elif isinstance ( data , ( list , tuple )): return [ encode_nulls ( item ) for item in data ] return data","title":"encode_nulls()"},{"location":"modules/loaders/toml_loader/#dynaconf.loaders.toml_loader.load","text":"Reads and loads in to \"obj\" a single key or all keys from source file. :param obj: the settings instance :param env: settings current env default='development' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :param filename: Optional custom filename to load :return: None Source code in dynaconf\\loaders\\toml_loader.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def load ( obj , env = None , silent = True , key = None , filename = None ): \"\"\" Reads and loads in to \"obj\" a single key or all keys from source file. :param obj: the settings instance :param env: settings current env default='development' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :param filename: Optional custom filename to load :return: None \"\"\" if toml is None : # pragma: no cover BaseLoader . warn_not_installed ( obj , \"toml\" ) return loader = BaseLoader ( obj = obj , env = env , identifier = \"toml\" , extensions = TOML_EXTENSIONS , file_reader = toml . load , string_reader = toml . loads , ) loader . load ( filename = filename , key = key , silent = silent )","title":"load()"},{"location":"modules/loaders/toml_loader/#dynaconf.loaders.toml_loader.write","text":"Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data Source code in dynaconf\\loaders\\toml_loader.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def write ( settings_path , settings_data , merge = True ): \"\"\"Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data \"\"\" settings_path = Path ( settings_path ) if settings_path . exists () and merge : # pragma: no cover with io . open ( str ( settings_path ), encoding = default_settings . ENCODING_FOR_DYNACONF ) as open_file : object_merge ( toml . load ( open_file ), settings_data ) with io . open ( str ( settings_path ), \"w\" , encoding = default_settings . ENCODING_FOR_DYNACONF , ) as open_file : toml . dump ( encode_nulls ( settings_data ), open_file )","title":"write()"},{"location":"modules/loaders/vault_loader/","text":"list_envs ( obj , path = '' ) This function is a helper to get a list of all the existing envs in the source of data, the use case is: existing_envs = vault_loader.list_envs(settings) for env in exiting_envs: with settings.using_env(env): # switch to the env # do something with a key of that env :param obj: settings object :param path: path to the vault secrets :return: list containing all the keys at the given path Source code in dynaconf\\loaders\\vault_loader.py 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 def list_envs ( obj , path = \"\" ): \"\"\" This function is a helper to get a list of all the existing envs in the source of data, the use case is: existing_envs = vault_loader.list_envs(settings) for env in exiting_envs: with settings.using_env(env): # switch to the env # do something with a key of that env :param obj: settings object :param path: path to the vault secrets :return: list containing all the keys at the given path \"\"\" client = get_client ( obj ) path = path or obj . get ( \"VAULT_PATH_FOR_DYNACONF\" ) try : return client . list ( f \"/secret/metadata/ { path } \" )[ \"data\" ][ \"keys\" ] except TypeError : return [] load ( obj , env = None , silent = None , key = None ) Reads and loads in to \"settings\" a single key or all keys from vault :param obj: the settings instance :param env: settings env default='DYNACONF' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :return: None Source code in dynaconf\\loaders\\vault_loader.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def load ( obj , env = None , silent = None , key = None ): \"\"\"Reads and loads in to \"settings\" a single key or all keys from vault :param obj: the settings instance :param env: settings env default='DYNACONF' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :return: None \"\"\" client = get_client ( obj ) env_list = build_env_list ( obj , env ) for env in env_list : path = \"/\" . join ([ obj . VAULT_PATH_FOR_DYNACONF , env ]) try : data = client . secrets . kv . read_secret_version ( path ) except InvalidPath : # If the path doesn't exist, ignore it and set data to None data = None if data : # There seems to be a data dict within a data dict, # extract the inner data data = data . get ( \"data\" , {}) . get ( \"data\" , {}) try : if data and key : value = parse_conf_data ( data . get ( key ), tomlfy = True ) if value : obj . logger . debug ( f \"vault_loader: loading by key: { key } :****\" f \"( { IDENTIFIER } : { path } )\" ) obj . set ( key , value ) elif data : obj . logger . debug ( f \"vault_loader: loading: { list ( data . keys ()) } \" f \"( { IDENTIFIER } : { path } )\" , ) obj . update ( data , loader_identifier = IDENTIFIER , tomlfy = True ) except Exception as e : if silent : if hasattr ( obj , \"logger\" ): obj . logger . error ( str ( e )) return False raise write ( obj , data = None , ** kwargs ) Write a value in to loader source :param obj: settings object :param data: vars to be stored :param kwargs: vars to be stored :return: Source code in dynaconf\\loaders\\vault_loader.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 def write ( obj , data = None , ** kwargs ): \"\"\"Write a value in to loader source :param obj: settings object :param data: vars to be stored :param kwargs: vars to be stored :return: \"\"\" if obj . VAULT_ENABLED_FOR_DYNACONF is False : raise RuntimeError ( \"Vault is not configured \\n \" \"export VAULT_ENABLED_FOR_DYNACONF=true \\n \" \"and configure the VAULT_FOR_DYNACONF_* variables\" ) data = data or {} data . update ( kwargs ) if not data : raise AttributeError ( \"Data must be provided\" ) client = get_client ( obj ) path = \"/\" . join ([ obj . VAULT_PATH_FOR_DYNACONF , obj . current_env . lower ()]) client . secrets . kv . create_or_update_secret ( path , secret = data ) load ( obj )","title":"vault"},{"location":"modules/loaders/vault_loader/#dynaconf.loaders.vault_loader","text":"","title":"dynaconf.loaders.vault_loader"},{"location":"modules/loaders/vault_loader/#dynaconf.loaders.vault_loader.list_envs","text":"This function is a helper to get a list of all the existing envs in the source of data, the use case is: existing_envs = vault_loader.list_envs(settings) for env in exiting_envs: with settings.using_env(env): # switch to the env # do something with a key of that env :param obj: settings object :param path: path to the vault secrets :return: list containing all the keys at the given path Source code in dynaconf\\loaders\\vault_loader.py 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 def list_envs ( obj , path = \"\" ): \"\"\" This function is a helper to get a list of all the existing envs in the source of data, the use case is: existing_envs = vault_loader.list_envs(settings) for env in exiting_envs: with settings.using_env(env): # switch to the env # do something with a key of that env :param obj: settings object :param path: path to the vault secrets :return: list containing all the keys at the given path \"\"\" client = get_client ( obj ) path = path or obj . get ( \"VAULT_PATH_FOR_DYNACONF\" ) try : return client . list ( f \"/secret/metadata/ { path } \" )[ \"data\" ][ \"keys\" ] except TypeError : return []","title":"list_envs()"},{"location":"modules/loaders/vault_loader/#dynaconf.loaders.vault_loader.load","text":"Reads and loads in to \"settings\" a single key or all keys from vault :param obj: the settings instance :param env: settings env default='DYNACONF' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :return: None Source code in dynaconf\\loaders\\vault_loader.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def load ( obj , env = None , silent = None , key = None ): \"\"\"Reads and loads in to \"settings\" a single key or all keys from vault :param obj: the settings instance :param env: settings env default='DYNACONF' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :return: None \"\"\" client = get_client ( obj ) env_list = build_env_list ( obj , env ) for env in env_list : path = \"/\" . join ([ obj . VAULT_PATH_FOR_DYNACONF , env ]) try : data = client . secrets . kv . read_secret_version ( path ) except InvalidPath : # If the path doesn't exist, ignore it and set data to None data = None if data : # There seems to be a data dict within a data dict, # extract the inner data data = data . get ( \"data\" , {}) . get ( \"data\" , {}) try : if data and key : value = parse_conf_data ( data . get ( key ), tomlfy = True ) if value : obj . logger . debug ( f \"vault_loader: loading by key: { key } :****\" f \"( { IDENTIFIER } : { path } )\" ) obj . set ( key , value ) elif data : obj . logger . debug ( f \"vault_loader: loading: { list ( data . keys ()) } \" f \"( { IDENTIFIER } : { path } )\" , ) obj . update ( data , loader_identifier = IDENTIFIER , tomlfy = True ) except Exception as e : if silent : if hasattr ( obj , \"logger\" ): obj . logger . error ( str ( e )) return False raise","title":"load()"},{"location":"modules/loaders/vault_loader/#dynaconf.loaders.vault_loader.write","text":"Write a value in to loader source :param obj: settings object :param data: vars to be stored :param kwargs: vars to be stored :return: Source code in dynaconf\\loaders\\vault_loader.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 def write ( obj , data = None , ** kwargs ): \"\"\"Write a value in to loader source :param obj: settings object :param data: vars to be stored :param kwargs: vars to be stored :return: \"\"\" if obj . VAULT_ENABLED_FOR_DYNACONF is False : raise RuntimeError ( \"Vault is not configured \\n \" \"export VAULT_ENABLED_FOR_DYNACONF=true \\n \" \"and configure the VAULT_FOR_DYNACONF_* variables\" ) data = data or {} data . update ( kwargs ) if not data : raise AttributeError ( \"Data must be provided\" ) client = get_client ( obj ) path = \"/\" . join ([ obj . VAULT_PATH_FOR_DYNACONF , obj . current_env . lower ()]) client . secrets . kv . create_or_update_secret ( path , secret = data ) load ( obj )","title":"write()"},{"location":"modules/loaders/yaml_loader/","text":"load ( obj , env = None , silent = True , key = None , filename = None ) Reads and loads in to \"obj\" a single key or all keys from source file. :param obj: the settings instance :param env: settings current env default='development' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :param filename: Optional custom filename to load :return: None Source code in dynaconf\\loaders\\yaml_loader.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def load ( obj , env = None , silent = True , key = None , filename = None ): \"\"\" Reads and loads in to \"obj\" a single key or all keys from source file. :param obj: the settings instance :param env: settings current env default='development' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :param filename: Optional custom filename to load :return: None \"\"\" if yaml is None : # pragma: no cover BaseLoader . warn_not_installed ( obj , \"yaml\" ) return # Resolve the loaders # https://github.com/yaml/pyyaml/wiki/PyYAML-yaml.load(input)-Deprecation # Possible values are `safe_load, full_load, unsafe_load, load` yaml_reader = getattr ( yaml , obj . get ( \"YAML_LOADER_FOR_DYNACONF\" ), yaml . safe_load ) if yaml_reader . __name__ == \"unsafe_load\" : # pragma: no cover warn ( \"yaml.unsafe_load is deprecated.\" \" Please read https://msg.pyyaml.org/load for full details.\" \" Try to use full_load or safe_load.\" ) loader = BaseLoader ( obj = obj , env = env , identifier = \"yaml\" , extensions = YAML_EXTENSIONS , file_reader = yaml_reader , string_reader = yaml_reader , ) loader . load ( filename = filename , key = key , silent = silent ) write ( settings_path , settings_data , merge = True ) Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data Source code in dynaconf\\loaders\\yaml_loader.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def write ( settings_path , settings_data , merge = True ): \"\"\"Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data \"\"\" settings_path = Path ( settings_path ) if settings_path . exists () and merge : # pragma: no cover with io . open ( str ( settings_path ), encoding = default_settings . ENCODING_FOR_DYNACONF ) as open_file : object_merge ( yaml . safe_load ( open_file ), settings_data ) with io . open ( str ( settings_path ), \"w\" , encoding = default_settings . ENCODING_FOR_DYNACONF , ) as open_file : yaml . dump ( settings_data , open_file , Dumper = yaml . dumper . SafeDumper , explicit_start = True , indent = 2 , default_flow_style = False , )","title":"yaml"},{"location":"modules/loaders/yaml_loader/#dynaconf.loaders.yaml_loader","text":"","title":"dynaconf.loaders.yaml_loader"},{"location":"modules/loaders/yaml_loader/#dynaconf.loaders.yaml_loader.load","text":"Reads and loads in to \"obj\" a single key or all keys from source file. :param obj: the settings instance :param env: settings current env default='development' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :param filename: Optional custom filename to load :return: None Source code in dynaconf\\loaders\\yaml_loader.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def load ( obj , env = None , silent = True , key = None , filename = None ): \"\"\" Reads and loads in to \"obj\" a single key or all keys from source file. :param obj: the settings instance :param env: settings current env default='development' :param silent: if errors should raise :param key: if defined load a single key, else load all in env :param filename: Optional custom filename to load :return: None \"\"\" if yaml is None : # pragma: no cover BaseLoader . warn_not_installed ( obj , \"yaml\" ) return # Resolve the loaders # https://github.com/yaml/pyyaml/wiki/PyYAML-yaml.load(input)-Deprecation # Possible values are `safe_load, full_load, unsafe_load, load` yaml_reader = getattr ( yaml , obj . get ( \"YAML_LOADER_FOR_DYNACONF\" ), yaml . safe_load ) if yaml_reader . __name__ == \"unsafe_load\" : # pragma: no cover warn ( \"yaml.unsafe_load is deprecated.\" \" Please read https://msg.pyyaml.org/load for full details.\" \" Try to use full_load or safe_load.\" ) loader = BaseLoader ( obj = obj , env = env , identifier = \"yaml\" , extensions = YAML_EXTENSIONS , file_reader = yaml_reader , string_reader = yaml_reader , ) loader . load ( filename = filename , key = key , silent = silent )","title":"load()"},{"location":"modules/loaders/yaml_loader/#dynaconf.loaders.yaml_loader.write","text":"Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data Source code in dynaconf\\loaders\\yaml_loader.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def write ( settings_path , settings_data , merge = True ): \"\"\"Write data to a settings file. :param settings_path: the filepath :param settings_data: a dictionary with data :param merge: boolean if existing file should be merged with new data \"\"\" settings_path = Path ( settings_path ) if settings_path . exists () and merge : # pragma: no cover with io . open ( str ( settings_path ), encoding = default_settings . ENCODING_FOR_DYNACONF ) as open_file : object_merge ( yaml . safe_load ( open_file ), settings_data ) with io . open ( str ( settings_path ), \"w\" , encoding = default_settings . ENCODING_FOR_DYNACONF , ) as open_file : yaml . dump ( settings_data , open_file , Dumper = yaml . dumper . SafeDumper , explicit_start = True , indent = 2 , default_flow_style = False , )","title":"write()"},{"location":"modules/utils/boxing/","text":"DynaBox Specialized Box for dynaconf it allows items/attrs to be found both in upper or lower case copy ( self ) D.copy() -> a shallow copy of D Source code in dynaconf\\utils\\boxing.py 27 28 def copy ( self ): return self . __class__ ( super ( Box , self ) . copy ()) get ( self , item , default = None , * args , ** kwargs ) Return the value for key if key is in the dictionary, else default. Source code in dynaconf\\utils\\boxing.py 30 31 32 33 def get ( self , item , default = None , * args , ** kwargs ): if item not in self : # toggle case item = item . lower () if item . isupper () else upperfy ( item ) return super ( DynaBox , self ) . get ( item , default , * args , ** kwargs )","title":"Boxing"},{"location":"modules/utils/boxing/#dynaconf.utils.boxing","text":"","title":"dynaconf.utils.boxing"},{"location":"modules/utils/boxing/#dynaconf.utils.boxing.DynaBox","text":"Specialized Box for dynaconf it allows items/attrs to be found both in upper or lower case","title":"DynaBox"},{"location":"modules/utils/boxing/#dynaconf.utils.boxing.DynaBox.copy","text":"D.copy() -> a shallow copy of D Source code in dynaconf\\utils\\boxing.py 27 28 def copy ( self ): return self . __class__ ( super ( Box , self ) . copy ())","title":"copy()"},{"location":"modules/utils/boxing/#dynaconf.utils.boxing.DynaBox.get","text":"Return the value for key if key is in the dictionary, else default. Source code in dynaconf\\utils\\boxing.py 30 31 32 33 def get ( self , item , default = None , * args , ** kwargs ): if item not in self : # toggle case item = item . lower () if item . isupper () else upperfy ( item ) return super ( DynaBox , self ) . get ( item , default , * args , ** kwargs )","title":"get()"},{"location":"modules/utils/files/","text":"find_file ( filename = '.env' , project_root = None , skip_files = None , ** kwargs ) Search in increasingly higher folders for the given file Returns path to the file if found, or an empty string otherwise. This function will build a search_tree based on: Project_root if specified Invoked script location and its parents until root Current working directory For each path in the search_tree it will also look for an aditional ./config folder. Source code in dynaconf\\utils\\files.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def find_file ( filename = \".env\" , project_root = None , skip_files = None , ** kwargs ): \"\"\"Search in increasingly higher folders for the given file Returns path to the file if found, or an empty string otherwise. This function will build a `search_tree` based on: - Project_root if specified - Invoked script location and its parents until root - Current working directory For each path in the `search_tree` it will also look for an aditional `./config` folder. \"\"\" search_tree = [] work_dir = os . getcwd () skip_files = skip_files or [] if project_root is None : logger . debug ( f \"No root_path for { filename } \" ) else : logger . debug ( f \"Got root_path { project_root } for { filename } \" ) search_tree . extend ( _walk_to_root ( project_root , break_at = work_dir )) script_dir = os . path . dirname ( os . path . abspath ( inspect . stack ()[ - 1 ] . filename )) # Path to invoked script and recursively to root with its ./config dirs search_tree . extend ( _walk_to_root ( script_dir )) # Path to where Python interpreter was invoked and recursively to root search_tree . extend ( _walk_to_root ( work_dir )) # Don't look the same place twice search_tree = deduplicate ( search_tree ) global SEARCHTREE SEARCHTREE != search_tree and logger . debug ( f \"Search Tree: { search_tree } \" ) SEARCHTREE = search_tree logger . debug ( f \"Searching for { filename } \" ) for dirname in search_tree : check_path = os . path . join ( dirname , filename ) if check_path in skip_files : continue if os . path . exists ( check_path ): logger . debug ( f \"Found: { os . path . abspath ( check_path ) } \" ) return check_path # First found will return # return empty string if not found so it can still be joined in os.path return \"\" get_local_filename ( filename ) Takes a filename like settings.toml and returns settings.local.toml Arguments:: filename {str} -- The filename or complete path Returns:: [str] -- The same name or path with `.local.` added. Source code in dynaconf\\utils\\files.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 def get_local_filename ( filename ): \"\"\"Takes a filename like `settings.toml` and returns `settings.local.toml` Arguments:: filename {str} -- The filename or complete path Returns:: [str] -- The same name or path with `.local.` added. \"\"\" name , _ , extension = os . path . basename ( str ( filename )) . rpartition ( os . path . extsep ) return os . path . join ( os . path . dirname ( str ( filename )), f \" { name } .local. { extension } \" )","title":"Files"},{"location":"modules/utils/files/#dynaconf.utils.files","text":"","title":"dynaconf.utils.files"},{"location":"modules/utils/files/#dynaconf.utils.files.find_file","text":"Search in increasingly higher folders for the given file Returns path to the file if found, or an empty string otherwise. This function will build a search_tree based on: Project_root if specified Invoked script location and its parents until root Current working directory For each path in the search_tree it will also look for an aditional ./config folder. Source code in dynaconf\\utils\\files.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def find_file ( filename = \".env\" , project_root = None , skip_files = None , ** kwargs ): \"\"\"Search in increasingly higher folders for the given file Returns path to the file if found, or an empty string otherwise. This function will build a `search_tree` based on: - Project_root if specified - Invoked script location and its parents until root - Current working directory For each path in the `search_tree` it will also look for an aditional `./config` folder. \"\"\" search_tree = [] work_dir = os . getcwd () skip_files = skip_files or [] if project_root is None : logger . debug ( f \"No root_path for { filename } \" ) else : logger . debug ( f \"Got root_path { project_root } for { filename } \" ) search_tree . extend ( _walk_to_root ( project_root , break_at = work_dir )) script_dir = os . path . dirname ( os . path . abspath ( inspect . stack ()[ - 1 ] . filename )) # Path to invoked script and recursively to root with its ./config dirs search_tree . extend ( _walk_to_root ( script_dir )) # Path to where Python interpreter was invoked and recursively to root search_tree . extend ( _walk_to_root ( work_dir )) # Don't look the same place twice search_tree = deduplicate ( search_tree ) global SEARCHTREE SEARCHTREE != search_tree and logger . debug ( f \"Search Tree: { search_tree } \" ) SEARCHTREE = search_tree logger . debug ( f \"Searching for { filename } \" ) for dirname in search_tree : check_path = os . path . join ( dirname , filename ) if check_path in skip_files : continue if os . path . exists ( check_path ): logger . debug ( f \"Found: { os . path . abspath ( check_path ) } \" ) return check_path # First found will return # return empty string if not found so it can still be joined in os.path return \"\"","title":"find_file()"},{"location":"modules/utils/files/#dynaconf.utils.files.get_local_filename","text":"Takes a filename like settings.toml and returns settings.local.toml Arguments:: filename {str} -- The filename or complete path Returns:: [str] -- The same name or path with `.local.` added. Source code in dynaconf\\utils\\files.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 def get_local_filename ( filename ): \"\"\"Takes a filename like `settings.toml` and returns `settings.local.toml` Arguments:: filename {str} -- The filename or complete path Returns:: [str] -- The same name or path with `.local.` added. \"\"\" name , _ , extension = os . path . basename ( str ( filename )) . rpartition ( os . path . extsep ) return os . path . join ( os . path . dirname ( str ( filename )), f \" { name } .local. { extension } \" )","title":"get_local_filename()"},{"location":"modules/utils/parse_conf/","text":"KV_PATTERN matches a=b, c=d, e=f used on VALUE='@merge foo=bar' variables. Del Triggers an existing key to be deleted DynaconfParseError Error to raise when parsing @casts Formatters Dynaconf builtin formatters Lazy Holds data to format lazily. context property readonly Builds a context for formatting. __call__ ( self , settings ) special LazyValue triggers format lazily. Source code in dynaconf\\utils\\parse_conf.py 163 164 165 166 def __call__ ( self , settings ): \"\"\"LazyValue triggers format lazily.\"\"\" self . settings = settings return self . formatter ( self . value , ** self . context ) __repr__ ( self ) special Give the quoted str representation Source code in dynaconf\\utils\\parse_conf.py 172 173 174 def __repr__ ( self ): \"\"\"Give the quoted str representation\"\"\" return f \"'@ { self . formatter } { self . value } '\" __str__ ( self ) special Gives string representation for the object. Source code in dynaconf\\utils\\parse_conf.py 168 169 170 def __str__ ( self ): \"\"\"Gives string representation for the object.\"\"\" return str ( self . value ) Merge Triggers an existing key to be merged MetaValue A Marker to trigger specific actions on set and object_merge Reset Triggers an existing key to be reset to its value NOTE: DEPRECATED on v3.0.0 evaluate_lazy_format ( f ) Marks a method on Settings instance to lazily evaluate LazyFormat objects upon access. Source code in dynaconf\\utils\\parse_conf.py 189 190 191 192 193 194 195 196 197 198 199 200 def evaluate_lazy_format ( f ): \"\"\"Marks a method on Settings instance to lazily evaluate LazyFormat objects upon access.\"\"\" @wraps ( f ) def evaluate ( settings , * args , ** kwargs ): value = f ( settings , * args , ** kwargs ) if getattr ( value , \"_dynaconf_lazy_format\" , None ): return value ( settings ) return value return evaluate parse_with_toml ( data ) Uses TOML syntax to parse data Source code in dynaconf\\utils\\parse_conf.py 224 225 226 227 228 229 def parse_with_toml ( data ): \"\"\"Uses TOML syntax to parse data\"\"\" try : return toml . loads ( f \"key= { data } \" , DynaBox ) . key except ( toml . TomlDecodeError , BoxKeyError ): return data try_to_encode ( value , callback =< class ' str '>) Tries to encode a value by verifying existence of _dynaconf_encode Source code in dynaconf\\utils\\parse_conf.py 181 182 183 184 185 186 def try_to_encode ( value , callback = str ): \"\"\"Tries to encode a value by verifying existence of `_dynaconf_encode`\"\"\" try : return value . _dynaconf_encode () except ( AttributeError , TypeError ) as e : return callback ( value )","title":"Parse Config"},{"location":"modules/utils/parse_conf/#dynaconf.utils.parse_conf","text":"","title":"dynaconf.utils.parse_conf"},{"location":"modules/utils/parse_conf/#dynaconf.utils.parse_conf.KV_PATTERN","text":"matches a=b, c=d, e=f used on VALUE='@merge foo=bar' variables.","title":"KV_PATTERN"},{"location":"modules/utils/parse_conf/#dynaconf.utils.parse_conf.Del","text":"Triggers an existing key to be deleted","title":"Del"},{"location":"modules/utils/parse_conf/#dynaconf.utils.parse_conf.DynaconfParseError","text":"Error to raise when parsing @casts","title":"DynaconfParseError"},{"location":"modules/utils/parse_conf/#dynaconf.utils.parse_conf.Formatters","text":"Dynaconf builtin formatters","title":"Formatters"},{"location":"modules/utils/parse_conf/#dynaconf.utils.parse_conf.Lazy","text":"Holds data to format lazily.","title":"Lazy"},{"location":"modules/utils/parse_conf/#dynaconf.utils.parse_conf.Lazy.context","text":"Builds a context for formatting.","title":"context"},{"location":"modules/utils/parse_conf/#dynaconf.utils.parse_conf.Lazy.__call__","text":"LazyValue triggers format lazily. Source code in dynaconf\\utils\\parse_conf.py 163 164 165 166 def __call__ ( self , settings ): \"\"\"LazyValue triggers format lazily.\"\"\" self . settings = settings return self . formatter ( self . value , ** self . context )","title":"__call__()"},{"location":"modules/utils/parse_conf/#dynaconf.utils.parse_conf.Lazy.__repr__","text":"Give the quoted str representation Source code in dynaconf\\utils\\parse_conf.py 172 173 174 def __repr__ ( self ): \"\"\"Give the quoted str representation\"\"\" return f \"'@ { self . formatter } { self . value } '\"","title":"__repr__()"},{"location":"modules/utils/parse_conf/#dynaconf.utils.parse_conf.Lazy.__str__","text":"Gives string representation for the object. Source code in dynaconf\\utils\\parse_conf.py 168 169 170 def __str__ ( self ): \"\"\"Gives string representation for the object.\"\"\" return str ( self . value )","title":"__str__()"},{"location":"modules/utils/parse_conf/#dynaconf.utils.parse_conf.Merge","text":"Triggers an existing key to be merged","title":"Merge"},{"location":"modules/utils/parse_conf/#dynaconf.utils.parse_conf.MetaValue","text":"A Marker to trigger specific actions on set and object_merge","title":"MetaValue"},{"location":"modules/utils/parse_conf/#dynaconf.utils.parse_conf.Reset","text":"Triggers an existing key to be reset to its value NOTE: DEPRECATED on v3.0.0","title":"Reset"},{"location":"modules/utils/parse_conf/#dynaconf.utils.parse_conf.evaluate_lazy_format","text":"Marks a method on Settings instance to lazily evaluate LazyFormat objects upon access. Source code in dynaconf\\utils\\parse_conf.py 189 190 191 192 193 194 195 196 197 198 199 200 def evaluate_lazy_format ( f ): \"\"\"Marks a method on Settings instance to lazily evaluate LazyFormat objects upon access.\"\"\" @wraps ( f ) def evaluate ( settings , * args , ** kwargs ): value = f ( settings , * args , ** kwargs ) if getattr ( value , \"_dynaconf_lazy_format\" , None ): return value ( settings ) return value return evaluate","title":"evaluate_lazy_format()"},{"location":"modules/utils/parse_conf/#dynaconf.utils.parse_conf.parse_with_toml","text":"Uses TOML syntax to parse data Source code in dynaconf\\utils\\parse_conf.py 224 225 226 227 228 229 def parse_with_toml ( data ): \"\"\"Uses TOML syntax to parse data\"\"\" try : return toml . loads ( f \"key= { data } \" , DynaBox ) . key except ( toml . TomlDecodeError , BoxKeyError ): return data","title":"parse_with_toml()"},{"location":"modules/utils/parse_conf/#dynaconf.utils.parse_conf.try_to_encode","text":"Tries to encode a value by verifying existence of _dynaconf_encode Source code in dynaconf\\utils\\parse_conf.py 181 182 183 184 185 186 def try_to_encode ( value , callback = str ): \"\"\"Tries to encode a value by verifying existence of `_dynaconf_encode`\"\"\" try : return value . _dynaconf_encode () except ( AttributeError , TypeError ) as e : return callback ( value )","title":"try_to_encode()"}]}